<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/66449ed0e802001c.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-1e56b3c3206210e2.js"/><script src="/_next/static/chunks/ec7a6716-6cab3e3f753fb035.js" async=""></script><script src="/_next/static/chunks/5774-3c92e2fd4a5f0665.js" async=""></script><script src="/_next/static/chunks/main-app-669fa76d353b467e.js" async=""></script><script src="/_next/static/chunks/f6ab4fea-4425dae3da7674a3.js" async=""></script><script src="/_next/static/chunks/b27dc69b-e5acb70cd9d66ddf.js" async=""></script><script src="/_next/static/chunks/f3ac7ef3-57e0d20b76b6c0bf.js" async=""></script><script src="/_next/static/chunks/5232-db5923cda78a4960.js" async=""></script><script src="/_next/static/chunks/6465-524ff7a6f6bb774c.js" async=""></script><script src="/_next/static/chunks/9388-d1a745fd53a10850.js" async=""></script><script src="/_next/static/chunks/1508-abbc58115cbb4fd0.js" async=""></script><script src="/_next/static/chunks/236-f8f5e32bce4e096f.js" async=""></script><script src="/_next/static/chunks/7101-9ab34b82066b9cd8.js" async=""></script><script src="/_next/static/chunks/6125-6f7cbc86df4f2503.js" async=""></script><script src="/_next/static/chunks/2919-7652e8907f6a6ad4.js" async=""></script><script src="/_next/static/chunks/7640-74d36ce7728a4200.js" async=""></script><script src="/_next/static/chunks/4091-69e125b8fd863f9f.js" async=""></script><script src="/_next/static/chunks/976-8676cce570a8fe93.js" async=""></script><script src="/_next/static/chunks/4942-51fd33fb9762f202.js" async=""></script><script src="/_next/static/chunks/app/%5Blocale%5D/(home)/layout-e297fbc0fe7ac09d.js" async=""></script><script src="/_next/static/chunks/1866796a-670a712d9364e62c.js" async=""></script><script src="/_next/static/chunks/6541-2f0250d6a0967fe4.js" async=""></script><script src="/_next/static/chunks/app/%5Blocale%5D/(default)/layout-681f37f67bcbff3e.js" async=""></script><script src="/_next/static/chunks/9732-8158987224fdfa35.js" async=""></script><script src="/_next/static/chunks/1358-a345831bbdffdf07.js" async=""></script><script src="/_next/static/chunks/app/%5Blocale%5D/(default)/clients/page-5664c6f855076eab.js" async=""></script><script src="/_next/static/chunks/4b7059ae-76f7529d720584f8.js" async=""></script><script src="/_next/static/chunks/4902-f1919cf5204afe9f.js" async=""></script><script src="/_next/static/chunks/2407-4b5edf4e84c5d717.js" async=""></script><script src="/_next/static/chunks/app/%5Blocale%5D/layout-2c849eca4082e774.js" async=""></script><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2123767634383915" crossorigin="anonymous"></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-9ZWF7FKDR8" as="script"/><link rel="icon" href="/favicon.ico"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="alternate" hrefLang="en" href="https://mcp.so"/><link rel="alternate" hrefLang="zh" href="https://mcp.so/zh/"/><link rel="alternate" hrefLang="ja" href="https://mcp.so/ja/"/><link rel="alternate" hrefLang="x-default" href="https://mcp.so"/><meta name="google-adsense-account" content="ca-pub-2123767634383915"/><title>MCP Clients</title><meta name="description" content="Find the best MCP Clients for your needs."/><meta name="keywords" content="MCP Servers, Awesome MCP Servers, Claude MCP, Model Context Protocol"/><link rel="canonical" href="https://mcp.so/clients"/><meta property="og:title" content="MCP Servers"/><meta property="og:description" content="The largest collection of MCP Servers, including Awesome MCP Servers and Claude MCP integration. Search and discover MCP servers to enhance your AI capabilities."/><meta property="og:url" content="https://mcp.so"/><meta property="og:site_name" content="MCP.so"/><meta property="og:locale" content="en"/><meta property="og:image" content="https://mcp.so/logo.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:site" content="MCP.so"/><meta name="twitter:title" content="MCP Servers"/><meta name="twitter:description" content="The largest collection of MCP Servers, including Awesome MCP Servers and Claude MCP integration. Search and discover MCP servers to enhance your AI capabilities."/><meta name="twitter:image" content="https://mcp.so/logo.png"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="min-h-screen bg-background antialiased overflow-x-hidden"><script>((e2, t2, r5, n2, a3, o4, i3, s3) => {
            let l4 = document.documentElement, u3 = ["light", "dark"];
            function c2(t3) {
              var r6;
              (Array.isArray(e2) ? e2 : [e2]).forEach((e3) => {
                let r7 = "class" === e3, n3 = r7 && o4 ? a3.map((e4) => o4[e4] || e4) : a3;
                r7 ? (l4.classList.remove(...n3), l4.classList.add(t3)) : l4.setAttribute(e3, t3);
              }), r6 = t3, s3 && u3.includes(r6) && (l4.style.colorScheme = r6);
            }
            __name(c2, "c2");
            if (n2) c2(n2);
            else try {
              let e3 = localStorage.getItem(t2) || r5, n3 = i3 && "system" === e3 ? window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light" : e3;
              c2(n3);
            } catch (e3) {
            }
          })("class","theme","system","light",["light","dark"],null,true,true)</script><div style="--sidebar-width:16rem;--sidebar-width-icon:3rem" class="group/sidebar-wrapper flex min-h-svh w-full has-data-[variant=inset]:bg-sidebar"><div class="group peer hidden text-sidebar-foreground md:block" data-state="expanded" data-collapsible="" data-variant="floating" data-side="left"><div class="relative w-(--sidebar-width) bg-transparent transition-[width] duration-200 ease-linear group-data-[collapsible=offcanvas]:w-0 group-data-[side=right]:rotate-180 group-data-[collapsible=icon]:w-[calc(var(--sidebar-width-icon)+(--spacing(4)))]"></div><div class="fixed inset-y-0 z-10 hidden h-svh w-(--sidebar-width) transition-[left,right,width] duration-200 ease-linear md:flex left-0 group-data-[collapsible=offcanvas]:left-[calc(var(--sidebar-width)*-1)] p-2 group-data-[collapsible=icon]:w-[calc(var(--sidebar-width-icon)+(--spacing(4))+2px)]"><div data-sidebar="sidebar" class="flex h-full w-full flex-col bg-sidebar group-data-[variant=floating]:rounded-lg group-data-[variant=floating]:border group-data-[variant=floating]:border-sidebar-border group-data-[variant=floating]:shadow-sm"><div data-sidebar="header" class="flex flex-col gap-2 p-2"><ul data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-1"><li data-sidebar="menu-item" class="group/menu-item relative"><a class="flex items-center gap-2" href="/"><img alt="MCP.so" loading="lazy" width="28" height="28" decoding="async" data-nimg="1" class="rounded-md w-8 h-8" style="color:transparent" srcSet="/_next/image?url=%2Flogo.png&amp;w=32&amp;q=75 1x, /_next/image?url=%2Flogo.png&amp;w=64&amp;q=75 2x" src="/_next/image?url=%2Flogo.png&amp;w=64&amp;q=75"/><span class="text-base font-semibold flex-1">MCP.so</span></a></li></ul></div><div data-sidebar="content" class="flex min-h-0 flex-1 flex-col gap-2 overflow-auto group-data-[collapsible=icon]:overflow-hidden"><div data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2"><div data-sidebar="group-content" class="w-full text-sm flex flex-col gap-2 mt-4"><ul data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-1"><li data-sidebar="menu-item" class="group/menu-item relative group/collapsible" data-state="closed"><button data-sidebar="menu-button" data-size="default" data-active="false" class="peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&amp;&gt;span:last-child]:truncate [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 hover:bg-sidebar-accent hover:text-sidebar-accent-foreground h-8 text-sm" type="button" aria-controls="radix-Â«RmjcqtbÂ»" aria-expanded="false" data-state="closed"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M21 20C21 20.5523 20.5523 21 20 21H4C3.44772 21 3 20.5523 3 20V9.48907C3 9.18048 3.14247 8.88917 3.38606 8.69972L11.3861 2.47749C11.7472 2.19663 12.2528 2.19663 12.6139 2.47749L20.6139 8.69972C20.8575 8.88917 21 9.18048 21 9.48907V20ZM19 19V9.97815L12 4.53371L5 9.97815V19H19Z"></path></svg><span>Home</span></button></li><li data-sidebar="menu-item" class="group/menu-item relative group/collapsible" data-state="closed"><button data-sidebar="menu-button" data-size="default" data-active="false" class="peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&amp;&gt;span:last-child]:truncate [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 hover:bg-sidebar-accent hover:text-sidebar-accent-foreground h-8 text-sm" type="button" aria-controls="radix-Â«R16jcqtbÂ»" aria-expanded="false" data-state="closed"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5 11H19V5H5V11ZM21 4V20C21 20.5523 20.5523 21 20 21H4C3.44772 21 3 20.5523 3 20V4C3 3.44772 3.44772 3 4 3H20C20.5523 3 21 3.44772 21 4ZM19 13H5V19H19V13ZM7 15H10V17H7V15ZM7 7H10V9H7V7Z"></path></svg><span>Servers</span></button></li><li data-sidebar="menu-item" class="group/menu-item relative group/collapsible" data-state="closed"><button data-sidebar="menu-button" data-size="default" data-active="false" class="peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&amp;&gt;span:last-child]:truncate [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 h-8 text-sm bg-sidebar-accent text-primary hover:bg-sidebar-accent/90 hover:text-primary active:bg-sidebar-accent/90 active:text-primary min-w-8 duration-200 ease-linear" type="button" aria-controls="radix-Â«R1mjcqtbÂ»" aria-expanded="false" data-state="closed"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6.75 2.5C9.09721 2.5 11 4.40279 11 6.75V11H6.75C4.40279 11 2.5 9.09721 2.5 6.75C2.5 4.40279 4.40279 2.5 6.75 2.5ZM9 9V6.75C9 5.50736 7.99264 4.5 6.75 4.5C5.50736 4.5 4.5 5.50736 4.5 6.75C4.5 7.99264 5.50736 9 6.75 9H9ZM6.75 13H11V17.25C11 19.5972 9.09721 21.5 6.75 21.5C4.40279 21.5 2.5 19.5972 2.5 17.25C2.5 14.9028 4.40279 13 6.75 13ZM6.75 15C5.50736 15 4.5 16.0074 4.5 17.25C4.5 18.4926 5.50736 19.5 6.75 19.5C7.99264 19.5 9 18.4926 9 17.25V15H6.75ZM17.25 2.5C19.5972 2.5 21.5 4.40279 21.5 6.75C21.5 9.09721 19.5972 11 17.25 11H13V6.75C13 4.40279 14.9028 2.5 17.25 2.5ZM17.25 9C18.4926 9 19.5 7.99264 19.5 6.75C19.5 5.50736 18.4926 4.5 17.25 4.5C16.0074 4.5 15 5.50736 15 6.75V9H17.25ZM13 13H17.25C19.5972 13 21.5 14.9028 21.5 17.25C21.5 19.5972 19.5972 21.5 17.25 21.5C14.9028 21.5 13 19.5972 13 17.25V13ZM15 15V17.25C15 18.4926 16.0074 19.5 17.25 19.5C18.4926 19.5 19.5 18.4926 19.5 17.25C19.5 16.0074 18.4926 15 17.25 15H15Z"></path></svg><span>Clients</span></button></li><li data-sidebar="menu-item" class="group/menu-item relative group/collapsible" data-state="closed"><button data-sidebar="menu-button" data-size="default" data-active="false" class="peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&amp;&gt;span:last-child]:truncate [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 hover:bg-sidebar-accent hover:text-sidebar-accent-foreground h-8 text-sm" type="button" aria-controls="radix-Â«R26jcqtbÂ»" aria-expanded="false" data-state="closed"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M3 4H21V6H3V4ZM3 11H15V13H3V11ZM3 18H21V20H3V18Z"></path></svg><span>Categories</span></button></li><li data-sidebar="menu-item" class="group/menu-item relative group/collapsible" data-state="closed"><button data-sidebar="menu-button" data-size="default" data-active="false" class="peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&amp;&gt;span:last-child]:truncate [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 hover:bg-sidebar-accent hover:text-sidebar-accent-foreground h-8 text-sm" type="button" aria-controls="radix-Â«R2mjcqtbÂ»" aria-expanded="false" data-state="closed"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M7.78428 14L8.2047 10H4V8H8.41491L8.94043 3H10.9514L10.4259 8H14.4149L14.9404 3H16.9514L16.4259 8H20V10H16.2157L15.7953 14H20V16H15.5851L15.0596 21H13.0486L13.5741 16H9.58509L9.05957 21H7.04855L7.57407 16H4V14H7.78428ZM9.7953 14H13.7843L14.2047 10H10.2157L9.7953 14Z"></path></svg><span>Tags</span></button></li><li data-sidebar="menu-item" class="group/menu-item relative group/collapsible" data-state="closed"><button data-sidebar="menu-button" data-size="default" data-active="false" class="peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&amp;&gt;span:last-child]:truncate [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 hover:bg-sidebar-accent hover:text-sidebar-accent-foreground h-8 text-sm" type="button" aria-controls="radix-Â«R36jcqtbÂ»" aria-expanded="false" data-state="closed"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M10.0014 14.6757C10.0011 14.6551 10.001 14.6345 10.001 14.6138C10.001 12.1055 12.0175 9.99564 14.7539 9.38092C14.3904 7.07873 11.9602 5.19995 8.90098 5.19995C5.58037 5.19995 3.00098 7.41344 3.00098 9.9793C3.00098 10.9487 3.36131 11.88 4.04082 12.6781C4.0728 12.7157 4.12443 12.7717 4.19342 12.8427C4.78537 13.4517 5.13709 14.2457 5.19546 15.0805C5.90857 14.6683 6.74285 14.5123 7.55832 14.6392C7.72416 14.665 7.85986 14.6847 7.96345 14.6982C8.27111 14.7383 8.58419 14.7586 8.90098 14.7586C9.27825 14.7586 9.64595 14.7301 10.0014 14.6757ZM10.4581 16.627C9.95467 16.7133 9.43399 16.7586 8.90098 16.7586C8.49441 16.7586 8.09502 16.7323 7.70499 16.6815C7.58312 16.6656 7.4317 16.6436 7.25073 16.6154C6.87693 16.5572 6.49436 16.6321 6.1713 16.8268L4.26653 17.9745C4.12052 18.0646 3.94891 18.1057 3.77733 18.0916C3.33814 18.0554 3.01178 17.6744 3.04837 17.2405L3.19859 15.4596C3.23664 15.0086 3.07664 14.5632 2.75931 14.2367C2.66182 14.1364 2.5814 14.0491 2.51802 13.9747C1.56406 12.8542 1.00098 11.4732 1.00098 9.9793C1.00098 6.23517 4.53793 3.19995 8.90098 3.19995C12.9601 3.19995 16.3041 5.82699 16.7504 9.20788C20.1225 9.36136 22.801 11.723 22.801 14.6138C22.801 15.8068 22.3448 16.9097 21.572 17.8044C21.5206 17.8639 21.4555 17.9336 21.3765 18.0137C21.1194 18.2744 20.9898 18.6301 21.0206 18.9903L21.1423 20.4125C21.172 20.759 20.9076 21.0632 20.5518 21.0921C20.4128 21.1034 20.2738 21.0706 20.1555 20.9986L18.6124 20.0821C18.3506 19.9266 18.0407 19.8668 17.7379 19.9133C17.5913 19.9358 17.4686 19.9533 17.3699 19.966C17.0539 20.0066 16.7303 20.0277 16.401 20.0277C13.7074 20.0277 11.4025 18.6201 10.4581 16.627ZM17.4346 17.9364C18.0019 17.8494 18.5793 17.911 19.1105 18.1111C19.2492 17.5503 19.5373 17.0304 19.9524 16.6094C20.0027 16.5585 20.0388 16.5198 20.0584 16.4971C20.5467 15.9318 20.801 15.2839 20.801 14.6138C20.801 12.8095 18.8983 11.2 16.401 11.2C13.9037 11.2 12.001 12.8095 12.001 14.6138C12.001 16.4181 13.9037 18.0277 16.401 18.0277C16.6424 18.0277 16.8809 18.0124 17.115 17.9823C17.1957 17.972 17.3029 17.9566 17.4346 17.9364Z"></path></svg><span>Feed</span></button></li></ul></div></div><div data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2 mt-auto"><div data-sidebar="group-content" class="w-full text-sm"><ul data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-1"><li data-sidebar="menu-item" class="group/menu-item relative"><a target="_self" data-sidebar="menu-button" data-size="default" data-active="false" class="peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&amp;&gt;span:last-child]:truncate [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 hover:bg-sidebar-accent hover:text-sidebar-accent-foreground h-8 text-sm" href="/my-servers"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M12 1L21.5 6.5V17.5L12 23L2.5 17.5V6.5L12 1ZM12 3.311L4.5 7.65311V16.3469L12 20.689L19.5 16.3469V7.65311L12 3.311ZM12 16C9.79086 16 8 14.2091 8 12C8 9.79086 9.79086 8 12 8C14.2091 8 16 9.79086 16 12C16 14.2091 14.2091 16 12 16ZM12 14C13.1046 14 14 13.1046 14 12C14 10.8954 13.1046 10 12 10C10.8954 10 10 10.8954 10 12C10 13.1046 10.8954 14 12 14Z"></path></svg><span>Settings</span></a></li></ul></div></div></div><div data-sidebar="footer" class="flex flex-col gap-2"><div class="flex justify-center items-center h-full px-4 py-4"><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 bg-primary text-primary-foreground hover:bg-primary/90 h-10 px-4 py-2 w-full">Sign In</button></div><div class="w-full flex items-center justify-center mx-auto gap-x-4 px-0 py-4 border-t"><div class="cursor-pointer hover:text-primary"><a target="_blank" class="cursor-pointer" href="https://x.com/chatmcp"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M17.6874 3.0625L12.6907 8.77425L8.37045 3.0625H2.11328L9.58961 12.8387L2.50378 20.9375H5.53795L11.0068 14.6886L15.7863 20.9375H21.8885L14.095 10.6342L20.7198 3.0625H17.6874ZM16.6232 19.1225L5.65436 4.78217H7.45745L18.3034 19.1225H16.6232Z"></path></svg></a></div><div class="cursor-pointer hover:text-primary"><a target="_blank" class="cursor-pointer" href="https://github.com/chatmcp/mcpso/issues"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M12.001 2C6.47598 2 2.00098 6.475 2.00098 12C2.00098 16.425 4.86348 20.1625 8.83848 21.4875C9.33848 21.575 9.52598 21.275 9.52598 21.0125C9.52598 20.775 9.51348 19.9875 9.51348 19.15C7.00098 19.6125 6.35098 18.5375 6.15098 17.975C6.03848 17.6875 5.55098 16.8 5.12598 16.5625C4.77598 16.375 4.27598 15.9125 5.11348 15.9C5.90098 15.8875 6.46348 16.625 6.65098 16.925C7.55098 18.4375 8.98848 18.0125 9.56348 17.75C9.65098 17.1 9.91348 16.6625 10.201 16.4125C7.97598 16.1625 5.65098 15.3 5.65098 11.475C5.65098 10.3875 6.03848 9.4875 6.67598 8.7875C6.57598 8.5375 6.22598 7.5125 6.77598 6.1375C6.77598 6.1375 7.61348 5.875 9.52598 7.1625C10.326 6.9375 11.176 6.825 12.026 6.825C12.876 6.825 13.726 6.9375 14.526 7.1625C16.4385 5.8625 17.276 6.1375 17.276 6.1375C17.826 7.5125 17.476 8.5375 17.376 8.7875C18.0135 9.4875 18.401 10.375 18.401 11.475C18.401 15.3125 16.0635 16.1625 13.8385 16.4125C14.201 16.725 14.5135 17.325 14.5135 18.2625C14.5135 19.6 14.501 20.675 14.501 21.0125C14.501 21.275 14.6885 21.5875 15.1885 21.4875C19.259 20.1133 21.9999 16.2963 22.001 12C22.001 6.475 17.526 2 12.001 2Z"></path></svg></a></div><div class="cursor-pointer hover:text-primary"><a target="_blank" class="cursor-pointer" href="https://discord.gg/RsYPRrnyqg"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M19.3034 5.33716C17.9344 4.71103 16.4805 4.2547 14.9629 4C14.7719 4.32899 14.5596 4.77471 14.411 5.12492C12.7969 4.89144 11.1944 4.89144 9.60255 5.12492C9.45397 4.77471 9.2311 4.32899 9.05068 4C7.52251 4.2547 6.06861 4.71103 4.70915 5.33716C1.96053 9.39111 1.21766 13.3495 1.5891 17.2549C3.41443 18.5815 5.17612 19.388 6.90701 19.9187C7.33151 19.3456 7.71356 18.73 8.04255 18.0827C7.41641 17.8492 6.82211 17.5627 6.24904 17.2231C6.39762 17.117 6.5462 17.0003 6.68416 16.8835C10.1438 18.4648 13.8911 18.4648 17.3082 16.8835C17.4568 17.0003 17.5948 17.117 17.7434 17.2231C17.1703 17.5627 16.576 17.8492 15.9499 18.0827C16.2789 18.73 16.6609 19.3456 17.0854 19.9187C18.8152 19.388 20.5875 18.5815 22.4033 17.2549C22.8596 12.7341 21.6806 8.80747 19.3034 5.33716ZM8.5201 14.8459C7.48007 14.8459 6.63107 13.9014 6.63107 12.7447C6.63107 11.5879 7.45884 10.6434 8.5201 10.6434C9.57071 10.6434 10.4303 11.5879 10.4091 12.7447C10.4091 13.9014 9.57071 14.8459 8.5201 14.8459ZM15.4936 14.8459C14.4535 14.8459 13.6034 13.9014 13.6034 12.7447C13.6034 11.5879 14.4323 10.6434 15.4936 10.6434C16.5442 10.6434 17.4038 11.5879 17.3825 12.7447C17.3825 13.9014 16.5548 14.8459 15.4936 14.8459Z"></path></svg></a></div><div class="cursor-pointer hover:text-primary"><a target="_self" class="cursor-pointer" href="mailto:support@mcp.so"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M3 3H21C21.5523 3 22 3.44772 22 4V20C22 20.5523 21.5523 21 21 21H3C2.44772 21 2 20.5523 2 20V4C2 3.44772 2.44772 3 3 3ZM20 7.23792L12.0718 14.338L4 7.21594V19H20V7.23792ZM4.51146 5L12.0619 11.662L19.501 5H4.51146Z"></path></svg></a></div><div data-orientation="vertical" role="none" class="shrink-0 bg-border w-px h-4"></div><div class="flex items-center gap-x-2 px-2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" class="cursor-pointer text-lg text-muted-foreground" width="1em" height="1em" xmlns="http://www.w3.org/2000/svg"><path d="M6 .278a.77.77 0 0 1 .08.858 7.2 7.2 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277q.792-.001 1.533-.16a.79.79 0 0 1 .81.316.73.73 0 0 1-.031.893A8.35 8.35 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.75.75 0 0 1 6 .278M4.858 1.311A7.27 7.27 0 0 0 1.025 7.71c0 4.02 3.279 7.276 7.319 7.276a7.32 7.32 0 0 0 5.205-2.162q-.506.063-1.029.063c-4.61 0-8.343-3.714-8.343-8.29 0-1.167.242-2.278.681-3.286"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.73 1.73 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.73 1.73 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.73 1.73 0 0 0 1.097-1.097zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.16 1.16 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.16 1.16 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732z"></path></svg></div></div></div></div></div></div><main class="relative flex w-full flex-1 flex-col bg-background md:peer-data-[variant=inset]:m-2 md:peer-data-[variant=inset]:peer-data-[state=collapsed]:ml-2 md:peer-data-[variant=inset]:ml-0 md:peer-data-[variant=inset]:rounded-xl md:peer-data-[variant=inset]:shadow-sm"><header class="flex py-2 shrink-0 items-center gap-2 transition-[width,height] ease-linear group-has-data-[collapsible=icon]/sidebar-wrapper:h-12"><div class="w-full flex items-center gap-4 px-4"><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-7 w-7 -ml-1 cursor-pointer" data-sidebar="trigger"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-panel-left"><rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="M9 3v18"></path></svg><span class="sr-only">Toggle Sidebar</span></button><div class="flex items-center gap-4"></div><div class="flex-1"></div><div class="flex gap-4"><a class="flex items-center gap-1 text-sm font-medium text-primary rounded-full px-4 hover:bg-primary/10" href="/submit"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="w-4 h-4 shrink-0" style="cursor:pointer" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M11 11V5H13V11H19V13H13V19H11V13H5V11H11Z"></path></svg>Submit</a><div><button type="button" role="combobox" aria-controls="radix-Â«R1alcqtbÂ»" aria-expanded="false" aria-autocomplete="none" dir="ltr" data-state="closed" class="h-10 w-full justify-between rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus:outline-hidden focus:ring-ring disabled:cursor-not-allowed disabled:opacity-50 [&amp;&gt;span]:line-clamp-1 flex items-center gap-x-2 border-none text-muted-foreground outline-hidden hover:bg-transparent focus:ring-0 focus:ring-offset-0"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M11.99 2C6.47 2 2 6.48 2 12s4.47 10 9.99 10C17.52 22 22 17.52 22 12S17.52 2 11.99 2zm6.93 6h-2.95a15.65 15.65 0 0 0-1.38-3.56A8.03 8.03 0 0 1 18.92 8zM12 4.04c.83 1.2 1.48 2.53 1.91 3.96h-3.82c.43-1.43 1.08-2.76 1.91-3.96zM4.26 14C4.1 13.36 4 12.69 4 12s.1-1.36.26-2h3.38c-.08.66-.14 1.32-.14 2 0 .68.06 1.34.14 2H4.26zm.82 2h2.95c.32 1.25.78 2.45 1.38 3.56A7.987 7.987 0 0 1 5.08 16zm2.95-8H5.08a7.987 7.987 0 0 1 4.33-3.56A15.65 15.65 0 0 0 8.03 8zM12 19.96c-.83-1.2-1.48-2.53-1.91-3.96h3.82c-.43 1.43-1.08 2.76-1.91 3.96zM14.34 14H9.66c-.09-.66-.16-1.32-.16-2 0-.68.07-1.35.16-2h4.68c.09.65.16 1.32.16 2 0 .68-.07 1.34-.16 2zm.25 5.56c.6-1.11 1.06-2.31 1.38-3.56h2.95a8.03 8.03 0 0 1-4.33 3.56zM16.36 14c.08-.66.14-1.32.14-2 0-.68-.06-1.34-.14-2h3.38c.16.64.26 1.31.26 2s-.1 1.36-.26 2h-3.38z"></path></svg><span class="hidden md:block">English</span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down h-4 w-4 opacity-50" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></button><select aria-hidden="true" tabindex="-1" style="position:absolute;border:0;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;word-wrap:normal"></select></div></div></div></header><div class="flex-1 px-4 md:px-6 pb-16 pt-4"><div class="mb-4 w-full max-w-2xl overflow-hidden"><h1 class="text-2xl font-bold mb-2">MCP Clients</h1><p class="text-sm text-muted-foreground">A list of MCP Clients.</p><nav class="flex items-center space-x-4 lg:space-x-4 overflow-x-auto py-4 mt-4 w-full max-w-full"><a class="text-xs md:text-sm font-medium px-1 py-1 pb-2 flex items-center gap-1 whitespace-nowrap flex-shrink-0 text-primary border-b-2 border-primary" href="/clients"><h2 class="block">All</h2></a><a class="text-xs md:text-sm font-medium px-1 py-1 pb-2 flex items-center gap-1 whitespace-nowrap flex-shrink-0 text-muted-foreground" href="/clients?tag=featured"><h2 class="block">Featured</h2></a><a class="text-xs md:text-sm font-medium px-1 py-1 pb-2 flex items-center gap-1 whitespace-nowrap flex-shrink-0 text-muted-foreground" href="/clients?tag=latest"><h2 class="block">Latest</h2></a></nav></div><div class="grid gap-4 grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4"><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/CarrotAI/Xingsandesu"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">C</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">CarrotAI</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">CarrotAI is a cutting-edge AI agent application that delivers real-time streaming chat via Server-Sent Events (SSE) with built-in Model Control Protocol (MCP) integration. It supports concurrent connections to multiple SSE MCP servers and provides user interfaces in English, Chinese, and Japanese.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/seekchat/seekrays"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">S</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">SeekChat</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">âœ¨ A Sleek and Powerful AI Desktop Assistant that supports MCP integrationâœ¨</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/easyrag/binarybana"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">L</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">LLM RAG</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Easy RAG scripts for a local, embedded, MCP-enabled knowledge store.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-download/shuakami"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">D</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Download MCP å·¥å…·</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">ğŸ“¥ MCP Download Tool - AI-powered file download manager | åŸºäº MCP çš„æ™ºèƒ½ä¸‹è½½ç®¡ç†å·¥å…·</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/pydantic-mcp/rectalogic"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">P</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">pydantic-mcp</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Model Context Protocol tool calling support for Pydantic AI</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/LibreChat/danny-avila"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">L</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">LibreChat</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Enhanced ChatGPT Clone: Features Agents, DeepSeek, Anthropic, AWS, OpenAI, Assistants API, Azure, Groq, o1, GPT-4o, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active project.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/tester-mcp-client/apify"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">T</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Tester Client for Model Context Protocol (MCP)</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Model Context Protocol (MCP) Client for Apify&#x27;s Actors</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/AI-Agent-Zxc/Study944"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">A</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">AIæ™ºèƒ½ä½“é¡¹ç›®</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">åŸºäºSpringAIæ¡†æ¶å®ç°æ¨¡å‹è°ƒç”¨ã€RAGã€ToolCallingå’ŒMCPï¼Œå®ç°ä¸€ä¸ªå¯ä»¥è§£å†³å¤æ‚é—®é¢˜ï¼Œè‡ªä¸»è°ƒç”¨å·¥å…·çš„æ™ºèƒ½ä½“</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-cli/wong2"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">mcp-cli</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">A CLI inspector for the Model Context Protocol</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/genaiscript/microsoft"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">G</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">GenAIScript</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Automatable GenAI Scripting</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-client-app/RegiByte"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">MCP Client Application</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">A mcp client chat application built for learning purposes</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/Clap-Agents/MaitreyaM"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">C</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">CLAP - Cognitive Layer Agent Package</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Powerful Asynchronous Multi agent framework built from scratch in python supporting RAG and MCP compatibilities.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/MCP_CLI_CLIENT/Fbeunder"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">MCP CLI Client</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Een lokale MCP host en client die met meerdere LLM&#x27;s en meerdere MCP servers kan werken.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/sekora-gitlab-mcp/Sekora"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">S</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Sekora GitLab MCP</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2"> Complete GitLab MCP integration with 72 specialized tools for comprehensive DevOps management</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-use/mcp-use"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">U</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Unified MCP Client Library</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">mcp-use is the easiest way to interact with mcp servers with custom agents</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/weather-tool-with-mcp/rairai77"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">R</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Requirements:</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">MCP Weather Tool</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/xhs-mcp/jobsonlook"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">å°</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">å°çº¢ä¹¦MCPæœåŠ¡</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">å°çº¢ä¹¦MCPæœåŠ¡ x-s x-t jsé€†å‘</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/slack-mcp-client/csonigo"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">S</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Slack MCP Client</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">An MCP client for slack in Typescript</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/speech-mcp/netixc"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">S</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Speech Mcp</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Speech MCP Project</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/speelka-agent/korchasa"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">S</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Speelka Agent</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Universal LLM Agent based on MCP</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/FLUJO/mario-andreschak"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">D</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">DISCLAIMER</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">MCP-Hub and -Inspector, Multi-Model Workflow and Chat Interface</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/teamspark-workbench/TeamSparkAI"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">T</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">TeamSpark AI Workbench</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">TeamSpark AI Workbench</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/Jira_mcp_streamlit/pawankumar94"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">J</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Jira Assistant with MCP Integration</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">A Streamlit-powered Jira assistant with MCP integration. Create, search, and manage Jira tickets through a clean tabbed interface using natural language commands or direct forms. Built with Python and MCP framework.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/scira-mcp-chat/zaidmukaddam"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">S</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Scira Mcp Chat</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">A minimalistic MCP client with a good feature set.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/langchaingo-mcp-adapter/i2y"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">L</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">LangChainGo MCP Adapter</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">A Go adapter that bridges LangChain Go tools with Model Context Protocol (MCP) servers.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-client-chatbot/cgoinglove"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">MCP Client Chatbot</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">ğŸš€ Open source MCP Client: A Multi-provider AI Chatbot Solution</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-chatbot/mctrinh"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">mcp-chatbot</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">MCP Chatbot powered by Anthropic Claude. Delivering onâ€demand literature search and summarisation for academics and engineers</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/agents-mcp-cloud/HiCoderMonkey"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">MCP Agents Cloud</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">MCP Agents Cloudæ˜¯ä¸€ä¸ªæä¾›ç®¡ç†MCPæœåŠ¡å™¨å’Œä»£ç†ï¼ˆAgentï¼‰çš„å¹³å°ã€‚</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/UtilityBelt/richardanaya"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">U</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">UtilityBelt</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Talk to MCP servers from aider</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-gomamayo/mizakaHK"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">mcp-gomamayo</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">MCP server for â€ã‚´ãƒãƒãƒ¨â€</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/launchbar-mcp_agent/justinhuang0208"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">MCP Agent</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">This is a LaunchBar version of Raycast&#x27;s AI extension function, which is integrated with Langchain and MCP to automatically complete tasks based on your prompt.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp_langgraph_tools/paulrobello"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">MCP Tool Langgraph Integration</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">MCP Tools Langraph Integration</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/LLaMa-MCP-Streamlit/Nikunj2003"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">L</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Llama MCP Streamlit</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">AI assistant built with Streamlit, NVIDIA NIM (LLaMa 3.3:70B) / Ollama, and Model Control Protocol (MCP).</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/langchainjs-mcp-adapters/langchain-ai"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">L</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">LangChain.js MCP Adapters</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">** THIS REPO HAS MOVED TO</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-client-langchain-ts/hideya"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">M</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">MCP Client Using LangChain / TypeScript</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Simple CLI MCP Client Implementation Using LangChain ReAct Agent / TypeScript</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/MCP_FLASK/Fbeunder"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">F</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Flask Webapplicatie met LLM-integratie en MCP-tools</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Flask webapplicatie met LLM-integratie en MCP-tools voor het verwerken van prompts via verschillende AI-modellen en contextuele tools.</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/mcp-react-dev-tools/wimpywarlord"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">B</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">BrowserTools MCP</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">MCP for React Dev Tools - Use directly inside cursor</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/figma-design-mcp/aranyak-4002"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">F</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Figma Design Automation</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Automated Figma design creation tools and plugins</p></div></a><a rel="noopener noreferrer nofollow" class="relative group flex items-start gap-4 rounded-xl border p-4 transition-colors border-gray-950/[.1] bg-gray-950/[.01] hover:bg-gray-950/[.05] dark:border-gray-50/[.1] dark:bg-gray-50/[.10] dark:hover:bg-gray-50/[.15]" href="/client/llama-server_mcp_proxy/extopico"><div class="flex-none"><span class="relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full"><span class="flex h-full w-full items-center justify-center rounded-full bg-muted">L</span></span></div><div class="min-w-0 flex-1"><div class="flex items-center gap-2"><h3 class="text-base text-sm font-semibold truncate">Llama-Server MCP Proxy</h3><div class="flex-1"></div></div><p class="mt-1 text-xs text-muted-foreground line-clamp-2">Simple node proxy for llama-server that enables MCP use</p></div></a></div><nav role="navigation" aria-label="pagination" class="mx-auto flex w-full justify-center mt-8"><ul class="flex flex-row items-center gap-1"><li class="cursor-pointer"><a class="inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 px-4 py-2 gap-1 pl-2.5 cursor-pointer" aria-label="Go to previous page"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-left h-4 w-4"><path d="m15 18-6-6 6-6"></path></svg><span>Previous</span></a></li><li class=""><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 w-10 cursor-pointer">1</a></li><li class=""><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 w-10 cursor-pointer">2</a></li><span aria-hidden="true" class="flex h-9 w-9 items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-ellipsis h-4 w-4"><circle cx="12" cy="12" r="1"></circle><circle cx="19" cy="12" r="1"></circle><circle cx="5" cy="12" r="1"></circle></svg><span class="sr-only">More pages</span></span><li class=""><a aria-current="page" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-10 w-10 cursor-pointer">6</a></li><span aria-hidden="true" class="flex h-9 w-9 items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-ellipsis h-4 w-4"><circle cx="12" cy="12" r="1"></circle><circle cx="19" cy="12" r="1"></circle><circle cx="5" cy="12" r="1"></circle></svg><span class="sr-only">More pages</span></span><li class=""><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 w-10 cursor-pointer">7</a></li><li class=""><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 w-10 cursor-pointer">8</a></li><li class="cursor-pointer"><a class="inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-hidden focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 px-4 py-2 gap-1 pr-2.5" aria-label="Go to next page"><span>Next</span><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right h-4 w-4"><path d="m9 18 6-6-6-6"></path></svg></a></li></ul></nav><!--$--><!--/$--><!--$--><!--/$--></div><div class="bg-background px-6 py-4 flex flex-col justify-between gap-4 border-t text-center text-sm font-normal text-muted-foreground lg:flex-row lg:items-center lg:text-left"><div class="flex flex-row flex-wrap items-center justify-center gap-1">Â© 2025 MCP.so. All rights reserved.<p>Sponsored by <a href="https://skywork.ai/?utm_source=mcp.so&amp;utm_medium=referral&amp;utm_campaign=202508&amp;utm_id=000001&amp;utm_term=web_footer&amp;utm_content=v2" target="_blank" rel="noopener noreferrer nofollow" class="text-[#6E29F6] underline font-medium">Skywork</a> Super Agent.</p></div><ul class="flex justify-center gap-4 lg:justify-start"><li class="hover:text-primary"><a target="_self" rel="noopener noreferrer nofollow" href="/explore">Explore</a></li><li class="hover:text-primary"><a target="_self" rel="noopener noreferrer nofollow" href="/playground">Playground</a></li><li class="hover:text-primary"><a target="_self" rel="noopener noreferrer nofollow" href="/posts">Blog</a></li><li class="hover:text-primary"><a target="_self" rel="noopener noreferrer nofollow" href="/usercases">Cases</a></li><li class="hover:text-primary"><a target="_self" rel="noopener noreferrer nofollow" href="/dxt">DXT</a></li><li class="hover:text-primary"><a target="_self" rel="noopener noreferrer nofollow" href="/partners">Partners</a></li></ul><ul class="flex justify-center gap-4 lg:justify-start"><li class="hover:text-primary"><a href="/privacy-policy" rel="noopener noreferrer nofollow">Privacy</a></li><li class="hover:text-primary"><a href="/terms-of-service" rel="noopener noreferrer nofollow">Terms</a></li></ul></div></main></div><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section><script defer="" data-domain="mcp.so" src="https://pla.trys.ai/js/script.js"></script><script src="/_next/static/chunks/webpack-1e56b3c3206210e2.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n5:I[90825,[],\"\"]\n6:I[94061,[],\"\"]\n8:I[32559,[],\"MetadataBoundary\"]\na:I[32559,[],\"OutletBoundary\"]\nd:I[12837,[],\"AsyncMetadataOutlet\"]\nf:I[32559,[],\"ViewportBoundary\"]\n11:I[64168,[],\"\"]\n12:\"$Sreact.suspense\"\n13:I[12837,[],\"AsyncMetadata\"]\n15:I[421,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"7291\",\"static/chunks/f3ac7ef3-57e0d20b76b6c0bf.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"7101\",\"static/chunks/7101-9ab34b82066b9cd8.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2919\",\"static/chunks/2919-7652e8907f6a6ad4.js\",\"7640\",\"static/chunks/7640-74d36ce7728a4200.js\",\"4091\",\"static/chunks/4091-69e125b8fd863f9f.js\",\"976\",\"static/chunks/976-8676cce570a8fe93.js\",\"4942\",\"static/chunks/4942-51fd33fb9762f202.js\",\"4359\",\"static/chunks/app/%5Blocale%5D/(home)/layout-e297fbc0fe7ac09d.js\"],\"SidebarProvider\"]\n16:I[44942,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"7291\",\"static/chunks/f3ac7ef3-57e0d20b76b6c0bf.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"7101\",\"static/chunks/7101-9ab34b82066b9cd8.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2919\",\"static/chunks/2919-7652e8907f6a6ad4.js\",\"7640\",\"static/chunks/7640-74d36ce7728a4200.js\",\"4091\",\"static/chunks/4091-69e125b8fd863f9f.js\",\"976\",\"static/chunks/976-8676cce570a8fe93.js\",\"4942\",\"static/chunks/4942-51fd33fb9762f202.js\",\"4359\",\"static/chunks/app/%5Blocale%5D/(home)/layout-e297fbc0fe7ac09d.js\"],\"default\"]\n17:I[421,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"7291\",\"static/chunks/f3ac7ef3-57e0d20b76b6c0bf.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"7101\",\"static/chunks/7101-9ab34b82066b9cd8.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2919\",\"static/chunks/2919-7652e8907f6a6ad4.js\",\"7640\",\"static/chunks/7640-74d36ce7728a4200.js\",\"4091\",\"static/chunks/4091-69e125b8fd863f9f.js\",\"976\",\"static/chunks/976-8676cce570a8fe93.js\",\"4942\",\"static/chunks/4942-51fd33fb9762f202.js\",\"4359\",\"static/chunks/app/%5Blocale%5D/(home)/layout-e297fbc0fe7ac09d.js\"],\"SidebarInset\"]\n18:I[88430,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"9175\",\"static/chunks/1866796a-670a712d9364e62c.js\",\"7291\",\"static/chunks/f3ac7ef3-57e0d20b76b6c0bf.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"7101\",\"static/chunks/7101-9ab34b82066b9cd8.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2919\",\"static/chunks/2919-7652e8907f6a6ad4.js\",\"6541\",\"static/chunks/6541-2f0250d6a0967fe4.js\",\"7640\",\"static/chunks/7640-74d36ce7728a4200.js\",\"4091\",\"static/chunks/4091-69e125b8fd863f9f.js\",\"976\",\"static/chunks/976-8676cce570a8fe93.js\",\"4942\",\"static/chunks/4942-51fd33fb9762f202.js\",\"3425\",\"static/chunks/app/%5Blocale%5D/(default)/layout-681f37f67bcbff3e.js\"],\"TopBanner\"]\n19:I[37484,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"9175\",\"static/chunks/1866796a-670a712d9364e62c.js\",\"7291\",\"static/chunks/f3ac7ef3-57e0d20b76b6c0bf.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\""])</script><script>self.__next_f.push([1,"static/chunks/236-f8f5e32bce4e096f.js\",\"7101\",\"static/chunks/7101-9ab34b82066b9cd8.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2919\",\"static/chunks/2919-7652e8907f6a6ad4.js\",\"6541\",\"static/chunks/6541-2f0250d6a0967fe4.js\",\"7640\",\"static/chunks/7640-74d36ce7728a4200.js\",\"4091\",\"static/chunks/4091-69e125b8fd863f9f.js\",\"976\",\"static/chunks/976-8676cce570a8fe93.js\",\"4942\",\"static/chunks/4942-51fd33fb9762f202.js\",\"3425\",\"static/chunks/app/%5Blocale%5D/(default)/layout-681f37f67bcbff3e.js\"],\"Header\"]\n20:I[16296,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"9732\",\"static/chunks/9732-8158987224fdfa35.js\",\"1358\",\"static/chunks/1358-a345831bbdffdf07.js\",\"1013\",\"static/chunks/app/%5Blocale%5D/(default)/clients/page-5664c6f855076eab.js\"],\"default\"]\n21:I[31096,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"9175\",\"static/chunks/1866796a-670a712d9364e62c.js\",\"7291\",\"static/chunks/f3ac7ef3-57e0d20b76b6c0bf.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"7101\",\"static/chunks/7101-9ab34b82066b9cd8.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2919\",\"static/chunks/2919-7652e8907f6a6ad4.js\",\"6541\",\"static/chunks/6541-2f0250d6a0967fe4.js\",\"7640\",\"static/chunks/7640-74d36ce7728a4200.js\",\"4091\",\"static/chunks/4091-69e125b8fd863f9f.js\",\"976\",\"static/chunks/976-8676cce570a8fe93.js\",\"4942\",\"static/chunks/4942-51fd33fb9762f202.js\",\"3425\",\"static/chunks/app/%5Blocale%5D/(default)/layout-681f37f67bcbff3e.js\"],\"default\"]\n22:I[76550,[\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"3960\",\"static/chunks/4b7059ae-76f7529d720584f8.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"4902\",\"static/chunks/4902-f1919cf5204afe9f.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2407\",\"static/chunks/2407-4b5edf4e84c5d717.js\",\"8450\",\"static/chunks/app/%5Blocale%5D/layout-2c849eca4082e774.js\"],\"NextAuthSessionProvider\"]\n23:I[44777,[\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"3960\",\"static/chunks/4b7059ae-76f7529d720584f8.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"4902\",\"static/chunks/4902-f1919cf5204afe9f.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2407\",\"static/chunks/2407-4b5edf4e84c5d717.js\",\"8450\",\"static/chunks/app/%5Blocale%5D/layout-2c849eca4082e774.js\"],\"AppContextProvider\"]\n24:I[84369,[\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"3960\",\"static/chunks/4b7059ae-76f7529d720584f8.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"4902\",\"static/chunks/4902-f1919cf5204afe9f.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2407\",\"static/chunks/2407-4b5edf4e84c5d717.js\",\"8450\",\"static/chunks/app/%5Blocale%5D/layout-2c849eca4082e774.js\"],\"ChatContextProvider\"]\n25:I[89735,[\"8548\",\"static/chunks/b27dc69b-e5acb70cd9d66ddf.js\",\"3960\",\"static/chunks/4b7059ae-76f7529d720584f8.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"4902\",\"static/chunks/4902-f1919cf5204afe9f.js\",\"1508\",\"static/chunks/1508-abbc58115cbb4fd0.js\",\"236\",\"static/chunks/236-f8f5e32bce4e096f.js\",\"6125\",\"static/chunks/6125-6f7cbc86df4f2503.js\",\"2407\",\"static/chunks/2407-4b5edf4e84c5d717.js\",\"8450\",\"static/chunks/app/%5Blocale%5D/layout-2c849eca4082e774.js\"],\"ThemeProvider\"]\n:HL[\"/_next/static/css/66449ed0e802001c.css\",\"style\"]\n0:{\"P\":null,\"b\":\"VHjKmOxKOsloonDc-p1aa\",\"p\":"])</script><script>self.__next_f.push([1,"\"\",\"c\":[\"\",\"en\",\"clients?page=6\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"locale\",\"en\",\"d\"],{\"children\":[\"(default)\",{\"children\":[\"clients\",{\"children\":[\"__PAGE__?{\\\"page\\\":\\\"6\\\"}\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/66449ed0e802001c.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],\"$L2\"]}],{\"children\":[[\"locale\",\"en\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,\"$L3\"]}],{\"children\":[\"(default)\",[\"$\",\"$1\",\"c\",{\"children\":[null,\"$L4\"]}],{\"children\":[\"clients\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L7\",[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],null,[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"TGXACt-RVQPqKvJRfr0TH\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":false}\n9:[\"$\",\"$12\",null,{\"fallback\":null,\"children\":[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]}]\n2:[\"$\",\"html\",null,{\"lang\":\"$undefined\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"alternate\",\"hrefLang\":\"en\",\"href\":\"https://mcp.so\"}],[\"$\",\"link\",null,{\"rel\":\"alternate\",\"hrefLang\":\"zh\",\"href\":\"https://mcp.so/zh/\"}],[\"$\",\"link\",null,{\"rel\":\"alternate\",\"hrefLang\":\"ja\",\"href\":\"https://mcp.so/ja/\"}],[\"$\",\"link\",null,{\"rel\":\"alternate\",\"hrefLang\":\"x-default\",\"href\":\"https://mcp.so\"}],[\"$\",\"meta\",null,{\"name\":\"google-adsense-account\",\"content\":\"ca-pub-2123767634383915\"}]]}],[\"$\",\"body\",null,{\"className\":\"min-h-screen bg-background antialiased overflow-x-hidden\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}]\nc:null\n4:[\"$\",\"$L15\",null,{\"children\":[[\"$\",\"$L16\",null,{\"variant\":\"floating\",\"sidebar\":{\"brand\":{\"title\":\"MCP.so\",\"logo\":{\"src\":\"/logo.png\",\"alt\":\"MCP.so\"},\"url\":\"/\"},\"nav\":{\"items\":[{\"title\":\"Home\",\"url\":\"/\",\"icon\":\"RiHomeLine\"},{\"title\":\"Servers\",\"url\":\"/servers?tag=featured\",\"icon\":\"RiServerLine\"},{\"title\":\"Clients\",\"url\":\"/clients?tag=featured\",\"icon\":\"RiAppsLine\"},{\"title\":\"Categories\",\"url\":\"/categories\",\"ico"])</script><script>self.__next_f.push([1,"n\":\"RiMenu2Fill\"},{\"title\":\"Tags\",\"url\":\"/tags\",\"icon\":\"RiHashtag\"},{\"title\":\"Feed\",\"url\":\"/feed\",\"icon\":\"RiWechatLine\"}]},\"bottomNav\":{\"items\":[{\"title\":\"Settings\",\"url\":\"/my-servers\",\"icon\":\"RiSettingsLine\",\"target\":\"_self\"}]},\"social\":{\"items\":[{\"title\":\"X\",\"icon\":\"RiTwitterXFill\",\"url\":\"https://x.com/chatmcp\",\"target\":\"_blank\"},{\"title\":\"Github\",\"icon\":\"RiGithubFill\",\"url\":\"https://github.com/chatmcp/mcpso/issues\",\"target\":\"_blank\"},{\"title\":\"Discord\",\"icon\":\"RiDiscordFill\",\"url\":\"https://discord.gg/RsYPRrnyqg\",\"target\":\"_blank\"},{\"title\":\"Email\",\"icon\":\"RiMailLine\",\"url\":\"mailto:support@mcp.so\",\"target\":\"_self\"}]},\"collapsible\":\"offcanvas\",\"variant\":\"floating\"}}],[\"$\",\"$L17\",null,{\"children\":[[\"$\",\"$L18\",null,{\"message\":\"Skywork: All-in-one Super Agent.\",\"highlight\":\"Skywork\",\"link\":{\"text\":\"Learn more\",\"href\":\"https://skywork.ai?utm_source=mcp.so\u0026utm_medium=referral\u0026utm_campaign=202508\u0026utm_id=000001\u0026utm_term=web_banner\u0026utm_content=v2\",\"target\":\"_blank\"}}],[\"$\",\"$L19\",null,{\"nav\":{\"items\":[]}}],[\"$\",\"div\",null,{\"className\":\"flex-1 px-4 md:px-6 pb-16 pt-4\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"div\",null,{\"className\":\"bg-background px-6 py-4 flex flex-col justify-between gap-4 border-t text-center text-sm font-normal text-muted-foreground lg:flex-row lg:items-center lg:text-left\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-row flex-wrap items-center justify-center gap-1\",\"children\":[\"Â© 2025 MCP.so. All rights reserved.\",[\"$\",\"p\",null,{\"children\":[\"Sponsored by \",[\"$\",\"a\",null,{\"href\":\"https://skywork.ai/?utm_source=mcp.so\u0026utm_medium=referral\u0026utm_campaign=202508\u0026utm_id=000001\u0026utm_term=web_footer\u0026utm_content=v2\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer nofollow\",\"className\":\"text-[#6E29F6] underline font-medium\",\"children\":\"Skywork\"}],\" Super Agent.\"]}]]}],[\"$\",\"ul\",null,{\"className\":\"flex justify-center gap-4 lg:justify-start\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"hover:text-primary\",\"children\":\"$L1a\"}],[\"$\",\"li\",\"1\",{\"className\":\"hover:text-primary\",\"children\":\"$L1b\"}],[\"$\",\"li\",\"2\",{\"className\":\"hover:text-primary\",\"children\":\"$L1c\"}],[\"$\",\"li\",\"3\",{\"className\":\"hover:text-primary\",\"children\":\"$L1d\"}],[\"$\",\"li\",\"4\",{\"className\":\"hover:text-primary\",\"children\":\"$L1e\"}],[\"$\",\"li\",\"5\",{\"className\":\"hover:text-primary\",\"children\":\"$L1f\"}]]}],[\"$\",\"ul\",null,{\"className\":\"flex justify-center gap-4 lg:justify-start\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"hover:text-primary\",\"children\":[\"$\",\"a\",null,{\"href\":\"/privacy-policy\",\"target\":\"$undefined\",\"rel\":\"noopener noreferrer nofollow\",\"children\":\"Privacy\"}]}],[\"$\",\"li\",\"1\",{\"className\":\"hover:text-primary\",\"children\":[\"$\",\"a\",null,{\"href\":\"/terms-of-service\",\"target\":\"$undefined\",\"rel\":\"noopener noreferrer nofollow\",\"children\":\"Terms\"}]}]]}]]}]]}]]}]\n1a:[\"$\",\"$L20\",null,{\"ref\":\"$undefined\",\"href\":\"/explore\",\"locale\":\"$undefined\",\"localeCookie\":{\"name\":\"NEXT_LOCALE\",\"sameSite\":\"lax\"},\"target\":\"_self\",\"rel\":\"noopener noreferrer nofollow\",\"children\":\"Explore\"}]\n1b:[\"$\",\"$L20\",null,{\"ref\":\"$undefined\",\"href\":\"/playground\",\"locale\":\"$undefined\",\"localeCookie\":\"$1a:props:localeCookie\",\"target\":\"_self\",\"rel\":\"noopener noreferrer nofollow\",\"children\":\"Playground\"}]\n1c:[\"$\",\"$L20\",null,{\"ref\":\"$undefined\",\"href\":\"/posts\",\"locale\":\"$undefined\",\"localeCookie\":\"$1a:props:localeCookie\",\"target\":\"_self\",\"rel\":\"noopener noreferrer nofollow\",\"children\":\"Blog\"}]\n1d:[\"$\",\"$L20\",null,{\"ref\":\"$undefined\",\"href\":\"/usercases\",\"locale\":\"$undefined\",\"localeCookie\":\"$1a:props:localeCookie\",\"target\":\"_self\",\"rel\":\"noopener noreferrer nofollow\",\"children\":\"Cases\"}]\n1e:[\"$\",\"$L20\",null,{\"ref\":\"$undefined\",\"href\":\"/dxt\",\"locale\":\"$undefined\",\"localeCookie\":\"$1a:props:localeCookie\",\"target\":\"_self\",\"rel\":\"noopener noreferrer nofollow\",\"children\":\"DXT\"}]\n1f:[\"$\",\"$L20\",null,{\"ref\":\"$undefined\",\"href\":\"/partners\",\"locale\""])</script><script>self.__next_f.push([1,":\"$undefined\",\"localeCookie\":\"$1a:props:localeCookie\",\"target\":\"_self\",\"rel\":\"noopener noreferrer nofollow\",\"children\":\"Partners\"}]\n3:[\"$\",\"$L21\",null,{\"formats\":\"$undefined\",\"locale\":\"en\",\"messages\":{\"metadata\":{\"title\":\"MCP Servers\",\"description\":\"The largest collection of MCP Servers, including Awesome MCP Servers and Claude MCP integration. Search and discover MCP servers to enhance your AI capabilities.\",\"keywords\":\"MCP Servers, Awesome MCP Servers, Claude MCP, Model Context Protocol\"},\"user\":{\"sign_in\":\"Sign In\",\"sign_out\":\"Sign Out\",\"credits\":\"Credits\",\"api_keys\":\"API Keys\",\"my_orders\":\"My Orders\",\"user_center\":\"User Center\",\"admin_system\":\"Admin System\",\"my_servers\":\"My Servers\",\"my_clients\":\"My Clients\"},\"sign_modal\":{\"sign_in_title\":\"Sign In\",\"sign_in_description\":\"Sign in to your account\",\"sign_up_title\":\"Sign Up\",\"sign_up_description\":\"Create an account\",\"email_title\":\"Email\",\"email_placeholder\":\"Input your email here\",\"password_title\":\"Password\",\"password_placeholder\":\"Input your password here\",\"forgot_password\":\"Forgot password?\",\"or\":\"Or\",\"continue\":\"Continue\",\"no_account\":\"Don't have an account?\",\"email_sign_in\":\"Sign in with Email\",\"google_sign_in\":\"Sign in with Google\",\"github_sign_in\":\"Sign in with GitHub\",\"close_title\":\"Close\",\"cancel_title\":\"Cancel\"},\"my_orders\":{\"title\":\"My Orders\",\"description\":\"orders paid with ShipAny.\",\"no_orders\":\"No orders found\",\"tip\":\"\",\"activate_order\":\"Activate Order\",\"actived\":\"Activated\",\"join_discord\":\"Join Discord\",\"read_docs\":\"Read Docs\",\"table\":{\"order_no\":\"Order No\",\"email\":\"Email\",\"product_name\":\"Product Name\",\"amount\":\"Amount\",\"paid_at\":\"Paid At\",\"github_username\":\"GitHub Username\",\"status\":\"Status\"}},\"my_credits\":{\"title\":\"My Credits\",\"left_tip\":\"left credits: {left_credits}\",\"no_credits\":\"No credits records\",\"recharge\":\"Recharge\",\"table\":{\"trans_no\":\"Trans No\",\"trans_type\":\"Trans Type\",\"credits\":\"Credits\",\"updated_at\":\"Updated At\",\"status\":\"Status\"}},\"api_keys\":{\"title\":\"API Keys\",\"tip\":\"Please keep your apikey safe to avoid leaks\",\"no_api_keys\":\"No API Keys\",\"create_api_key\":\"Create API Key\",\"table\":{\"name\":\"Name\",\"key\":\"Key\",\"created_at\":\"Created At\"},\"form\":{\"name\":\"Name\",\"name_placeholder\":\"API Key Name\",\"submit\":\"Submit\"}},\"blog\":{\"title\":\"Blog\",\"description\":\"News, resources, and updates about MCP Servers\",\"read_more_text\":\"Read More\"},\"my_invites\":{\"title\":\"My Invites\",\"description\":\"View your invite records\",\"no_invites\":\"No invite records found\",\"my_invite_link\":\"My Invite Link\",\"edit_invite_link\":\"Edit Invite Link\",\"copy_invite_link\":\"Copy Invite Link\",\"invite_code\":\"Invite Code\",\"invite_tip\":\"Invite 1 friend to buy ShipAny, reward $50.\",\"invite_balance\":\"Invite Reward Balance\",\"total_invite_count\":\"Total Invite Count\",\"total_paid_count\":\"Total Paid Count\",\"total_award_amount\":\"Total Award Amount\",\"update_invite_code\":\"Set Invite Code\",\"update_invite_code_tip\":\"Input your custom invite code\",\"update_invite_button\":\"Save\",\"no_orders\":\"You can't invite others before you bought ShipAny\",\"no_affiliates\":\"You're not allowed to invite others, please contact us to apply for permission.\",\"table\":{\"invite_time\":\"Invite Time\",\"invite_user\":\"Invite User\",\"status\":\"Status\",\"reward_percent\":\"Reward Percent\",\"reward_amount\":\"Reward Amount\",\"pending\":\"Pending\",\"completed\":\"Completed\"}},\"my_servers\":{\"title\":\"My Servers\",\"submit_server\":\"Submit Server\",\"edit_server\":\"Edit Server\",\"table\":{\"avatar\":\"Avatar\",\"name\":\"Name\",\"title\":\"Title\",\"description\":\"Description\",\"status\":\"Status\",\"created_at\":\"Created At\",\"empty_message\":\"No servers\",\"edit\":\"Edit\",\"view\":\"View\",\"url\":\"Github URL\",\"avatar_url\":\"Avatar URL\",\"author_name\":\"Author Name\",\"server_config\":\"Server Config\",\"overview\":\"Overview\",\"content\":\"Content\",\"tags\":\"Tags\",\"category\":\"Category\",\"type\":\"Type\"}},\"mcp\":{\"index_label\":\"Indexed\",\"search_placeholder\":\"Search with keywords\",\"featured_servers\":\"Featured MCP Servers\",\"official_servers\":\"Official MCP Servers\",\"featured_clients\":\"Featured MCP Clients\",\"official_clients\":\"Official MCP Clients\",\"latest_servers\":\"Latest MCP Servers\",\"latest_clients\":\"Latest MCP Client"])</script><script>self.__next_f.push([1,"s\",\"hosted_servers\":\"Hosted MCP Servers\",\"innovation_projects\":\"Innovation Projects\",\"view_all\":\"View All\",\"tabs\":{\"all\":\"All\",\"hosted\":\"Hosted\",\"official\":\"Official\",\"clients\":\"Clients\",\"servers\":\"Servers\",\"categories\":\"Categories\",\"tags\":\"Tags\",\"featured\":\"Featured\",\"latest\":\"Latest\",\"today\":\"Today\",\"random\":\"Random\",\"sponsors\":\"Sponsors\",\"innovation\":\"Innovations\"}},\"usercases\":{\"title\":\"MCP Server Use Cases\",\"description\":\"How to use MCP Servers with creative ways.\"},\"feed\":{\"title\":\"Feed\",\"description\":\"Recent MCP Servers and Clients submitted by users\",\"sub_title\":\"Recent Submissions\",\"submit_my_server\":\"Submit My Server\",\"submitted_at\":\"Submit\",\"created_by\":\"Created By\",\"latest\":\"Latest\",\"comments\":\"Comments\",\"all\":\"All\",\"clients\":\"Clients\",\"servers\":\"Servers\"},\"explore\":{\"title\":\"Explore MCP Servers and Clients\",\"highlight_text\":\"MCP Servers\",\"description\":\"What are you looking for?\",\"trending\":\"Trending\",\"categories\":\"Categories\",\"mcp_servers_title\":\"MCP Servers\",\"mcp_servers_description\":\"Find the best MCP Servers for your needs.\",\"mcp_clients_title\":\"MCP Clients\",\"mcp_clients_description\":\"Find the best MCP Clients for your needs.\",\"nav\":{\"all\":\"All\",\"hosting_servers\":\"Hosting Servers\",\"official_servers\":\"Official Servers\",\"featured_servers\":\"Featured Servers\",\"latest_servers\":\"Latest Servers\",\"featured_clients\":\"Featured Clients\",\"official_clients\":\"Official Clients\",\"latest_clients\":\"Latest Clients\",\"all_servers\":\"All Servers\",\"all_clients\":\"All Clients\",\"innovation_projects\":\"Innovation Projects\"}},\"categories\":{\"title\":\"Categories\",\"description\":\"A list of categories for MCP Servers and Clients.\",\"crumb\":{\"home\":\"Home\",\"categories\":\"Categories\"},\"tabs\":{\"all\":\"All\",\"servers\":\"Servers\",\"clients\":\"Clients\"},\"results\":\"{count} results found\"},\"submit\":{\"title\":\"Submit MCP Server or Client\",\"description\":\"hunt awesome MCP servers or clients, share with the community.\",\"form\":{\"name\":\"Name\",\"name_placeholder\":\"Input the name of the MCP server or client\",\"type\":\"Type\",\"type_placeholder\":\"Select the type of MCP server or client\",\"url\":\"URL\",\"url_placeholder\":\"Input the URL of the MCP server or client\",\"server_config\":\"Server Config\",\"submitting\":\"Submitting...\",\"submit\":\"Submit\",\"hosting_on_cloud\":\"Host your server on cloud ğŸ‘‰\",\"is_innovation\":\"Innovation\",\"innovation_tip\":\"World First MCP Innovation ChallengeğŸ‘‰\",\"is_dxt\":\"Is DXT\",\"is_dxt_tip\":\"Desktop Extensions: One-click local MCP server installation in desktop apps\"}},\"project\":{\"created_at\":\"Created At\",\"created_by\":\"Created By\",\"recommend_servers\":\"Recommend Servers\",\"recommend_clients\":\"Recommend Clients\",\"vist_server\":\"Visit Server\",\"vist_client\":\"Visit Client\",\"connect_server\":\"Connect Server\",\"connected\":\"Server Connected\",\"connect_with_sse_url\":\"Connect Server with SSE URL\",\"available_clients\":\"Available Clients\",\"sse_tip\":\"SSE Connect is unstable for connection, please use Stdio or Streamable HTTP to connect server.\",\"try_in_playground\":\"Try in Playground\",\"server_config\":\"Server Config\",\"list_tools\":\"List Tools\",\"loading\":\"Loading...\",\"crumb\":{\"home\":\"Home\",\"server\":\"Servers\",\"client\":\"Clients\"},\"tab\":{\"overview\":\"Overview\",\"content\":\"Content\",\"config\":\"Config\",\"tools\":\"Tools\",\"comments\":\"Comments\",\"chat\":\"Chat\",\"not_configured\":\"Not configured\",\"run\":\"Run\",\"loading\":\"Loading...\",\"connecting\":\"Connecting...\",\"connect\":\"Connect\",\"reconnect\":\"Reconnect\",\"running\":\"Running...\"},\"search_results\":\"Search Results\",\"no_results\":\"No results found\"},\"playground\":{\"title\":\"MCP Server Playground\",\"description\":\"Calling MCP Server Tools online\",\"edit\":\"Edit\",\"reconnect\":\"Reconnect\",\"select_server\":\"Select MCP Server\",\"tools\":\"Tools\",\"call_tool\":\"Call Tool\",\"result\":\"Result\",\"server_not_connected\":\"Server not connected\",\"loading\":\"Loading...\"},\"ranking\":{\"title\":\"Call Ranking\",\"description\":\"Top MCP Servers and Clients ranked by calls\",\"sub_title\":\"Ranking\",\"clients\":\"Clients\",\"servers\":\"Servers\",\"today\":\"Today\",\"this_week\":\"This Week\",\"this_month\":\"This Month\",\"this_year\":\"This Year\",\"calls\":\"Calls\",\"loading\":\"Loading...\"},\"project_info\":{\"title\":\"Project In"])</script><script>self.__next_f.push([1,"fo\",\"featured\":\"Featured\",\"hosted\":\"Hosted\",\"official\":\"Official\",\"remote\":\"Remote\",\"created_at\":\"Created At\",\"updated_at\":\"Updated At\",\"author_name\":\"Author Name\",\"star\":\"Star\",\"language\":\"Language\",\"license\":\"License\",\"category\":\"Category\",\"tags\":\"Tags\",\"homepage\":\"Homepage\",\"source_code\":\"Source Code\",\"update\":\"Update\",\"claim\":\"Claim\",\"report\":\"Report\"},\"nav\":{\"home\":\"Home\",\"explore\":\"Explore\",\"servers\":\"Servers\",\"clients\":\"Clients\",\"feed\":\"Feed\",\"submit\":\"Submit\",\"settings\":\"Settings\",\"chat\":\"Chat\",\"usercases\":\"Cases\",\"playground\":\"Playground\",\"categories\":\"Categories\",\"tags\":\"Tags\",\"blog\":\"Blog\",\"dxt\":\"DXT\",\"partners\":\"Partners\"},\"tags\":{\"title\":\"Tags\",\"description\":\"A list of tags for MCP Servers and Clients.\",\"tabs\":{\"all\":\"All\"},\"results\":\"{count} results found\"},\"clients\":{\"title\":\"MCP Clients\",\"description\":\"A list of MCP Clients.\",\"nav\":{\"all\":\"All\",\"featured\":\"Featured\",\"latest\":\"Latest\"}},\"servers\":{\"title\":\"MCP Servers\",\"description\":\"A list of MCP Servers.\",\"nav\":{\"all\":\"All\",\"featured\":\"Featured\",\"latest\":\"Latest\"}},\"community\":{\"title\":\"Community\",\"description\":\"Meet MCP Lovers here\",\"tabs\":{\"latest\":\"Latest\",\"hot\":\"Hot\"},\"new_topic\":\"New Topic\"},\"dxt\":{\"title\":\"DXT\",\"description\":\"Desktop Extensions: One-click local MCP server installation in desktop apps\",\"tabs\":{\"all\":\"All\"}},\"partners\":{\"title\":\"Partners\",\"description\":\"Trusted Partnerships\"}},\"now\":\"$undefined\",\"timeZone\":\"UTC\",\"children\":[\"$\",\"$L22\",null,{\"children\":[\"$\",\"$L23\",null,{\"children\":[\"$\",\"$L24\",null,{\"children\":[\"$\",\"$L25\",null,{\"attribute\":\"class\",\"disableTransitionOnChange\":true,\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]}]}]}]\n10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n14:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"MCP Clients\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Find the best MCP Clients for your needs.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"keywords\",\"content\":\"MCP Servers, Awesome MCP Servers, Claude MCP, Model Context Protocol\"}],[\"$\",\"link\",\"3\",{\"rel\":\"canonical\",\"href\":\"https://mcp.so/clients\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"MCP Servers\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"The largest collection of MCP Servers, including Awesome MCP Servers and Claude MCP integration. Search and discover MCP servers to enhance your AI capabilities.\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:url\",\"content\":\"https://mcp.so\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:site_name\",\"content\":\"MCP.so\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:locale\",\"content\":\"en\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image\",\"content\":\"https://mcp.so/logo.png\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:site\",\"content\":\"MCP.so\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:title\",\"content\":\"MCP Servers\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:description\",\"content\":\"The largest collection of MCP Servers, including Awesome MCP Servers and Claude MCP integration. Search and discover MCP servers to enhance your AI capabilities.\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:image\",\"content\":\"https://mcp.so/logo.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\ne:{\"metadata\":\"$14:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n26:I[66774,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"9732\",\"static/chunks/9732-8158987224fdfa35.js\",\"1358\",\"static/chunks/1358-a345831bbdffdf07.js\",\"1013\",\"static/chunks/app/%5Blocale%5D/(default)/clients/page-5664c6f8550"])</script><script>self.__next_f.push([1,"76eab.js\"],\"PageTitleTabs\"]\n27:I[85939,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"9732\",\"static/chunks/9732-8158987224fdfa35.js\",\"1358\",\"static/chunks/1358-a345831bbdffdf07.js\",\"1013\",\"static/chunks/app/%5Blocale%5D/(default)/clients/page-5664c6f855076eab.js\"],\"default\"]\n72:I[41664,[\"7626\",\"static/chunks/f6ab4fea-4425dae3da7674a3.js\",\"5232\",\"static/chunks/5232-db5923cda78a4960.js\",\"6465\",\"static/chunks/6465-524ff7a6f6bb774c.js\",\"9388\",\"static/chunks/9388-d1a745fd53a10850.js\",\"9732\",\"static/chunks/9732-8158987224fdfa35.js\",\"1358\",\"static/chunks/1358-a345831bbdffdf07.js\",\"1013\",\"static/chunks/app/%5Blocale%5D/(default)/clients/page-5664c6f855076eab.js\"],\"Pagination\"]\n28:T26ec,# CarrotAI\n\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"public/icon.png\" alt=\"CarrotAI Logo\" width=\"200\"/\u003e\n  \u003ch3\u003eAI Agent with Multi-Server Streaming \u0026 Multi-Language Support\u003c/h3\u003e\n  \u003cp\u003eFlutter Frontend + FastAPI Backend\u003c/p\u003e\n\u003c/div\u003e\n\n\u003cp align=\"center\"\u003e\n  ğŸš€ \u003ca href=\"https://chat.jintongshu.com/\"\u003eExperience online now\u003c/a\u003e  |  \u003ca href=\"https://jintongshu.com/download/\"\u003eSaaS Client download\u003c/a\u003e\n\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n  ğŸ‡¨ğŸ‡³ \u003ca href=\"README_zh.md\"\u003eé˜…è¯»ä¸­æ–‡æ–‡æ¡£\u003c/a\u003e\n\u003c/p\u003e\n\n---\n\n## ğŸ¥• Introduction\n\nCarrotAI is a cutting-edge AI agent application that delivers real-time streaming chat via Server-Sent Events (SSE) and streamable HTTP with built-in Model Control Protocol (MCP) integration. It supports concurrent connections to multiple SSE MCP servers and provides user interfaces in English, Chinese, and Japanese.\n\n## ğŸš€ Features\n\n- **AI Agent**: Real-time chat powered by SSE and MCP adapters for a seamless conversational experience.\n- **Multi-Server Support**: Connect to and call multiple SSE MCP servers simultaneously to aggregate intelligent responses.\n- **Multi-Language**: Full localization in English, ä¸­æ–‡ (Chinese), and æ—¥æœ¬èª (Japanese).\n- **Deep Thinking Mode**: Advanced analysis for complex or multi-step queries.\n- **Authentication**: Secure login/register flow using JWT tokens.\n- **Responsive UI**: Adaptive design for mobile, desktop, and web platforms.\n- **Theme Customization**: Light/dark mode, custom seed colors, and dynamic Material 3 theming via `dynamic_color`.\n- **File Upload**: Attach and parse files within conversations for richer context.\n\n## ğŸ¤– Supported Model APIs\n\n- **DeepSeek**: Advanced language model with strong reasoning capabilities\n\n## ğŸ› ï¸ Tech Stack\n\n### Frontend\n- **Framework**: Flutter\n- **State Management**: Provider\n- **UI**: Material Design 3\n- **Localization**: flutter gen-l10n\n- **Theming**: dynamic_color\n\n### Backend\n- **Framework**: FastAPI\n- **Streaming**: Server-Sent Events (SSE)\n- **AI Integration**: DeepSeek LLM, MCP (Model Control Protocol)\n- **Database**: PostgreSQL + SQLAlchemy\n- **Authentication**: JSON Web Tokens\n- **Migrations**: Alembic\n- **Deployment**: Uvicorn \u0026 Gunicorn\n\n## ğŸ“‹ Prerequisites\n\n- Flutter SDK ^3.7.2\n- Python \u003e=3.12\n- PostgreSQL\n\n## âš¡ Quick Start\n\n\u003e Please make sure that it has been installed. [uv](https://docs.astral.sh/uv/getting-started/installation/)\n\n```bash\n# Clone repository\ngit clone https://github.com/Xingsandesu/CarrotAI.git \u0026\u0026 cd CarrotAI\n\n# Deal with environment variables\nmv backend/.env.example backend/.env \u0026\u0026 mv .env.example .env\n\n# Edit environment variables\nvim .env\nvim backend/.env\n\n# Temporarily start PostgreSQL\ndocker-compose -f docker-compose.yml -f docker-compose.override.yml up -d postgres\n\n# Backend setup\nuv run backend/scripts/startup.py --user --email \u003cemail\u003e --username \u003cname\u003e --password \u003cpassword\u003e\n\n# Stop PostgreSQL\ndocker-compose -f docker-compose.yml -f docker-compose.override.yml down\n\n# Deal with Config\nvim config/\n\n# Run Backend\ndocker compose up -d\n\n```\n\n## ğŸ”§ Installation\n\n### Backend Setup\n\n1. Navigate to the backend directory:\n   ```bash\n   cd backend\n   ```\n2. Create and activate a virtual environment:\n   ```bash\n   uv sync\n   ```\n3. Copy the example environment file:\n   ```bash\n   cp .env."])</script><script>self.__next_f.push([1,"example .env\n   ```\n4. Apply database migrations:\n   ```bash\n   uv run scripts/init_db.py \u0026\u0026 uv run scripts/init_config.py\n   ```\n6. Run the server:\n   ```bash\n   python main.py       # Development mode\n   python main.py prod  # Production mode with Gunicorn\n   ```\n\n### Frontend Setup\n\n1. Return to the project root:\n   ```bash\n   cd ..\n   ```\n2. Fetch Flutter dependencies:\n   ```bash\n   flutter pub get\n   ```\n3. Generate localization files:\n   ```bash\n   flutter gen-l10n\n   ```\n4. Launch the app:\n   ```bash\n   flutter run\n   ```\n5. Build for web:\n   ```bash\n   flutter build web --wasm\n   ```\n\n## ğŸŒ Configuration\n\n- **Frontend**: Edit `lib/core/config/app_config.dart` for API endpoints and theming defaults.\n- **Backend**: Configure `.env` and `backend/app/core/config.py` for database, and MCP servers.\n\n### Backend Configuration Files\n\nThe backend uses JSON files located in `backend/config/` to define models, MCP servers, and custom adapters. Below is the default folder structure:\n\n```text\nbackend/config/\nâ”œâ”€â”€ model_configs.json       # LLM model definitions and metadata\nâ”œâ”€â”€ mcp_servers.json         # SSE MCP server endpoints and env settings\nâ””â”€â”€ app/                     # Custom adapter definitions\n    â””â”€â”€ duckduckgo-search.json\n```\n\n#### model_configs.json\n\nDefines available LLM models for CarrotAI. Each entry includes:\n- `id` (string): Unique model identifier.\n- `icon` (string): Icon name for display.\n- `translations` (object): Localized names and descriptions (`zh`, `en`, `ja`).\n- `exclusiveRules` (object): Toggles and exclusion rules for features.\n\nExample:\n```json\n[\n  {\n    \"id\": \"deepseek\",\n    \"icon\": \"smart_toy_outlined\",\n    \"translations\": {\n      \"zh\": { \"name\": \"DeepSeek\", \"description\": \"ä¸“æ³¨äºæ·±åº¦æ€è€ƒå’Œå¤æ‚æ¨ç†çš„æ»¡è¡€æ¨¡å‹\" },\n      \"en\": { \"name\": \"DeepSeek\", \"description\": \"Powerful Chinese large model focused on deep thinking and complex reasoning\" },\n      \"ja\": { \"name\": \"DeepSeek\", \"description\": \"æ·±ã„æ€è€ƒã¨è¤‡é›‘ãªæ¨è«–ã«ç‰¹åŒ–ã—ãŸå¼·åŠ›ãªä¸­å›½èªå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«\" }\n    },\n    \"exclusiveRules\": {\n      \"deepThinking\": { \"enabled\": true, \"excludes\": [\"mcpServices\"] },\n      \"mcpServices\": { \"enabled\": true, \"excludes\": [\"deepThinking\"] }\n    }\n  }\n]\n```\n\n#### mcp_servers.json\n\nSpecifies SSE Model Control Protocol (MCP) endpoints. Format:\n- Keys: service names.\n- `url` (string): SSE endpoint URL.\n- `env` (object): Environment variables for the adapter.\n\nExample:\n```json\n{\n  \"serviceA\": {\n    \"url\": \"http://localhost:10000/sse\",\n    \"env\": {\n      \"API_KEY\": \"your_api_key\"\n    }\n  }\n}\n```\n\n#### Custom Adapters (`app/*.json`)\n\nPlace custom MCP adapters in `backend/config/app/`. Each file defines:\n- `id` (string): Adapter identifier.\n- `icon` (string): Emoji or icon name.\n- `mcpServer` (object): Same structure as entries in `mcp_servers.json`.\n- `translations` (object): Localized UI metadata.\n\nExample (`duckduckgo-search.json`):\n```json\n{\n  \"id\": \"duckduckgo-search\",\n  \"icon\": \"ğŸ”\",\n  \"mcpServer\": {\n    \"url\": \"http://localhost:10000/duckduckgo-search\",\n    \"env\": {}\n  },\n  \"transportType\": \"sse\",\n  \"translations\": {\n    \"en\": { \"name\": \"DuckDuckGo Search\", \"type\": \"Search Tool\", \"description\": \"Use DuckDuckGo search engine for secure and private web searches\" },\n    \"zh\": { \"name\": \"DuckDuckGoæœç´¢\", \"type\": \"æœç´¢å·¥å…·\", \"description\": \"ä½¿ç”¨DuckDuckGoæœç´¢å¼•æ“è¿›è¡Œå®‰å…¨ã€ç§å¯†çš„ç½‘ç»œæœç´¢\" },\n    \"ja\": { \"name\": \"DuckDuckGoæ¤œç´¢\", \"type\": \"æ¤œç´¢ãƒ„ãƒ¼ãƒ«\", \"description\": \"DuckDuckGoæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ã—ã¦å®‰å…¨ã§ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªã‚¦ã‚§ãƒ–æ¤œç´¢ã‚’è¡Œã„ã¾ã™\" }\n  }\n}\n```\n\n#### Usage\n\n1. Initialize default configurations:\n   ```bash\n   uv run scripts/init_config.py\n   ```\n2. Modify JSON files under `backend/config/` to add or update models and endpoints.\n3. Restart the backend server to apply changes.\n\n## ğŸ”§ Environment Variables\n\n**Backend (.env)**\n\n| Key                  | Description                            | Default   |\n|----------------------|----------------------------------------|-----------|\n| DATABASE_U"])</script><script>self.__next_f.push([1,"RL         | PostgreSQL connection URL              | *required*|\n| BACKEND_CORS_ORIGINS | Allowed CORS origins (comma-separated) | []        |\n| MCP_SERVERS          | JSON list of SSE MCP server endpoints  | *required*|\n| SECRET_KEY           | JWT secret key                         | *required*|\n\n**Frontend (lib/core/config/app_config.dart)**\n```dart\nstatic String get baseUrl =\u003e \"http://127.0.0.1:8000\";\n```\n\n## ğŸ’¡ Usage\n\n1. Launch backend and frontend as shown in Quick Start.\n2. Open the app in your browser or mobile emulator.\n3. Register or login to obtain a JWT token.\n4. Use deep thinking mode or default chat mode to interact with the AI agent.\n5. Switch between MCP servers or add new endpoints under Settings.\n\n## ğŸ”— API Reference\n\nAccess the interactive Swagger UI at:\n\n```\nhttp://127.0.0.1:8000/docs\n```\n\n\n## ğŸ›£ï¸ Roadmap\n\n- [x] SSE multi-server support\n- [x] Multi-language (EN, ä¸­æ–‡, æ—¥æœ¬èª)\n- [x] Docker Compose setup\n- [x] streamable HTTP support\n- [ ] Local Stdio multi-server support\n- [ ] Local OCR support\n- [ ] Support for more formats of the upload interface\n- [ ] Frontend custom prompts\n- [ ] More model support\n- [ ] More language support\n\n## ğŸ›¡ï¸ Security\n\n- **Authentication**: All backend endpoints secured with JWT; tokens stored securely in encrypted storage.\n- **Data Protection**: Use HTTPS in production; configure allowed CORS origins via `BACKEND_CORS_ORIGINS` in `.env`.\n- **Secret Management**: Define `SECRET_KEY` in `.env`; ensure no secrets are committed to source control.\n\n## ğŸ” Monitoring \u0026 Logging\n\n- **Server Logs**: Configured in `gunicorn.conf.py`; access and error logs in `logs/`.\n- **Application Logs**: Uses Loguru for structured logging; frontend disables `debugPrint` in release mode.\n\n\n## ğŸš€ Performance \u0026 Optimization\n\n- **Caching**: Frontend caches static assets; backend uses async connection pooling for PostgreSQL.\n- **Bundle Size**: Web artifact built with `--wasm` for optimized delivery.\n\n\n\n\n## ğŸ—‚ï¸ Changelog\n\n\u003e All notable changes are documented in [CHANGELOG.md](CHANGELOG.md).\n\n## ğŸ“± Screenshots\n\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"images/home.png\" width=\"280\"/\u003e\n  \u003cimg src=\"images/shop.png\" width=\"280\"/\u003e\n  \u003cimg src=\"images/env.png\" width=\"280\"/\u003e\n  \u003cimg src=\"images/chat.png\" width=\"280\"/\u003e\n  \u003cimg src=\"images/myapps.png\" width=\"280\"/\u003e\n  \u003cimg src=\"images/settings.png\" width=\"280\"/\u003e\n\u003c/div\u003e\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Please open a Pull Request with your suggestions.\n\n## ğŸ“„ License\n\nThis project is licensed under the CarrotAI Open Source License. See the [LICENSE](LICENSE) file for details.29:T636,## What is CarrotAI? \nCarrotAI is a cutting-edge AI agent application that provides real-time streaming chat through Server-Sent Events (SSE) with integrated Model Control Protocol (MCP). It allows users to connect to multiple SSE MCP servers concurrently and offers interfaces in English, Chinese, and Japanese.\n\n## How to use CarrotAI? \nTo use CarrotAI, clone the repository from GitHub, set up the backend and frontend as per the instructions, and then launch the application. Users can register or log in to start interacting with the AI agent.\n\n## Key features of CarrotAI? \n- Real-time chat powered by SSE and MCP.\n- Multi-server support for concurrent connections.\n- Multi-language support (English, Chinese, Japanese).\n- Deep Thinking Mode for complex queries.\n- Secure authentication using JWT tokens.\n- Responsive user interface adaptable to various devices.\n- File upload capability for richer context in conversations.\n\n## Use cases of CarrotAI? \n1. Engaging in real-time conversations with an AI agent.\n2. Utilizing deep thinking mode for complex problem-solving.\n3. Connecting to multiple AI models for diverse responses.\n4. Supporting multilingual interactions in various applications.\n\n## FAQ from CarrotAI? \n- Can I use CarrotAI in multiple languages?  \n\u003e Yes! CarrotAI supports English, Chinese, and Japanese.\n\n- Is there a mobile version of CarrotAI?  \n\u003e Yes! The application is designed to be responsive and works on mobile devices.\n\n- How do I set up the ba"])</script><script>self.__next_f.push([1,"ckend?  \n\u003e Follow the installation instructions in the repository to set up the backend using Docker and Python.2a:Ta68,# SeekChat\n\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"public/assets/logo/logo.png\" alt=\"SeekChat Logo\" width=\"200\" /\u003e\n  \u003ch3\u003eâœ¨ A Sleek and Powerful AI Desktop Assistant âœ¨\u003c/h3\u003e\n  \u003cp\u003e\n    \u003ca href=\"https://www.seekrays.com/chat\" target=\"_blank\"\u003eOfficial Website\u003c/a\u003e |\n    \u003ca href=\"README_zh-cn.md\"\u003eä¸­æ–‡æ–‡æ¡£\u003c/a\u003e\n  \u003c/p\u003e\n\u003c/div\u003e\n\n\n[![Discord](https://img.shields.io/badge/Discord-Join%20Chat-blue?logo=discord\u0026logoColor=white)](https://discord.gg/qcSXXmX9Gx)\n[![WeChat](https://img.shields.io/badge/WeChat-Join%20Group-brightgreen?logo=wechat\u0026logoColor=white)](https://seekrays.com/chat/zh-cn/docs/contacts/)\n\nSeekChat supports MCP tool execution, enabling AI to directly control your computer and perform various tasks. Easily automate file management, data analysis, code development, and more, turning AI into a truly intelligent assistant.\n\n\n## âœ¨ Key Features\n\n- **Multiple AI Providers**: Support for various AI service providers\n- **MCP Tool Integration**: Support for [Model Context Protocol](https://github.com/mccpros/model-context-protocol) tools that enhance AI capabilities\n- **Local Storage**: Chat history is stored locally to protect your privacy\n- **Multi-language Support**: Available in English and Chinese\n- **Modern UI**: Simple and intuitive user interface\n\n## ğŸŒ  Screenshots\n\n### Chat Interface\n![Chat Interface](docs/screenshot/screenshot-chat.png)\n\n### MCP Tool Settings\n![MCP Tool Settings](docs/screenshot/screenshot-setting-mcp.png)\n\n## ğŸ“¦ Installation\n\n### Download Pre-compiled Version\n\nVisit the [Releases](https://github.com/seekrays/seekchat/releases) page to download the latest pre-compiled version.\n\n### Build from Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/seekrays/seekchat.git\ncd seekchat\n\n# Install dependencies\nnpm install\n\n# Run in development mode\nnpm run dev\n\n# Build for production\n# For macOS\nnpm run electron:build:mac\n\n# For Windows\nnpm run electron:build:win\n\n# For Linux\nnpm run electron:build:linux\n```\n\n\n## Community\n\n### Discord Community\nJoin our [Discord community](https://discord.gg/qcSXXmX9Gx) to get the latest updates and participate in product discussions.\n\n### WeChat Community\n![](https://seekrays.com/chat/images/qrcode_seekrays.jpg)\n\nAfter following our WeChat Official Account, send the message \"åŠ ç¾¤\" to join our WeChat community group and discuss with other users.\n\n## ğŸ¤ Contributing\n\nPull Requests and Issues are welcome! If you have any suggestions or find a bug, please let us know.\n\n\n## ğŸ™ Acknowledgements\n\n- Thanks to all open-source project contributors\n- Thanks to the Electron and React communities\n- Special thanks to all users for their support and feedback2b:T5b8,## what is SeekChat? \nSeekChat is a powerful AI desktop assistant that enables users to automate various tasks on their computer, including file management, data analysis, and code development, by leveraging AI capabilities.\n\n## how to use SeekChat? \nTo use SeekChat, download the pre-compiled version from the Releases page or build it from source. Once installed, you can interact with the AI through a modern user interface and utilize various AI providers for enhanced functionality.\n\n## key features of SeekChat? \n- Multiple AI Providers: Support for various AI service providers like OpenAI and Google.\n- MCP Tool Integration: Enhances AI capabilities through Model Context Protocol tools.\n- Local Storage: Ensures chat history is stored locally for privacy.\n- Multi-language Support: Available in both English and Chinese.\n- Modern UI: Simple and intuitive user interface for ease of use.\n\n## use cases of SeekChat? \n1. Automating repetitive file management tasks.\n2. Conducting data analysis with AI assistance.\n3. Developing and debugging code with AI support.\n\n## FAQ from SeekChat? \n- What AI providers does SeekChat support?  \n\u003e SeekChat supports OpenAI, Anthropic (Claude), Google (Gemini), and custom providers.\n\n- Is my data safe with SeekChat?  \n\u003e Yes! SeekChat stores chat history locall"])</script><script>self.__next_f.push([1,"y to protect your privacy.\n\n- How can I contribute to SeekChat?  \n\u003e You can contribute by submitting pull requests or reporting issues on the GitHub repository.2c:T513,## what is Easy RAG? \nEasy RAG is a Retrieval Augmented Generation (RAG) implementation that utilizes LlamaIndex for document processing, Gemini for embeddings, and LanceDB for vector storage, aimed at enhancing knowledge retrieval and generation.\n\n## how to use Easy RAG? \nTo use Easy RAG, set up the environment by installing dependencies and configuring your Google API key. Then, you can ingest data and run a search server using the provided commands.\n\n## key features of Easy RAG? \n- Integration with LlamaIndex for efficient document processing\n- Use of Gemini for advanced embeddings\n- LanceDB for scalable vector storage\n- Command-line interface for data ingestion and search\n\n## use cases of Easy RAG? \n1. Enhancing document retrieval for AI applications\n2. Building knowledge bases that require efficient data processing\n3. Implementing search functionalities in applications using vector databases\n\n## FAQ from Easy RAG? \n- What is RAG?\n\u003e RAG stands for Retrieval Augmented Generation, a method that combines retrieval of documents with generative models to improve the quality of generated content.\n\n- Is Easy RAG free to use?\n\u003e Yes! Easy RAG is open-source and available for anyone to use.\n\n- What programming language is Easy RAG written in?\n\u003e Easy RAG is primarily written in Python.2d:T1ff4,# Download MCP å·¥å…·\n\n[![ISC License](https://img.shields.io/badge/License-ISC-3a86ff?style=flat-square)](https://opensource.org/licenses/ISC)\n[![Node.js](https://img.shields.io/badge/Node.js-18.x-ff006e?style=flat-square)](https://nodejs.org/)\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.x-8338ec?style=flat-square)](https://www.typescriptlang.org/)\n[![Download](https://img.shields.io/badge/Download-MCP-fb5607?style=flat-square)](https://github.com/shuakami/mcp-download)\n\n[English Version (README-EN.md)](README-EN.md)\n\n## è¿™æ˜¯ä»€ä¹ˆ\n\nè¿™æ˜¯ä¸€ä¸ªåŸºäº MCP (Model Context Protocol) çš„ä¸‹è½½å·¥å…·ï¼Œå®ƒèƒ½è®© AI æ¨¡å‹é€šè¿‡æ ‡å‡†åŒ–æ¥å£ç®¡ç†æ–‡ä»¶ä¸‹è½½ä»»åŠ¡ã€‚\n\nç®€å•æ¥è¯´ï¼Œå®ƒè®© AI åŠ©æ‰‹èƒ½å¤Ÿæ‰§è¡Œå„ç§ä¸‹è½½æ“ä½œï¼Œå¦‚å¯åŠ¨å¤šçº¿ç¨‹ä¸‹è½½ã€ç›‘æ§ä¸‹è½½è¿›åº¦ã€ç®¡ç†ä¸‹è½½ä»»åŠ¡ç­‰ï¼Œæ— éœ€ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥å¤æ‚çš„å‘½ä»¤æˆ–åˆ‡æ¢åˆ°å…¶ä»–ä¸‹è½½å·¥å…·ã€‚\n\n\u003cdetails\u003e\n\u003csummary\u003e\u003cb\u003eæ”¯æŒçš„åŠŸèƒ½\u003c/b\u003e (ç‚¹å‡»å±•å¼€)\u003c/summary\u003e\n\n- **ä¸‹è½½æ–‡ä»¶**ï¼šè‡ªåŠ¨åˆ›å»ºå¤šçº¿ç¨‹ä¸‹è½½ä»»åŠ¡ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ \n- **ä»»åŠ¡ç®¡ç†**ï¼šåˆ—å‡ºã€è·å–ã€æš‚åœã€æ¢å¤ã€å–æ¶ˆå’Œæ¸…ç†ä¸‹è½½ä»»åŠ¡\n- **å¤šçº¿ç¨‹ä¸‹è½½**ï¼šæ”¯æŒå¤šè¾¾32çº¿ç¨‹å¹¶è¡Œä¸‹è½½ï¼Œæ˜¾è‘—æå‡ä¸‹è½½é€Ÿåº¦\n- **æŒä¹…åŒ–åŠŸèƒ½**ï¼šä¸‹è½½ä»»åŠ¡å¯åœ¨åå°æŒç»­è¿è¡Œï¼Œå³ä½¿å…³é—­å‰å°ç¨‹åº\n- **çŠ¶æ€ç›‘æ§**ï¼šå®æ—¶è·Ÿè¸ªä¸‹è½½è¿›åº¦ã€é€Ÿåº¦å’Œè€—æ—¶\n- **çµæ´»é…ç½®**ï¼šæ”¯æŒé˜»å¡/éé˜»å¡ã€æŒä¹…åŒ–/éæŒä¹…åŒ–ç­‰å¤šç§æ¨¡å¼\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\u003cb\u003eåŠŸèƒ½ç‰¹ç‚¹\u003c/b\u003e (ç‚¹å‡»å±•å¼€)\u003c/summary\u003e\n\nä»¥ä¸‹æ˜¯ Download MCP å·¥å…·çš„ä¸€äº›æ ¸å¿ƒç‰¹ç‚¹ï¼š\n\n- **æé€Ÿå¤šçº¿ç¨‹ä¸‹è½½**ï¼šæœ€é«˜æ”¯æŒ32çº¿ç¨‹å¹¶è¡Œä¸‹è½½ï¼Œå¤§å¹…æå‡ä¸‹è½½é€Ÿåº¦\n- **æ™ºèƒ½æ–­ç‚¹ç»­ä¼ **ï¼šè‡ªåŠ¨æ£€æµ‹ä¸­æ–­çš„ä¸‹è½½å¹¶ä»æ–­ç‚¹å¤„ç»§ç»­\n- **æŒä¹…åŒ–ä¸‹è½½ä»»åŠ¡**ï¼šå³ä½¿å…³é—­å‰å°è¿›ç¨‹ï¼Œä¸‹è½½ä»»åŠ¡ä¹Ÿä¼šåœ¨åå°ç»§ç»­\n- **å®æ—¶çŠ¶æ€ç›‘æ§**ï¼šæä¾›ä¸‹è½½é€Ÿåº¦ã€è¿›åº¦ã€å‰©ä½™æ—¶é—´ç­‰å®æ—¶ä¿¡æ¯\n- **çµæ´»çš„å·¥ä½œæ¨¡å¼**ï¼šæ”¯æŒé˜»å¡å¼æˆ–éé˜»å¡å¼ä¸‹è½½ï¼Œæ ¹æ®éœ€æ±‚é€‰æ‹©\n- **å®Œæ•´çš„ä»»åŠ¡ç®¡ç†**ï¼šåˆ›å»ºã€æš‚åœã€æ¢å¤ã€å–æ¶ˆå’Œæ¸…ç†ä¸‹è½½ä»»åŠ¡çš„å…¨æµç¨‹ç®¡ç†\n- **æ™ºèƒ½é”™è¯¯å¤„ç†**ï¼šè‡ªåŠ¨é‡è¯•å¤±è´¥çš„ä¸‹è½½ï¼Œç¡®ä¿ä¸‹è½½æˆåŠŸç‡\n\né€šè¿‡ç®€å•çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ŒAI å¯ä»¥å¸®åŠ©ä½ å®Œæˆä¸Šè¿°æ‰€æœ‰æ“ä½œï¼Œæ— éœ€æ‰‹åŠ¨ç¼–å†™å¤æ‚å‘½ä»¤æˆ–ä½¿ç”¨ä¸“é—¨çš„ä¸‹è½½è½¯ä»¶ã€‚\n\u003c/details\u003e\n\n## å¿«é€Ÿä¸Šæ‰‹\n\n### 0. ç¯å¢ƒå‡†å¤‡\n\n\u003cdetails\u003e\n\u003csummary\u003eå¦‚æœä½ ä¹‹å‰æ²¡æœ‰ä½¿ç”¨è¿‡ Node.js (ç‚¹å‡»å±•å¼€)\u003c/summary\u003e\n\n1. å®‰è£… Node.js å’Œ npm\n   - è®¿é—® [Node.js å®˜ç½‘](https://nodejs.org/)\n   - ä¸‹è½½å¹¶å®‰è£… LTSï¼ˆé•¿æœŸæ”¯æŒï¼‰ç‰ˆæœ¬\n   - å®‰è£…æ—¶é€‰æ‹©"])</script><script>self.__next_f.push([1,"é»˜è®¤é€‰é¡¹å³å¯ï¼Œå®‰è£…åŒ…ä¼šåŒæ—¶å®‰è£… Node.js å’Œ npm\n\n2. éªŒè¯å®‰è£…\n   - å®‰è£…å®Œæˆåï¼Œæ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼ˆCMDï¼‰æˆ– PowerShell\n   - è¾“å…¥ä»¥ä¸‹å‘½ä»¤ç¡®è®¤å®‰è£…æˆåŠŸï¼š\n     ```bash\n     node --version\n     npm --version\n     ```\n   - å¦‚æœæ˜¾ç¤ºç‰ˆæœ¬å·ï¼Œåˆ™è¡¨ç¤ºå®‰è£…æˆåŠŸ\n\n3. å®‰è£… Gitï¼ˆå¦‚æœå°šæœªå®‰è£…ï¼‰\n   - è®¿é—® [Git å®˜ç½‘](https://git-scm.com/)\n   - ä¸‹è½½å¹¶å®‰è£… Git\n   - å®‰è£…æ—¶ä½¿ç”¨é»˜è®¤é€‰é¡¹å³å¯\n\n4. å®‰è£… Python 3.11 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆå¿…éœ€ï¼‰\n   - è®¿é—® [Python å®˜ç½‘](https://www.python.org/downloads/)\n   - ä¸‹è½½å¹¶å®‰è£… Python 3.11 æˆ–æ›´é«˜ç‰ˆæœ¬\n   - **é‡è¦**ï¼šå®‰è£…æ—¶å¿…é¡»å‹¾é€‰\"Add Python to PATH\"é€‰é¡¹\n   - å®‰è£…å®Œæˆå**é‡å¯ç”µè„‘**ï¼Œç¡®ä¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ\n\u003c/details\u003e\n\n### 1. å…‹éš†å¹¶å®‰è£…\n\n```bash\ngit clone https://github.com/shuakami/mcp-download.git\ncd mcp-download\nnpm install\nnpm run build\n```\n\n### 2. æ„å»ºé¡¹ç›®\n\n```bash\nnpm run build\n```\n\n### 3. æ·»åŠ åˆ° Cursor MCP é…ç½®\n\næ ¹æ®ä½ çš„æ“ä½œç³»ç»Ÿï¼ŒæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é…ç½® MCPï¼š\n\n\u003cdetails\u003e\n\u003csummary\u003e\u003cb\u003eWindows é…ç½®\u003c/b\u003e (ç‚¹å‡»å±•å¼€)\u003c/summary\u003e\n\n1. åœ¨ Cursor ä¸­ï¼Œæ‰“å¼€æˆ–åˆ›å»º MCP é…ç½®æ–‡ä»¶ï¼š`C:\\\\Users\\\\ä½ çš„ç”¨æˆ·å\\\\.cursor\\\\mcp.json`\n   - æ³¨æ„ï¼šè¯·å°† `ä½ çš„ç”¨æˆ·å` æ›¿æ¢ä¸ºä½ çš„ Windows ç”¨æˆ·å\n\n2. æ·»åŠ æˆ–ä¿®æ”¹é…ç½®å¦‚ä¸‹ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"download-mcp\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"C:/Users/ä½ çš„ç”¨æˆ·å/mcp-download/bridging_download_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\n\u003e âš ï¸ **è¯·æ³¨æ„**:\n\u003e - å°† `ä½ çš„ç”¨æˆ·å` æ›¿æ¢ä¸ºä½ çš„ Windows ç”¨æˆ·å\n\u003e - ç¡®ä¿è·¯å¾„æ­£ç¡®æŒ‡å‘ä½ å…‹éš†æˆ–è§£å‹çš„é¡¹ç›®ç›®å½•\n\u003e - è·¯å¾„åº”è¯¥åæ˜ ä½ å°†é¡¹ç›®æ–‡ä»¶æ”¾ç½®çš„å®é™…ä½ç½®\n\u003e - **ä¸è¦åˆ é™¤å…‹éš†æˆ–è§£å‹çš„æ–‡ä»¶å¤¹**ï¼Œè¿™ä¼šå¯¼è‡´ MCP æ— æ³•æ­£å¸¸å·¥ä½œ\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\u003cb\u003emacOS é…ç½®\u003c/b\u003e (ç‚¹å‡»å±•å¼€)\u003c/summary\u003e\n\n1. åœ¨ Cursor ä¸­ï¼Œæ‰“å¼€æˆ–åˆ›å»º MCP é…ç½®æ–‡ä»¶ï¼š`/Users/ä½ çš„ç”¨æˆ·å/.cursor/mcp.json`\n   - æ³¨æ„ï¼šè¯·å°† `ä½ çš„ç”¨æˆ·å` æ›¿æ¢ä¸ºä½ çš„ macOS ç”¨æˆ·å\n\n2. æ·»åŠ æˆ–ä¿®æ”¹é…ç½®å¦‚ä¸‹ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"download-mcp\": {\n      \"command\": \"python3\",\n      \"args\": [\n        \"/Users/ä½ çš„ç”¨æˆ·å/mcp-download/bridging_download_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\n\u003e âš ï¸ **è¯·æ³¨æ„**:\n\u003e - å°† `ä½ çš„ç”¨æˆ·å` æ›¿æ¢ä¸ºä½ çš„ macOS ç”¨æˆ·å\n\u003e - ç¡®ä¿è·¯å¾„æ­£ç¡®æŒ‡å‘ä½ å…‹éš†æˆ–è§£å‹çš„é¡¹ç›®ç›®å½•\n\u003e - è·¯å¾„åº”è¯¥åæ˜ ä½ å°†é¡¹ç›®æ–‡ä»¶æ”¾ç½®çš„å®é™…ä½ç½®\n\u003e - **ä¸è¦åˆ é™¤å…‹éš†æˆ–è§£å‹çš„æ–‡ä»¶å¤¹**ï¼Œè¿™ä¼šå¯¼è‡´ MCP æ— æ³•æ­£å¸¸å·¥ä½œ\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003e\u003cb\u003eLinux é…ç½®\u003c/b\u003e (ç‚¹å‡»å±•å¼€)\u003c/summary\u003e\n\n1. åœ¨ Cursor ä¸­ï¼Œæ‰“å¼€æˆ–åˆ›å»º MCP é…ç½®æ–‡ä»¶ï¼š`/home/ä½ çš„ç”¨æˆ·å/.cursor/mcp.json`\n   - æ³¨æ„ï¼šè¯·å°† `ä½ çš„ç”¨æˆ·å` æ›¿æ¢ä¸ºä½ çš„ Linux ç”¨æˆ·å\n\n2. æ·»åŠ æˆ–ä¿®æ”¹é…ç½®å¦‚ä¸‹ï¼š\n\n```json\n{\n  \"mcpServers\": {\n    \"download-mcp\": {\n      \"command\": \"python3\",\n      \"args\": [\n        \"/home/ä½ çš„ç”¨æˆ·å/mcp-download/bridging_download_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\n\u003e âš ï¸ **è¯·æ³¨æ„**:\n\u003e - å°† `ä½ çš„ç”¨æˆ·å` æ›¿æ¢ä¸ºä½ çš„ Linux ç”¨æˆ·å\n\u003e - ç¡®ä¿è·¯å¾„æ­£ç¡®æŒ‡å‘ä½ å…‹éš†æˆ–è§£å‹çš„é¡¹ç›®ç›®å½•\n\u003e - è·¯å¾„åº”è¯¥åæ˜ ä½ å°†é¡¹ç›®æ–‡ä»¶æ”¾ç½®çš„å®é™…ä½ç½®\n\u003e - **ä¸è¦åˆ é™¤å…‹éš†æˆ–è§£å‹çš„æ–‡ä»¶å¤¹**ï¼Œè¿™ä¼šå¯¼è‡´ MCP æ— æ³•æ­£å¸¸å·¥ä½œ\n\u003c/details\u003e\n\n### 4. å¯åŠ¨æœåŠ¡\n\né…ç½®å¥½ä¹‹åï¼Œé‡å¯ Cursor ç¼–è¾‘å™¨ï¼Œå®ƒä¼šè‡ªåŠ¨å¯åŠ¨ MCP æœåŠ¡ã€‚ç„¶åä½ å°±å¯ä»¥å¼€å§‹ä½¿ç”¨äº†ã€‚\n\n\u003cdetails\u003e\n\u003csummary\u003eä½¿ç”¨ç¤ºä¾‹ (ç‚¹å‡»å±•å¼€)\u003c/summary\u003e\n\nä½ å¯ä»¥è¦æ±‚ AI æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\n- \"ä¸‹è½½ https://nodejs.org/dist/v18.19.0/node-v18.19.0-x64.msi åˆ°æˆ‘çš„ä¸‹è½½æ–‡ä»¶å¤¹\"\n- \"æ˜¾ç¤ºå½“å‰çš„æ‰€æœ‰ä¸‹è½½ä»»åŠ¡\" \n- \"æŸ¥çœ‹ä¸‹è½½IDä¸ºabc123çš„ä¸‹è½½çŠ¶æ€\"\n- \"æš‚åœå½“å‰çš„ä¸‹è½½ä»»åŠ¡\"\n- \"æ¢å¤IDä¸ºabc123çš„ä¸‹è½½ï¼Œä½¿ç”¨8ä¸ªçº¿ç¨‹\"\n- \"å–æ¶ˆæ­£åœ¨è¿›è¡Œçš„ä¸‹è½½\"\n- \"æ¸…ç†æ‰€æœ‰å·²å®Œæˆçš„ä¸‹è½½ä»»åŠ¡\"\n\né«˜çº§ç”¨æ³•ï¼š\n- \"ä½¿ç”¨32çº¿ç¨‹ä¸‹è½½ https://dlcdn.apache.org/tomcat/tomcat-10/v10.1.19/bin/apache-tomcat-10.1.19.zip\"\n- \"ä»¥é˜»å¡æ¨¡å¼ä¸‹è½½ https://dl.google.com/android/repository/platform-t"])</script><script>self.__next_f.push([1,"ools-latest-windows.zip\"ï¼ˆç­‰å¾…ä¸‹è½½å®Œæˆåå†ç»§ç»­ï¼‰\n- \"å¯åŠ¨æŒä¹…åŒ–ä¸‹è½½ https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Windows-x86_64.exe\"ï¼ˆå³ä½¿å…³é—­å‰å°ç¨‹åºä¹Ÿä¼šç»§ç»­ä¸‹è½½ï¼‰\n\u003c/details\u003e\n\n## å·¥ä½œåŸç†\n\n\u003cdetails\u003e\n\u003csummary\u003eæŠ€æœ¯å®ç°ç»†èŠ‚ (ç‚¹å‡»å±•å¼€)\u003c/summary\u003e\n\næœ¬å·¥å…·åŸºäº **MCP (Model Context Protocol)** æ ‡å‡†å®ç°ï¼Œä½œä¸º AI æ¨¡å‹ä¸æ–‡ä»¶ä¸‹è½½æœåŠ¡ä¹‹é—´çš„æ¡¥æ¢ã€‚å®ƒä½¿ç”¨ **node-fetch** ä½œä¸ºåº•å±‚ä¸‹è½½å®¢æˆ·ç«¯ï¼Œå¹¶é€šè¿‡ **Zod** è¿›è¡Œè¯·æ±‚éªŒè¯å’Œç±»å‹æ£€æŸ¥ã€‚\n\nä¸»è¦æŠ€æœ¯ç»„ä»¶åŒ…æ‹¬ï¼š\n- **å¤šçº¿ç¨‹ä¸‹è½½ç®¡ç†å™¨**ï¼šå°†å¤§æ–‡ä»¶åˆ†å‰²ä¸ºå¤šä¸ªæ®µï¼Œå¹¶å‘ä¸‹è½½ï¼Œç„¶ååˆå¹¶\n- **æ–­ç‚¹ç»­ä¼ ç³»ç»Ÿ**ï¼šè·Ÿè¸ªæ¯ä¸ªæ®µçš„ä¸‹è½½è¿›åº¦ï¼Œæ”¯æŒä¸­æ–­åæ¢å¤\n- **æŒä¹…åŒ–å­˜å‚¨**ï¼šä¿å­˜ä¸‹è½½ä»»åŠ¡çŠ¶æ€ï¼Œå³ä½¿ç¨‹åºé‡å¯ä¹Ÿèƒ½æ¢å¤\n- **å®æ—¶ç›‘æ§**ï¼šè®¡ç®—ä¸‹è½½é€Ÿåº¦ã€é¢„ä¼°å‰©ä½™æ—¶é—´ç­‰å…³é”®æŒ‡æ ‡\n- **çµæ´»çš„å·¥ä½œæ¨¡å¼**ï¼šæ”¯æŒé˜»å¡/éé˜»å¡ã€æŒä¹…åŒ–/éæŒä¹…åŒ–æ¨¡å¼\n\næ¯ä¸ªä¸‹è½½æ“ä½œéƒ½è¢«å°è£…ä¸ºæ ‡å‡†åŒ–çš„ MCP å·¥å…·ï¼Œæ¥æ”¶ç»“æ„åŒ–å‚æ•°å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœã€‚æ‰€æœ‰ä¸‹è½½ä»»åŠ¡éƒ½ä½œä¸ºç‹¬ç«‹è¿›ç¨‹ç®¡ç†ï¼Œç¡®ä¿å³ä½¿å‰å°ç¨‹åºå…³é—­ï¼Œä¸‹è½½ä¹Ÿèƒ½å®‰å…¨ç»§ç»­ã€‚\n\nè¿™ç§è®¾è®¡ä½¿ AI æ¨¡å‹èƒ½å¤Ÿæ¸…æ™°åœ°ç†è§£å’Œå¤„ç†ä¸‹è½½çŠ¶æ€ï¼Œå¹¶ä»¥æ›´è‡ªç„¶çš„æ–¹å¼ä¸ç”¨æˆ·æ²Ÿé€šä¸‹è½½è¿›åº¦ã€é€Ÿåº¦å’Œå…¶ä»–å…³é”®ä¿¡æ¯ã€‚\n\u003c/details\u003e\n\n## è®¸å¯è¯\n\nISC\n\n---\n\nå¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ç»™ä¸ª Star â­ï¸ (ï½¡â™¥â€¿â™¥ï½¡)2e:T5bf,## What is MCP Download Tool? \nThe MCP Download Tool is an AI-powered file download manager that utilizes the Model Context Protocol (MCP) to manage file download tasks through a standardized interface.\n\n## How to use MCP Download Tool? \nTo use the MCP Download Tool, clone the repository, install the necessary dependencies, configure the MCP settings according to your operating system, and start the service. You can then issue commands to the AI for various download operations.\n\n## Key features of MCP Download Tool? \n- Multi-threaded downloads with up to 32 concurrent threads.\n- Automatic resume of interrupted downloads.\n- Real-time monitoring of download progress and speed.\n- Task management capabilities including pause, resume, and cancel.\n- Flexible configuration options for blocking and non-blocking modes.\n\n## Use cases of MCP Download Tool? \n1. Downloading large files efficiently using multiple threads.\n2. Managing multiple download tasks without manual intervention.\n3. Automating download processes through natural language commands.\n\n## FAQ from MCP Download Tool? \n- Can I use MCP Download Tool for any file type?  \n\u003e Yes! It can handle various file types as long as the URL is accessible.\n\n- Is there a limit to the number of downloads?  \n\u003e No, you can manage multiple downloads simultaneously.\n\n- Do I need to keep the application open for downloads to continue?  \n\u003e No, downloads can continue in the background even if the application is closed.2f:T475,# pydantic-mcp\n\n**PydanticAI now includes support for [MCP servers](https://ai.pydantic.dev/mcp/), use that instead**\n\n![PyPI - Version](https://img.shields.io/pypi/v/pydantic-mcp)\n\n[Model Context Protocol](https://modelcontextprotocol.io) tool calling support for [Pydantic AI](https://ai.pydantic.dev/).\n\nJust create an `mcp.ClientSession` and call `tools = await mcptools(session)`\nto get a list of `pydantic_ai.Tool` instances for the supported tools.\n\nExample:\n\nhttps://github.com/rectalogic/pydantic-mcp/blob/98c4e9abf31837cb48ebeb3eae6cb55b16c841e8/tests/demo.py#L15-L25\n\n## Demo\n\nYou can run the demo against [Groq](https://groq.com/) `llama-3.1-8b-instant`:\n```sh-session\n$ export GROQ_API_KEY=xxx\n$ uv run tests/demo.py \"Read and summarize the file ./LICENSE\"\nSecure MCP Filesystem Server running on stdio\nAllowed directories: [ '/users/aw/projects/rectalogic/pydantic-mcp' ]\nThe file ./LICENSE is a MIT License agreement. It states that the software is provided \"as is\" without warranty and that the authors and copyright holders are not liable for any claims, damages, or other liability arising from the software or its use.\n```30:T"])</script><script>self.__next_f.push([1,"43c,## what is pydantic-mcp? \nPydantic-mcp is a tool that provides Model Context Protocol (MCP) support for Pydantic AI, enabling seamless integration and tool calling capabilities.\n\n## how to use pydantic-mcp? \nTo use pydantic-mcp, create an `mcp.ClientSession` and call `tools = await mcptools(session)` to retrieve a list of supported `pydantic_ai.Tool` instances.\n\n## key features of pydantic-mcp? \n- Integration with Model Context Protocol for Pydantic AI.\n- Easy setup with `mcp.ClientSession`.\n- Access to a variety of tools through MCP.\n\n## use cases of pydantic-mcp? \n1. Automating interactions with Pydantic AI tools.\n2. Enhancing data validation and parsing in Python applications.\n3. Facilitating complex data workflows using MCP.\n\n## FAQ from pydantic-mcp? \n- What is the purpose of pydantic-mcp?\n\u003e It provides support for Model Context Protocol tool calling in Pydantic AI applications.\n\n- Is pydantic-mcp free to use?\n\u003e Yes! It is open-source and available under the MIT license.\n\n- What programming language is pydantic-mcp written in?\n\u003e Pydantic-mcp is written in Python.31:T28b9,\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://librechat.ai\"\u003e\n    \u003cimg src=\"client/public/assets/logo.svg\" height=\"256\"\u003e\n  \u003c/a\u003e\n  \u003ch1 align=\"center\"\u003e\n    \u003ca href=\"https://librechat.ai\"\u003eLibreChat\u003c/a\u003e\n  \u003c/h1\u003e\n\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://discord.librechat.ai\"\u003e \n    \u003cimg\n      src=\"https://img.shields.io/discord/1086345563026489514?label=\u0026logo=discord\u0026style=for-the-badge\u0026logoWidth=20\u0026logoColor=white\u0026labelColor=000000\u0026color=blueviolet\"\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://www.youtube.com/@LibreChat\"\u003e \n    \u003cimg\n      src=\"https://img.shields.io/badge/YOUTUBE-red.svg?style=for-the-badge\u0026logo=youtube\u0026logoColor=white\u0026labelColor=000000\u0026logoWidth=20\"\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://docs.librechat.ai\"\u003e \n    \u003cimg\n      src=\"https://img.shields.io/badge/DOCS-blue.svg?style=for-the-badge\u0026logo=read-the-docs\u0026logoColor=white\u0026labelColor=000000\u0026logoWidth=20\"\u003e\n  \u003c/a\u003e\n  \u003ca aria-label=\"Sponsors\" href=\"https://github.com/sponsors/danny-avila\"\u003e\n    \u003cimg\n      src=\"https://img.shields.io/badge/SPONSORS-brightgreen.svg?style=for-the-badge\u0026logo=github-sponsors\u0026logoColor=white\u0026labelColor=000000\u0026logoWidth=20\"\u003e\n  \u003c/a\u003e\n\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\n\u003ca href=\"https://railway.app/template/b5k2mn?referralCode=HI9hWz\"\u003e\n  \u003cimg src=\"https://railway.app/button.svg\" alt=\"Deploy on Railway\" height=\"30\"\u003e\n\u003c/a\u003e\n\u003ca href=\"https://zeabur.com/templates/0X2ZY8\"\u003e\n  \u003cimg src=\"https://zeabur.com/button.svg\" alt=\"Deploy on Zeabur\" height=\"30\"/\u003e\n\u003c/a\u003e\n\u003ca href=\"https://template.cloud.sealos.io/deploy?templateName=librechat\"\u003e\n  \u003cimg src=\"https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg\" alt=\"Deploy on Sealos\" height=\"30\"\u003e\n\u003c/a\u003e\n\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://www.librechat.ai/docs/translation\"\u003e\n    \u003cimg \n      src=\"https://img.shields.io/badge/dynamic/json.svg?style=for-the-badge\u0026color=2096F3\u0026label=locize\u0026query=%24.translatedPercentage\u0026url=https://api.locize.app/badgedata/4cb2598b-ed4d-469c-9b04-2ed531a8cb45\u0026suffix=%+translated\" \n      alt=\"Translation Progress\"\u003e\n  \u003c/a\u003e\n\u003c/p\u003e\n\n\n# âœ¨ Features\n\n- ğŸ–¥ï¸ **UI \u0026 Experience** inspired by ChatGPT with enhanced design and features\n\n- ğŸ¤– **AI Model Selection**:  \n  - Anthropic (Claude), AWS Bedrock, OpenAI, Azure OpenAI, Google, Vertex AI, OpenAI Assistants API (incl. Azure)\n  - [Custom Endpoints](https://www.librechat.ai/docs/quick_start/custom_endpoints): Use any OpenAI-compatible API with LibreChat, no proxy required\n  - Compatible with [Local \u0026 Remote AI Providers](https://www.librechat.ai/docs/configuration/librechat_yaml/ai_endpoints):\n    - Ollama, groq, Cohere, Mistral AI, Apple MLX, koboldcpp, together.ai,\n    - OpenRouter, Perplexity, ShuttleAI, Deepseek, Qwen, and more\n\n- ğŸ”§ **[Code Interpreter API](https://www.librechat.ai/docs/features/code_interpreter)**: \n  - Secure, Sandboxed Execution in Python, Node.js (JS/TS), Go, C/C++, Java, PHP, Rust, and Fortran\n  - Seamless File Handling: Upload, process, and download files directly\n  - No Privacy Concerns: Fully isolated and secure execution\n\n- ğŸ”¦ **Agents \u0026 To"])</script><script>self.__next_f.push([1,"ols Integration**:  \n  - **[LibreChat Agents](https://www.librechat.ai/docs/features/agents)**:\n    - No-Code Custom Assistants: Build specialized, AI-driven helpers without coding  \n    - Flexible \u0026 Extensible: Attach tools like DALL-E-3, file search, code execution, and more  \n    - Compatible with Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, and more\n    - [Model Context Protocol (MCP) Support](https://modelcontextprotocol.io/clients#librechat) for Tools\n  - Use LibreChat Agents and OpenAI Assistants with Files, Code Interpreter, Tools, and API Actions\n\n- ğŸ” **Web Search**:  \n  - Search the internet and retrieve relevant information to enhance your AI context\n  - Combines search providers, content scrapers, and result rerankers for optimal results\n  - **[Learn More â†’](https://www.librechat.ai/docs/features/web_search)**\n\n- ğŸª„ **Generative UI with Code Artifacts**:  \n  - [Code Artifacts](https://youtu.be/GfTj7O4gmd0?si=WJbdnemZpJzBrJo3) allow creation of React, HTML, and Mermaid diagrams directly in chat\n\n- ğŸ¨ **Image Generation \u0026 Editing**\n  - Text-to-image and image-to-image with [GPT-Image-1](https://www.librechat.ai/docs/features/image_gen#1--openai-image-tools-recommended)\n  - Text-to-image with [DALL-E (3/2)](https://www.librechat.ai/docs/features/image_gen#2--dalle-legacy), [Stable Diffusion](https://www.librechat.ai/docs/features/image_gen#3--stable-diffusion-local), [Flux](https://www.librechat.ai/docs/features/image_gen#4--flux), or any [MCP server](https://www.librechat.ai/docs/features/image_gen#5--model-context-protocol-mcp)\n  - Produce stunning visuals from prompts or refine existing images with a single instruction\n\n- ğŸ’¾ **Presets \u0026 Context Management**:  \n  - Create, Save, \u0026 Share Custom Presets  \n  - Switch between AI Endpoints and Presets mid-chat\n  - Edit, Resubmit, and Continue Messages with Conversation branching  \n  - [Fork Messages \u0026 Conversations](https://www.librechat.ai/docs/features/fork) for Advanced Context control\n\n- ğŸ’¬ **Multimodal \u0026 File Interactions**:  \n  - Upload and analyze images with Claude 3, GPT-4.5, GPT-4o, o1, Llama-Vision, and Gemini ğŸ“¸  \n  - Chat with Files using Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, \u0026 Google ğŸ—ƒï¸\n\n- ğŸŒ **Multilingual UI**:  \n  - English, ä¸­æ–‡, Deutsch, EspaÃ±ol, FranÃ§ais, Italiano, Polski, PortuguÃªs Brasileiro\n  - Ğ ÑƒÑÑĞºĞ¸Ğ¹, æ—¥æœ¬èª, Svenska, í•œêµ­ì–´, Tiáº¿ng Viá»‡t, ç¹é«”ä¸­æ–‡, Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©, TÃ¼rkÃ§e, Nederlands, ×¢×‘×¨×™×ª\n\n- ğŸ§  **Reasoning UI**:  \n  - Dynamic Reasoning UI for Chain-of-Thought/Reasoning AI models like DeepSeek-R1\n\n- ğŸ¨ **Customizable Interface**:  \n  - Customizable Dropdown \u0026 Interface that adapts to both power users and newcomers\n\n- ğŸ—£ï¸ **Speech \u0026 Audio**:  \n  - Chat hands-free with Speech-to-Text and Text-to-Speech  \n  - Automatically send and play Audio  \n  - Supports OpenAI, Azure OpenAI, and Elevenlabs\n\n- ğŸ“¥ **Import \u0026 Export Conversations**:  \n  - Import Conversations from LibreChat, ChatGPT, Chatbot UI  \n  - Export conversations as screenshots, markdown, text, json\n\n- ğŸ” **Search \u0026 Discovery**:  \n  - Search all messages/conversations\n\n- ğŸ‘¥ **Multi-User \u0026 Secure Access**:\n  - Multi-User, Secure Authentication with OAuth2, LDAP, \u0026 Email Login Support\n  - Built-in Moderation, and Token spend tools\n\n- âš™ï¸ **Configuration \u0026 Deployment**:  \n  - Configure Proxy, Reverse Proxy, Docker, \u0026 many Deployment options  \n  - Use completely local or deploy on the cloud\n\n- ğŸ“– **Open-Source \u0026 Community**:  \n  - Completely Open-Source \u0026 Built in Public  \n  - Community-driven development, support, and feedback\n\n[For a thorough review of our features, see our docs here](https://docs.librechat.ai/) ğŸ“š\n\n## ğŸª¶ All-In-One AI Conversations with LibreChat\n\nLibreChat brings together the future of assistant AIs with the revolutionary technology of OpenAI's ChatGPT. Celebrating the original styling, LibreChat gives you the ability to integrate multiple AI models. It also integrates and enhances original client features such as conversation and message search, prompt template"])</script><script>self.__next_f.push([1,"s and plugins.\n\nWith LibreChat, you no longer need to opt for ChatGPT Plus and can instead use free or pay-per-call APIs. We welcome contributions, cloning, and forking to enhance the capabilities of this advanced chatbot platform.\n\n[![Watch the video](https://raw.githubusercontent.com/LibreChat-AI/librechat.ai/main/public/images/changelog/v0.7.6.gif)](https://www.youtube.com/watch?v=ilfwGQtJNlI)\n\nClick on the thumbnail to open the videoâ˜ï¸\n\n---\n\n## ğŸŒ Resources\n\n**GitHub Repo:**\n  - **RAG API:** [github.com/danny-avila/rag_api](https://github.com/danny-avila/rag_api)\n  - **Website:** [github.com/LibreChat-AI/librechat.ai](https://github.com/LibreChat-AI/librechat.ai)\n\n**Other:**\n  - **Website:** [librechat.ai](https://librechat.ai)\n  - **Documentation:** [docs.librechat.ai](https://docs.librechat.ai)\n  - **Blog:** [blog.librechat.ai](https://blog.librechat.ai)\n\n---\n\n## ğŸ“ Changelog\n\nKeep up with the latest updates by visiting the releases page and notes:\n- [Releases](https://github.com/danny-avila/LibreChat/releases)\n- [Changelog](https://www.librechat.ai/changelog) \n\n**âš ï¸ Please consult the [changelog](https://www.librechat.ai/changelog) for breaking changes before updating.**\n\n---\n\n## â­ Star History\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://star-history.com/#danny-avila/LibreChat\u0026Date\"\u003e\n    \u003cimg alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=danny-avila/LibreChat\u0026type=Date\u0026theme=dark\" onerror=\"this.src='https://api.star-history.com/svg?repos=danny-avila/LibreChat\u0026type=Date'\" /\u003e\n  \u003c/a\u003e\n\u003c/p\u003e\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://trendshift.io/repositories/4685\" target=\"_blank\" style=\"padding: 10px;\"\u003e\n    \u003cimg src=\"https://trendshift.io/api/badge/repositories/4685\" alt=\"danny-avila%2FLibreChat | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://runacap.com/ross-index/q1-24/\" target=\"_blank\" rel=\"noopener\" style=\"margin-left: 20px;\"\u003e\n    \u003cimg style=\"width: 260px; height: 56px\" src=\"https://runacap.com/wp-content/uploads/2024/04/ROSS_badge_white_Q1_2024.svg\" alt=\"ROSS Index - Fastest Growing Open-Source Startups in Q1 2024 | Runa Capital\" width=\"260\" height=\"56\"/\u003e\n  \u003c/a\u003e\n\u003c/p\u003e\n\n---\n\n## âœ¨ Contributions\n\nContributions, suggestions, bug reports and fixes are welcome!\n\nFor new features, components, or extensions, please open an issue and discuss before sending a PR.\n\nIf you'd like to help translate LibreChat into your language, we'd love your contribution! Improving our translations not only makes LibreChat more accessible to users around the world but also enhances the overall user experience. Please check out our [Translation Guide](https://www.librechat.ai/docs/translation).\n\n---\n\n## ğŸ’– This project exists in its current state thanks to all the people who contribute\n\n\u003ca href=\"https://github.com/danny-avila/LibreChat/graphs/contributors\"\u003e\n  \u003cimg src=\"https://contrib.rocks/image?repo=danny-avila/LibreChat\" /\u003e\n\u003c/a\u003e\n\n---\n\n## ğŸ‰ Special Thanks\n\nWe thank [Locize](https://locize.com) for their translation management tools that support multiple languages in LibreChat.\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://locize.com\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\n    \u003cimg src=\"https://github.com/user-attachments/assets/d6b70894-6064-475e-bb65-92a9e23e0077\" alt=\"Locize Logo\" height=\"50\"\u003e\n  \u003c/a\u003e\n\u003c/p\u003e32:T613,## What is LibreChat? \nLibreChat is an enhanced clone of ChatGPT that integrates multiple AI models and features, allowing users to engage in AI-driven conversations with various tools and functionalities.\n\n## How to use LibreChat? \nUsers can access LibreChat through its web interface, where they can interact with different AI models, upload files, and utilize various integrated tools for a comprehensive chat experience.\n\n## Key features of LibreChat? \n- AI Model Selection: Choose from multiple AI providers including OpenAI, Anthropic, and Google.\n- Code Interpreter API: Execute code securely in various programming languages.\n- Agents \u0026 Tools Integration: Create custom AI assistants without coding.\n- Multimodal Interactions: Upload and analyze imag"])</script><script>self.__next_f.push([1,"es, chat with files, and more.\n- Multilingual Support: Available in multiple languages for global accessibility.\n- Open-Source: Community-driven development and contributions.\n\n## Use cases of LibreChat? \n1. Building custom AI assistants for specific tasks.\n2. Conducting complex conversations with integrated tools.\n3. Analyzing images and files during chat sessions.\n4. Utilizing code execution for programming-related queries.\n\n## FAQ from LibreChat? \n- Can I self-host LibreChat?  \n\u003e Yes! LibreChat is open-source and can be self-hosted.\n\n- What AI models can I use with LibreChat?  \n\u003e You can use models from OpenAI, Anthropic, Google, and more.\n\n- Is there a cost associated with using LibreChat?  \n\u003e LibreChat is free to use, but some features may require payment depending on the API used.33:T199f,# Tester Client for Model Context Protocol (MCP)\n\n[![Actors MCP Client](https://apify.com/actor-badge?actor=jiri.spilka/tester-mcp-client)](https://apify.com/jiri.spilka/tester-mcp-client)\n\nImplementation of a model context protocol (MCP) client that connects to an MCP server using Server-Sent Events (SSE) and displays the conversation in a chat-like UI.\nIt is a standalone Actor server designed for testing MCP servers over SSE.\nIt uses [Pay-per-event](https://docs.apify.com/sdk/js/docs/guides/pay-per-event) pricing model.\n\nFor more information, see the [Model Context Protocol](https://modelcontextprotocol.org/) website or blogpost [What is MCP and why does it matter?](https://blog.apify.com/what-is-model-context-protocol/).\n\nOnce you run the Actor, check the output or logs for a link to the chat UI interface to interact with the MCP server.\nThe URL will look like this and will vary each run:\n```shell\nNavigate to https://...apify.net to interact with chat-ui interface.\n```\n\n## ğŸš€ Main features\n\n- ğŸ”Œ Connects to an MCP server using Server-Sent Events (SSE) or Streamable HTTP\n- ğŸ’¬ Provides a chat-like UI for displaying tool calls and results\n- ğŸ‡¦ Connects to an [Apify MCP Server](https://mcp.apify.com) for interacting with one or more Apify Actors\n- ğŸ’¥ Dynamically uses tools based on context and user queries (if supported by a server)\n- ğŸ”“ Use Authorization headers and API keys for secure connections\n- ğŸªŸ Open source, so you can review it, suggest improvements, or modify it\n\n## ğŸ¯ What does Tester MCP Client do?\n\nWhen connected to [Apify MCP Server](https://mcp.apify.com/) the Tester MCP Client provides an interactive chat interface where you can:\n\n- \"What are the most popular Actors for social media scraping?\"\n- \"Show me the best way to use the Instagram Scraper\"\n- \"Which Actor should I use to extract data from LinkedIn?\"\n- \"Can you help me understand how to scrape Google search results?\"\n\n![Tester-MCP-client-screenshot](https://raw.githubusercontent.com/apify/tester-mcp-client/refs/heads/main/docs/chat-ui.png)\n\n## ğŸ“– How does it work?\n\nThe Apify MCP Client connects to a running MCP server over Server-Sent Events (SSE) and it does the following:\n\n- Initiates an SSE connection to the MCP server `/sse`.\n- Sends user queries to the MCP server via `POST /message`.\n- Receives real-time streamed responses (via `GET /sse`) that may include LLM output, and **tool usage** blocks\n- Based on the LLM response, orchestrates tool calls and displays the conversation\n- Displays the conversation\n\n## âš™ï¸ Usage\n\n- Test any MCP server over SSE\n- Test [Apify MCP Server](https://mcp.apify.com/) and the ability to dynamically select amongst thousands of tools\n\n### Normal Mode (on Apify)\n\nYou can run the Tester MCP Client on Apify and connect it to any MCP server that supports SSE.\nConfiguration can be done via the Apify UI or API by specifying parameters such as the MCP server URL, system prompt, and API key.\n\nOnce you run Actor, check the logs for a link to the Tester MCP Client UI, where you can interact with the MCP server:\nThe URL will look like this and will be different from run to run:\n```shell\nINFO  Navigate to https://......runs.apify.net in your browser to interact with an MCP server.\n```\n\n## ğŸ’° Pricing\n\nThe Apify MCP Clie"])</script><script>self.__next_f.push([1,"nt is free to use. You only pay for LLM provider usage and resources consumed on the Apify platform.\n\nThis Actor uses a modern and flexible approach for AI Agents monetization and pricing called [Pay-per-event](https://docs.apify.com/sdk/js/docs/guides/pay-per-event).\n\nEvents charged:\n- Actor start (based on memory used, charged per 128 MB unit)\n- Running time (charged every 5 minutes, per 128 MB unit)\n- Query answered (depends on the model used, not charged if you provide your own API key for LLM provider)\n\nWhen you use your own LLM provider API key, running the MCP Client for 1 hour with 128 MB memory costs approximately $0.06.\nWith the Apify Free tier (no credit card required ğŸ’³), you can run the MCP Client for 80 hours per month.\nDefinitely enough to test your MCP server!\n\n## ğŸ“– How it works\n\n```plaintext\nBrowser â† (SSE) â†’ Tester MCP Client  â† (SSE) â†’ MCP Server\n```\nWe create this chain to keep any custom bridging logic inside the Tester MCP Client, while leaving the main MCP Server unchanged.\nThe browser uses SSE to communicate with the Tester MCP Client, and the Tester MCP Client relies on SSE to talk to the MCP Server.\nThis separates extra client-side logic from the core server, making it easier to maintain and debug.\n\n1. Navigate to `https://tester-mcp-client.apify.actor?token=YOUR-API-TOKEN` (or http://localhost:3000 if you are running it locally).\n2. Files `index.html` and `client.js` are served from the `public/` directory.\n3. Browser opens SSE stream via `GET /sse`.\n4. The user's query is sent with `POST /message`.\n5. Query processing:\n    - Calls Large Language Model.\n    - Optionally calls tools if required using\n6. For each result chunk, `sseEmit(role, content)`\n\n\n### Local development\n\nThe Tester MCP Client Actor is open source and available on [GitHub](https://github.com/apify/rag-web-browser), allowing you to modify and develop it as needed.\n\nDownload the source code:\n\n```bash\ngit clone https://github.com/apify/tester-mcp-client.git\ncd tester-mcp-client\n```\nInstall the dependencies:\n```shell\nnpm install\n```\n\nCreate a `.env` file with the following content (refer to the `.env.example` file for guidance):\n\n```plaintext\nAPIFY_TOKEN=YOUR_APIFY_TOKEN\nLLM_PROVIDER_API_KEY=YOUR_API_KEY\n```\n\nDefault values for settings such as `mcpUrl`, `systemPrompt`, and others are defined in the `const.ts` file. You can adjust these as needed for your development.\n\nRun the client locally\n\n```bash\nnpm start\n```\n\nNavigate to [http://localhost:3000](http://localhost:3000) in your browser to interact with the MCP server.\n\n**Happy chatting with Apify Actors!**\n\n## â“˜ Limitations and feedback\n\nThe client does not support all MCP features, such as Prompts and Resource.\n\n## References\n\n- [Model Context Protocol](https://modelcontextprotocol.org/)\n- [Apify Actors MCP Server](https://apify.com/apify/actors-mcp-server)\n- [Apify MCP Server](https://docs.apify.com/platform/integrations/mcp)\n- [Pay-per-event pricing model](https://docs.apify.com/sdk/js/docs/guides/pay-per-event)\n- [What are AI Agents?](https://blog.apify.com/what-are-ai-agents/)\n- [What is MCP and why does it matter?](https://blog.apify.com/what-is-model-context-protocol/)\n- [How to use MCP with Apify Actors](https://blog.apify.com/how-to-use-mcp/)34:T5f6,## What is Tester MCP Client? \nTester MCP Client is an implementation of a Model Context Protocol (MCP) client that connects to an MCP server using Server-Sent Events (SSE) and provides a chat-like UI for displaying tool calls and results.\n\n## How to use Tester MCP Client? \nTo use the Tester MCP Client, run it on Apify and connect it to any MCP server that supports SSE. Configuration can be done via the Apify UI or API by specifying parameters such as the MCP server URL, system prompt, and API key. Once running, navigate to the provided URL to interact with the MCP server.\n\n## Key features of Tester MCP Client? \n- Connects to an MCP server using Server-Sent Events (SSE)\n- Provides a chat-like UI for displaying tool calls and results\n- Connects to an Apify MCP Server for interacting with Apify Actors\n- Dynami"])</script><script>self.__next_f.push([1,"cally uses tools based on context and user queries\n- Supports secure connections with Authorization headers and API keys\n- Open source for review and modification\n\n## Use cases of Tester MCP Client? \n1. Testing any MCP server over SSE.\n2. Interacting with Apify Actors to perform various tasks.\n3. Facilitating real-time communication with an MCP server.\n\n## FAQ from Tester MCP Client? \n- Is the Tester MCP Client free to use?  \n\u003e Yes! The Tester MCP Client is free to use, but you pay for the resources consumed on the Apify platform.\n\n- How do I run the Tester MCP Client locally?  \n\u003e Clone the repository, install dependencies, create a .env file with your API token, and run the client using npm start.35:Te07,# AIæ™ºèƒ½ä½“é¡¹ç›®\nè¿™æ˜¯ä¸€ä¸ªåŸºäºSpring AIæ¡†æ¶æ„å»ºçš„AIæ™ºèƒ½ä½“é¡¹ç›®ï¼Œæ—¨åœ¨å±•ç¤ºå¦‚ä½•ç»“åˆRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ã€Tool Callingã€å¤šæ¨¡æ€å†…å®¹å¤„ç†ï¼ˆMCPï¼‰ä»¥åŠAgentæŠ€æœ¯æ¥æ„å»ºå¼ºå¤§çš„æ™ºèƒ½åº”ç”¨ã€‚\n\n# æ¨¡å‹ä¸€ï¼šAIå­¦ä¹ æ™ºèƒ½ä½“\nä½¿ç”¨RAGã€Tool Callingå’ŒMCPï¼Œä¸»è¦è§£å†³ç®€å•çš„è®¡ç®—æœºå­¦ä¹ é—®é¢˜ï¼Œè°ƒç”¨çŸ¥è¯†åº“è·å–å¤–éƒ¨çŸ¥è¯†ï¼Œæ›´æ”¹SystemPromptå’ŒçŸ¥è¯†åº“å°±å¯ä»¥è·å¾—ä¸€ä¸ªä½ çš„ä¸“å±AI\n# æ¨¡å‹äºŒï¼šAIè¶…çº§æ™ºèƒ½ä½“\nä½¿ç”¨CoTæ€ç»´é“¾ï¼ŒReActæ€è€ƒè¡ŒåŠ¨ï¼Œå°†ä¸€ä¸ªé—®é¢˜åˆ†è§£å›ç­”ï¼Œè°ƒç”¨å·¥å…·è§£å†³é—®é¢˜\n\n\n## æ ¸å¿ƒæŠ€æœ¯äº®ç‚¹\n### 1. Spring AI\næœ¬é¡¹ç›®é‡‡ç”¨Spring AIä½œä¸ºæ ¸å¿ƒæ¡†æ¶ï¼Œå®ƒæä¾›äº†ä¸€å¥—ç®€æ´ã€ç»Ÿä¸€çš„APIï¼Œç”¨äºé›†æˆå„ç§AIæ¨¡å‹ï¼ˆå¦‚OpenAIã€Hugging Faceç­‰ï¼‰ã€‚é€šè¿‡Spring AIï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°è¿›è¡Œæ–‡æœ¬ç”Ÿæˆã€åµŒå…¥ã€å›¾åƒå¤„ç†ç­‰æ“ä½œï¼Œæå¤§åœ°ç®€åŒ–äº†AIåº”ç”¨çš„å¼€å‘ã€‚\n\n### 2. RAG (Retrieval Augmented Generation)\nä¸ºäº†å¢å¼ºAIæ¨¡å‹çš„çŸ¥è¯†å¹¿åº¦å’Œå‡†ç¡®æ€§ï¼Œæœ¬é¡¹ç›®é›†æˆäº†RAGæŠ€æœ¯ã€‚é€šè¿‡RAGï¼ŒAIæ™ºèƒ½ä½“èƒ½å¤Ÿä»å¤–éƒ¨çŸ¥è¯†åº“ï¼ˆä¾‹å¦‚é¡¹ç›®ä¸­çš„SQLæ•°æ®åº“ã€PDFæ–‡æ¡£ç­‰ï¼‰ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥ç»™è¯­è¨€æ¨¡å‹ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®ã€æ›´å…·ä¿¡æ¯é‡çš„å›å¤ã€‚è¿™å¯¹äºå¤„ç†ç‰¹å®šé¢†åŸŸçŸ¥è¯†æˆ–å®æ—¶æ•°æ®éå¸¸æœ‰ç”¨ã€‚\n\n### 3. Tool Calling\næ™ºèƒ½ä½“é€šè¿‡Tool Callingèƒ½åŠ›ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤æˆ–å½“å‰ä»»åŠ¡çš„éœ€è¦ï¼ŒåŠ¨æ€åœ°è°ƒç”¨å¤–éƒ¨å·¥å…·æˆ–æœåŠ¡æ¥å®Œæˆå¤æ‚çš„æ“ä½œã€‚ä¾‹å¦‚ï¼Œæ™ºèƒ½ä½“å¯ä»¥è°ƒç”¨æ•°æ®åº“æŸ¥è¯¢å·¥å…·æ¥è·å–æ•°æ®ï¼Œæˆ–è€…è°ƒç”¨æ–‡ä»¶å¤„ç†å·¥å…·æ¥è§£ææ–‡æ¡£ã€‚è¿™ä½¿å¾—æ™ºèƒ½ä½“ä¸ä»…é™äºæ–‡æœ¬äº¤äº’ï¼Œè¿˜èƒ½ä¸å¤–éƒ¨ç³»ç»Ÿè¿›è¡Œæ·±åº¦é›†æˆã€‚\n\n### 4. MCP (Multi-modal Content Processing)\næœ¬é¡¹ç›®æ”¯æŒå¤šæ¨¡æ€å†…å®¹å¤„ç†ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å›¾ç‰‡å’ŒPDFæ–‡æ¡£ã€‚é€šè¿‡MCPï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿç†è§£å’Œå¤„ç†ä¸åŒæ ¼å¼çš„ä¿¡æ¯ï¼Œä¾‹å¦‚ä»PDFä¸­æå–æ–‡æœ¬å†…å®¹ï¼Œæˆ–è€…å¯¹å›¾ç‰‡è¿›è¡Œåˆ†æã€‚è¿™ä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿå¤„ç†æ›´ä¸°å¯Œçš„ç”¨æˆ·è¾“å…¥å’Œè¾“å‡ºã€‚\n\n### 5. Agent\næœ¬é¡¹ç›®ä¸­çš„AIæ™ºèƒ½ä½“ï¼ˆAgentï¼‰æ˜¯æ ¸å¿ƒç»„ä»¶ï¼Œå®ƒèƒ½å¤Ÿç†è§£ç”¨æˆ·æ„å›¾ï¼Œè§„åˆ’æ‰§è¡Œæ­¥éª¤ï¼Œå¹¶åˆ©ç”¨RAGã€Tool Callingå’ŒMCPç­‰èƒ½åŠ›æ¥å®Œæˆä»»åŠ¡ã€‚Agentçš„è®¾è®¡ä½¿å¾—ç³»ç»Ÿå…·å¤‡äº†æ›´å¼ºçš„è‡ªä¸»æ€§å’Œé—®é¢˜è§£å†³èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ä¸šåŠ¡é€»è¾‘å’Œç”¨æˆ·è¯·æ±‚ã€‚\n\n### é¡¹ç›®å±•ç¤º\n![image](https://github.com/user-attachments/assets/faac2f40-0b76-43ef-9201-2083b277ebc3)\n![image](https://github.com/user-attachments/assets/ba5852c7-750b-4348-a4f9-9d6c9a0f7372)\n![image](https://github.com/user-attachments/assets/ed5125c3-68f8-42a0-bd1f-3ee4201691ae)\n\n\n## é¡¹ç›®ç»“æ„æ¦‚è§ˆ\n```\n.gitignore\n.mvn/\nchatMemory/\npom.xml\nsql/\nâ”œâ”€â”€Â table.sql\nsrc/\nâ”œâ”€â”€Â main/\nâ”‚Â Â Â â”œâ”€â”€Â java/\nâ”‚Â Â Â â””â”€â”€Â resources/\nâ””â”€â”€Â test/\nÂ Â Â Â â””â”€â”€Â java/\ntmp/\nâ”œâ”€â”€Â files/\nâ”œâ”€â”€Â pdf/\nâ””â”€â”€Â resource/\nzxc-agent-picture-search-mcp-server/Â Â #Â å¯èƒ½åŒ…å«å›¾ç‰‡æœç´¢å’Œå¤šæ¨¡æ€å†…\nå®¹å¤„ç†ç›¸å…³æœåŠ¡\nâ”œâ”€â”€Â .gitignore\nâ”œâ”€â”€Â .mvn/\nâ”œâ”€â”€Â pom.xml\nâ””â”€â”€Â src/\nÂ Â Â Â â”œâ”€â”€Â main/\nÂ Â Â Â â””â”€â”€Â test/\nzxcAgent-Front/Â #Â å‰ç«¯é¡¹ç›®ï¼Œå¯èƒ½ç”¨äºå±•ç¤ºæ™ºèƒ½ä½“äº¤äº’ç•Œé¢\nâ”œâ”€â”€Â .gitignore\nâ”œâ”€â”€Â README.md\nâ”œâ”€â”€Â index.html\nâ”œâ”€â”€Â package-lock.json\nâ”œâ”€â”€Â package.json\nâ”œâ”€â”€Â public/\nâ”‚Â Â Â â””â”€â”€Â vite.svg\nâ”œâ”€â”€Â src/\nâ”‚Â Â Â â”œâ”€â”€Â "])</script><script>self.__next_f.push([1,"App.vue\nâ”‚Â Â Â â”œâ”€â”€Â assets/\nâ”‚Â Â Â â”œâ”€â”€Â components/\nâ”‚Â Â Â â”œâ”€â”€Â main.js\nâ”‚Â Â Â â”œâ”€â”€Â router/\nâ”‚Â Â Â â”œâ”€â”€Â style.css\nâ”‚Â Â Â â””â”€â”€Â views/\nâ””â”€â”€Â vite.config.js\n```36:T5d8,## what is AI-Agent-Zxc? \nAI-Agent-Zxc is an AI agent project built on the Spring AI framework, designed to demonstrate how to create powerful intelligent applications by integrating Retrieval Augmented Generation (RAG), Tool Calling, Multi-modal Content Processing (MCP), and Agent technologies.\n\n## how to use AI-Agent-Zxc? \nTo use AI-Agent-Zxc, you can interact with the agent through a user interface that allows you to input queries or commands, and the agent will utilize its capabilities to provide solutions or perform tasks.\n\n## key features of AI-Agent-Zxc? \n- Integration of RAG for enhanced knowledge retrieval\n- Dynamic Tool Calling for executing complex operations\n- Multi-modal Content Processing for handling various data formats\n- Autonomous Agent capable of understanding user intent and executing tasks\n\n## use cases of AI-Agent-Zxc? \n1. Solving complex computer science problems using external knowledge bases.\n2. Automating data retrieval and processing tasks in various applications.\n3. Assisting users with multi-modal queries involving text, images, and documents.\n\n## FAQ from AI-Agent-Zxc? \n- What technologies does AI-Agent-Zxc use?\n\u003e AI-Agent-Zxc utilizes Spring AI, RAG, Tool Calling, and MCP technologies to enhance its functionality.\n\n- Can AI-Agent-Zxc handle different types of data?\n\u003e Yes! It supports various formats including text, images, and PDFs.\n\n- Is AI-Agent-Zxc open-source?\n\u003e Yes! The project is available on GitHub for public access and contributions.37:T48e,# mcp-cli\n\nA CLI inspector for the Model Context Protocol\n\nhttps://github.com/user-attachments/assets/4cd113e9-f097-4c9d-b391-045c5f213183\n\n## Features\n\n- Run MCP servers from various sources\n- List Tools, Resources, Prompts\n- Call Tools, Read Resources, Read Prompts\n- OAuth support for SSE and Streamable HTTP servers\n\n## Usage\n\n### Run without arguments\n\n```bash\nnpx @wong2/mcp-cli\n```\n\nThis will use the config file of Claude Desktop.\n\n### Run with a config file\n\n```bash\nnpx @wong2/mcp-cli -c config.json\n```\n\nThe config file has the same format as the Claude Desktop config file.\n\n### Run servers from NPM\n\n```bash\nnpx @wong2/mcp-cli npx \u003cpackage-name\u003e \u003cargs\u003e\n```\n\n### Run locally developed server\n\n```bash\nnpx @wong2/mcp-cli node path/to/server/index.js args...\n```\n\n### Connect to a running server over Streamable HTTP\n\n```bash\nnpx @wong2/mcp-cli --url http://localhost:8000/mcp\n```\n\n### Connect to a running server over SSE\n\n```bash\nnpx @wong2/mcp-cli --sse http://localhost:8000/sse\n```\n\n### Purge stored data (OAuth tokens, etc.)\n\n```bash\nnpx @wong2/mcp-cli purge\n```\n\n## Related\n\n- [mcpservers.org](https://mcpservers.org) - A curated list of MCP servers38:T5cd,## what is mcp-cli? \n mcp-cli is a command-line interface (CLI) inspector designed for the Model Context Protocol (MCP), providing users with tools to interact with and manage MCP servers. \n\n## how to use mcp-cli? \n To use mcp-cli, you can run it with or without a configuration file. \n - To run without a config file, use: `npx @wong2/mcp-cli` (this will use the default config). \n - To specify a config file, use: `npx @wong2/mcp-cli -c config.json`. \n - You can also run MCP servers from NPM or locally developed servers with the provided commands in the documentation. \n\n## key features of mcp-cli? \n - Ability to run MCP servers from multiple sources. \n - Lists available Tools, Resources, and Prompts. \n - Facilitates calling Tools, reading Resources, and accessing Prompts. \n\n## use cases of mcp-cli? \n 1. Inspecting and managing various MCP servers in a development environment. \n 2. Testing and launching tools and resources integrated with the Model Context Protocol. \n 3. Assisting developers in working with the Claude Desktop system and its configurations. \n\n## FAQ from mcp-cli? \n - Does mcp-cli work with any MCP server? \n \u003e Yes, as long as the server adheres to the Model Context Prot"])</script><script>self.__next_f.push([1,"ocol. \n - Is there a default configuration for mcp-cli? \n \u003e Yes, it can run with a default config file used by Claude Desktop if none is specified. \n - Can I develop my own servers with mcp-cli? \n \u003e Yes, you can run locally developed servers by providing the path to the server script.39:T2be4,![A yellow square with the word \"gen\" in lowercase black letters above the uppercase black letters \"AI.\"](./docs/public/images/favicon.png)\n\n# GenAIScript\n\n## Prompting is Coding\n\nProgrammatically assemble prompts for LLMs using JavaScript. Orchestrate LLMs, tools, and data in code.\n\n- JavaScript toolbox to work with prompts\n- Abstraction to make it easy and productive\n- Seamless Visual Studio Code integration or flexible command line\n- Built-in support for GitHub Copilot and GitHub Models, OpenAI, Azure OpenAI, Anthropic, and more\n\n- ğŸ“„ **Read the ONLINE DOCUMENTATION at [microsoft.github.io/genaiscript](https://microsoft.github.io/genaiscript/)**\n- ğŸ’¬ Join the [Discord server](https://discord.gg/y7HpumjHeB)\n- ğŸ“ Read the [blog](https://microsoft.github.io/genaiscript/blog/) for the latest news\n- ğŸ“º Watch [Mr. Maeda's Cozy AI Kitchen](https://youtu.be/ajEbAm6kjI4)\n- ğŸ¤– Agents - read the [llms-full.txt](https://microsoft.github.io/genaiscript/llms-full.txt)\n\n---\n\n## Hello world\n\nSay to you want to create an LLM script that generates a 'hello world' poem. You can write the following script:\n\n```js\n$`Write a 'hello world' poem.`\n```\n\nThe `$` function is a template tag that creates a prompt. The prompt is then sent to the LLM (you configured), which generates the poem.\n\nLet's make it more interesting by adding files, data and structured output. Say you want to include a file in the prompt, and then save the output in a file. You can write the following script:\n\n```js\n// read files\nconst file = await workspace.readText(\"data.txt\")\n// include the file content in the prompt in a context-friendly way\ndef(\"DATA\", file)\n// the task\n$`Analyze DATA and extract data in JSON in data.json.`\n```\n\nThe `def` function includes the content of the file, and optimizes it if necessary for the target LLM. GenAIScript script also parses the LLM output\nand will extract the `data.json` file automatically.\n\n---\n\n## ğŸš€ Quickstart Guide\n\nGet started quickly by installing the [Visual Studio Code Extension](https://microsoft.github.io/genaiscript/getting-started/installation/) or using the [command line](https://microsoft.github.io/genaiscript/getting-started/installation).\n\n---\n\n## âœ¨ Features\n\n### ğŸ¨ Stylized JavaScript \u0026 TypeScript\n\nBuild prompts programmatically using [JavaScript](https://microsoft.github.io/genaiscript/reference/scripts/) or [TypeScript](https://microsoft.github.io/genaiscript/reference/scripts/typescript).\n\n```js\ndef(\"FILE\", env.files, { endsWith: \".pdf\" })\n$`Summarize FILE. Today is ${new Date()}.`\n```\n\n---\n\n### ğŸš€ Fast Development Loop\n\nEdit, [Debug](https://microsoft.github.io/genaiscript/getting-started/debugging-scripts/), [Run](https://microsoft.github.io/genaiscript/getting-started/running-scripts/), and [Test](https://microsoft.github.io/genaiscript/getting-started/testing-scripts/) your scripts in [Visual Studio Code](https://microsoft.github.io/genaiscript/getting-started/installation) or with the [command line](https://microsoft.github.io/genaiscript/getting-started/installation).\n\n---\n\n### ğŸ”— Reuse and Share Scripts\n\nScripts are [files](https://microsoft.github.io/genaiscript/reference/scripts/)! They can be versioned, shared, and forked.\n\n```js\n// define the context\ndef(\"FILE\", env.files, { endsWith: \".pdf\" })\n// structure the data\nconst schema = defSchema(\"DATA\", { type: \"array\", items: { type: \"string\" } })\n// assign the task\n$`Analyze FILE and extract data to JSON using the ${schema} schema.`\n```\n\n---\n\n### ğŸ“‹ Data Schemas\n\nDefine, validate, and repair data using [schemas](https://microsoft.github.io/genaiscript/reference/scripts/schemas). Zod support builtin.\n\n```js\nconst data = defSchema(\"MY_DATA\", { type: \"array\", items: { ... } })\n$`Extract data from files using ${data} schema.`\n```\n\n---\n\n### ğŸ“„ Ing"])</script><script>self.__next_f.push([1,"est Text from PDFs, DOCX, ...\n\nManipulate [PDFs](https://microsoft.github.io/genaiscript/reference/scripts/pdf), [DOCX](https://microsoft.github.io/genaiscript/reference/scripts/docx), ...\n\n```js\ndef(\"PDF\", env.files, { endsWith: \".pdf\" })\nconst { pages } = await parsers.PDF(env.files[0])\n```\n\n---\n\n### ğŸ“Š Ingest Tables from CSV, XLSX, ...\n\nManipulate tabular data from [CSV](https://microsoft.github.io/genaiscript/reference/scripts/csv), [XLSX](https://microsoft.github.io/genaiscript/reference/scripts/xlsx), ...\n\n```js\ndef(\"DATA\", env.files, { endsWith: \".csv\", sliceHead: 100 })\nconst rows = await parsers.CSV(env.files[0])\ndefData(\"ROWS\", rows, { sliceHead: 100 })\n```\n\n---\n\n### ğŸ“ Generate Files\n\nExtract files and diff from the LLM output. Preview changes in Refactoring UI.\n\n```js\n$`Save the result in poem.txt.`\n```\n\n```txt\nFILE ./poem.txt\nThe quick brown fox jumps over the lazy dog.\n```\n\n---\n\n### ğŸ” File Search\n\nGrep or fuzz search [files](https://microsoft.github.io/genaiscript/reference/scripts/files).\n\n```js\nconst { files } = await workspace.grep(/[a-z][a-z0-9]+/, { globs: \"*.md\" })\n```\n\n---\n\n## Classify\n\nClassify text, images or a mix of all.\n\n```js\nconst joke = await classify(\n    \"Why did the chicken cross the road? To fry in the sun.\",\n    {\n        yes: \"funny\",\n        no: \"not funny\",\n    }\n)\n```\n\n### LLM Tools\n\nRegister JavaScript functions as [tools](https://microsoft.github.io/genaiscript/reference/scripts/tools)\n(with fallback for models that don't support tools). [Model Context Protocol (MCP) tools](https://microsoft.github.io/genaiscript/reference/scripts/mcp-tools) are also supported.\n\n```js\ndefTool(\n    \"weather\",\n    \"query a weather web api\",\n    { location: \"string\" },\n    async (args) =\u003e\n        await fetch(`https://weather.api.api/?location=${args.location}`)\n)\n```\n\n---\n\n### LLM Agents\n\nRegister JavaScript functions as **tools** and combine tools + prompt into agents.\n\n```js\ndefAgent(\n    \"git\",\n    \"Query a repository using Git to accomplish tasks.\",\n    `Your are a helpful LLM agent that can use the git tools to query the current repository.\n    Answer the question in QUERY.\n    - The current repository is the same as github repository.`,\n    { model, system: [\"system.github_info\"], tools: [\"git\"] }\n)\n```\n\nthen use it as a tool\n\n```js\nscript({ tools: \"agent_git\" })\n\n$`Do a statistical analysis of the last commits`\n```\n\nSee the [git agent source](https://github.com/microsoft/genaiscript/blob/main/packages/cli/genaisrc/system.agent_git.genai.mts).\n\n---\n\n### ğŸ” RAG Built-in\n\n[Vector search](https://microsoft.github.io/genaiscript/reference/scripts/vector-search/).\n\n```js\nconst { files } = await retrieval.vectorSearch(\"cats\", \"**/*.md\")\n```\n\n---\n\n### ğŸ™ GitHub Models and GitHub Copilot\n\nRun models through [GitHub Models](https://microsoft.github.io/genaiscript/configuration/github) or [GitHub Copilot](https://microsoft.github.io/genaiscript/configuration/github-copilot-chat).\n\n```js\nscript({ ..., model: \"github:gpt-4o\" })\n```\n\n---\n\n### ğŸ’» Local Models\n\nRun your scripts with [Open Source models](https://microsoft.github.io/genaiscript/getting-started/configuration/), like [Phi-3](https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/), using [Ollama](https://ollama.com/), [LocalAI](https://localai.io/).\n\n```js\nscript({ ..., model: \"ollama:phi3\" })\n```\n\n---\n\n### ğŸ Code Interpreter\n\nLet the LLM run code in a sand-boxed execution environment.\n\n```js\nscript({ tools: [\"python_code_interpreter\"] })\n```\n\n---\n\n### ğŸ³ Containers\n\nRun code in Docker [containers](https://microsoft.github.io/genaiscript/reference/scripts/container).\n\n```js\nconst c = await host.container({ image: \"python:alpine\" })\nconst res = await c.exec(\"python --version\")\n```\n\n---\n\n### Video processing\n\nTranscribe and screenshot your videos so that you can feed them efficiently in your LLMs requests.\n\n```js\n// transcribe\nconst transcript = await transcript(\"path/to/audio.mp3\")\n// screenshots at segments\nconst frames = await ffmpeg.extractFrames(\"path_url_to_video\", { transcript })\ndef(\"TR"])</script><script>self.__next_f.push([1,"ANSCRIPT\", transcript)\ndef(\"FRAMES\", frames)\n```\n\n### ğŸ§© LLM Composition\n\n[Run LLMs](https://microsoft.github.io/genaiscript/reference/scripts/inline-prompts/) to build your LLM prompts.\n\n```js\nfor (const file of env.files) {\n    const { text } = await runPrompt((_) =\u003e {\n        _.def(\"FILE\", file)\n        _.$`Summarize the FILE.`\n    })\n    def(\"SUMMARY\", text)\n}\n$`Summarize all the summaries.`\n```\n\n---\n\n### ğŸ…¿ï¸ Prompty support\n\nRun your [Prompty](https://prompty.ai) files as well!\n\n```markdown\n---\nname: poem\n---\n\nWrite me a poem\n```\n\n---\n\n### Pluggable Secret Scanning\n\nScan your chats for secrets using [secret scanning](/genaiscript/reference/scripts/secret-scanning).\n\n```json\n{\n    \"secretPatterns\": {\n        ...,\n        \"OpenAI API Key\": \"sk-[A-Za-z0-9]{32,48}\"\n    }\n}\n```\n\n### âš™ Automate with CLI or API\n\nAutomate using the [CLI](https://microsoft.github.io/genaiscript/reference/cli) or [API](https://microsoft.github.io/genaiscript/reference/api).\n\n```bash\nnpx genaiscript run tlaplus-linter \"*.tla\"\n```\n\n```js\nimport { run } from \"genaiscript/api\"\n\nconst res = await run(\"tlaplus-linter\", \"*.tla\")\n```\n\n---\n\n### Safety First!\n\nGenAIScript provides built-in Responsible AI system prompts and Azure Content Safety supports\nto validate [content safety](https://microsoft.github.io/genaiscript/reference/scripts/content-safety).\n\n```js wrap\nscript({ ...,\n    system: [\"system.safety_harmful_content\", ...],\n    contentSafety: \"azure\" // use azure content safety\n})\n\nconst safety = await host.contentSafety()\nconst res = await safety.detectPromptInjection(env.vars.input)\n```\n\n---\n\n### ğŸ’¬ Pull Request Reviews\n\nIntegrate into your [Pull Requests checks](https://microsoft.github.io/genaiscript/reference/cli/run/#pull-requests) through comments, reviews, or description updates. Supports GitHub Actions and Azure DevOps pipelines.\n\n```bash wrap\nnpx genaiscript ... --pull-request-reviews\n```\n\n---\n\n### â­ Tests and Evals\n\nBuild reliable prompts using [tests and evals](https://microsoft.github.io/genaiscript/reference/scripts/tests) powered by [promptfoo](https://promptfoo.dev/).\n\n```js wrap\nscript({ ..., tests: {\n  files: \"penguins.csv\",\n  rubric: \"is a data analysis report\",\n  facts: \"The data refers about penguin population in Antarctica.\",\n}})\n```\n\n---\n\n### LLM friendly docs\n\nThe entire content of the docs is rendered at https://microsoft.github.io/genaiscript/llms-full.txt in markdown. Feed it directly into your favorite RAG system.\n\nIf you are an LLM crawler, add the `.md` suffix to any documentation URLs to get a raw markdown content. For example, https://microsoft.github.io/genaiscript/guides/prompt-as-code.md (note the .md extension)\n\n## Contributing\n\nWe accept contributions! Checkout the [CONTRIBUTING](./CONTRIBUTING.md) page for details and developer setup.\n\n---\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark \u0026 Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.3a:T49d,## What is GenAIScript?  \nGenAIScript is a tool that allows users to programmatically assemble prompts for large language models (LLMs) using JavaScript, enabling automation of GenAI scripting.  \n\n## How to use GenAIScript?  \nTo use GenAIScript, install the Visual Studio Code extension or use the command line interface to create scripts that interact with LLMs.  \n\n## Key features of GenAIScript?  \n- JavaScript toolbox for prompt creation  \n- Seamless integration with Visual Studio Code  \n- Ability to read and manipulate files, including PDFs and CSVs  \n- Support for defining and validating data schemas  \n\n## Use cases of GenAIScript?  \n1. Automating data extraction from documents  \n2. Generating structured outputs from LLMs  \n3. Creating in"])</script><script>self.__next_f.push([1,"teractive scripts for data analysis  \n\n## FAQ from GenAIScript?  \n- Can GenAIScript handle all types of files?  \n\u003e Yes! GenAIScript can read and manipulate various file types including PDFs, DOCX, and CSV.  \n\n- Is GenAIScript free to use?  \n\u003e Yes! GenAIScript is open-source and free to use.  \n\n- How can I contribute to GenAIScript?  \n\u003e Contributions are welcome! Please check the contributing guidelines on the GitHub repository.3b:Td46,# MCP Client Application\n\nA desktop application for interacting with AI models via the Model Context Protocol (MCP), providing a powerful interface for chat conversations with tool execution capabilities.\n\n## What is MCP?\n\nThe Model Context Protocol (MCP) is a standardized communication protocol that enables AI models to request execution of tools and functions with user confirmation. This creates a secure and transparent environment for AI assistants to interact with your system while maintaining user control.\n\n## Features\n\n- ğŸ¤– **Multi-model support**: Connect to Claude, GPT, and other LLMs through a unified interface\n- ğŸ”§ **Tool execution**: Allow AI models to perform actions through a secure permission system\n- ğŸ”„ **Real-time streaming**: Experience fluid conversations with streaming responses\n- ğŸ”Œ **Server management**: Register, configure and connect to MCP servers\n- ğŸ’¾ **Conversation history**: Save and revisit your chat sessions\n- ğŸ” **Secure vault**: Store sensitive information like API keys safely\n\n## Why Use MCP Client?\n\nMCP Client demonstrates how to create applications that leverage the full potential of modern AI systems while maintaining appropriate security boundaries. It serves as both a practical tool and a learning resource for developers interested in building applications with AI capabilities.\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js 18+\n- npm package manager\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone git@github.com:RegiByte/mcp-client-app.git\ncd mcp-client-app\n\n# Install dependencies\nnpm install\n\n# Start the development server\nnpm dev\n```\n\n### Building for Production\n\n```bash\n# For Windows\nnpm build:win\n\n# For macOS\nnpm build:mac\n\n# For Linux\nnpm build:linux\n```\n\n## Using the Application\n\n### Starting a Conversation\n\n1. Open the application\n2. Navigate to the conversations page\n3. Click on \"New conversation\"\n4. Start chatting!\n\n### Working with Tools\n\nWhen an AI assistant needs to perform an action:\n\n1. You'll see a tool execution request in the chat\n2. Review the requested action and parameters\n3. Approve or deny the request\n4. See the results integrated back into the conversation\n\n## Architecture Overview\n\nThe MCP Client App is built with:\n\n- **Electron**: For cross-platform desktop capabilities\n- **React**: For the user interface\n- **TypeScript**: For type-safe code\n- **Vercel AI SDK**: For standardized AI model interactions\n- **Model Context Protocol**: For secure and standardized tool execution\n\nThe application uses a driver pattern to support multiple LLM providers while maintaining a consistent interface.\n\n## Learning Resources\n\n- [MCP Protocol Documentation](https://modelcontextprotocol.github.io/)\n- [Vercel AI SDK Guide](https://sdk.vercel.ai/docs)\n- [Building MCP-enabled Applications](https://yourwebsite.com/tutorials)\n- [Tool Development Guide](https://yourwebsite.com/tool-guide)\n\n## Contributing\n\nWe welcome contributions to the MCP Client App! Please see our [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- The Anthropic team for Claude and MCP\n- Vercel for the AI SDK\n- The Electron community for the application framework\n\n---\n\n_Project maintained by [@RegiByte](https://github.com/RegiByte). For support, open an issue on the repository._3c:T675,## What is MCP Client Application? \nThe MCP Client Application is a desktop application designed for interacting with AI models via the Model Context Protocol (MCP), providing a powerful interface for chat conversations with tool execution capabilitie"])</script><script>self.__next_f.push([1,"s.\n\n## How to use MCP Client Application? \nTo use the MCP Client Application, clone the repository, install the dependencies, and start the development server. You can then open the application, navigate to the conversations page, and start chatting.\n\n## Key features of MCP Client Application? \n- Multi-model support for connecting to various AI models like Claude and GPT.\n- Tool execution capabilities with a secure permission system.\n- Real-time streaming for fluid conversations.\n- Server management for registering and connecting to MCP servers.\n- Conversation history to save and revisit chat sessions.\n- Secure vault for storing sensitive information like API keys.\n\n## Use cases of MCP Client Application? \n1. Engaging in conversations with AI models for various tasks.\n2. Executing tools through AI assistants with user approval.\n3. Learning how to build applications that leverage AI capabilities securely.\n\n## FAQ from MCP Client Application? \n- What is the Model Context Protocol (MCP)?\n\u003e MCP is a standardized communication protocol that allows AI models to request execution of tools and functions with user confirmation.\n\n- Is the MCP Client Application free to use?\n\u003e Yes! The MCP Client Application is open-source and free to use.\n\n- What technologies are used in the MCP Client Application?\n\u003e The application is built with Electron, React, TypeScript, and utilizes the Vercel AI SDK.3d:T2c05,\u003cp align=\"center\"\u003e\n  \u003cimg src=\"GITCLAP.png\" alt=\"CLAP Logo\" width=\"700\" height=\"200\"/\u003e\n\u003c/p\u003e\n\n# CLAP - Cognitive Layer Agent Package\n\n[![PyPI version](https://img.shields.io/pypi/v/clap-agents.svg)](https://pypi.org/project/clap-agents/) \n[![License: Apache 2.0](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Python Version](https://img.shields.io/pypi/pyversions/clap-agents.svg)](https://pypi.org/project/clap-agents/) \n\n**CLAP (Cognitive Layer Agent Package)** is a Python framework providing building blocks for creating sophisticated AI agents based on modern agentic patterns. It enables developers to easily construct agents capable of reasoning, planning, and interacting with external tools, systems, and knowledge bases.\n\nBuilt with an asynchronous core (`asyncio`), CLAP offers flexibility and performance for complex agentic workflows.\n\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"PIP CLAP.png\" alt=\"CLAP Pip Install\" width=\"700\" height=\"200\"/\u003e \u003c!-- Updated alt text --\u003e\n\u003c/p\u003e\n\n## Key Features\n\n*   **Modular Agent Patterns:**\n    *   **ReAct Agent:** Implements the Reason-Act loop with robust thought-prompting and native tool calling. Ideal for complex reasoning and RAG.\n    *   **Tool Agent:** A straightforward agent for single-step tool usage, including simple RAG.\n    *   **Multi-Agent Teams:** Define teams of specialized agents with dependencies, enabling collaborative task execution (sequential or parallel).\n*   **Advanced Tool Integration:**\n    *   **Native LLM Tool Calling:** Leverages modern LLM APIs for reliable tool execution.\n    *   **Local Tools:** Easily define and use local Python functions (both synchronous and asynchronous) as tools using the `@tool` decorator.\n    *   **Remote Tools (MCP):** Integrates with [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) servers via the included `MCPClientManager`, allowing agents to discover and use tools exposed by external systems (currently supports SSE transport).\n    *   **Robust Validation \u0026 Coercion:** Uses `jsonschema` for strict validation of tool arguments and attempts type coercion for common LLM outputs (e.g., string numbers to integers).\n*   **Retrieval Augmented Generation (RAG) Capabilities:**\n    *   **`VectorStoreInterface`:** An abstraction for interacting with various vector databases.\n    *   **Supported Vector Stores:**\n        *   **ChromaDB:** (`ChromaStore`) For local or self-hosted vector storage.\n        *   **Qdrant:** (`QdrantStore`) For local (in-memory or file-based) vector storage.\n    *   **`EmbeddingFunctionInterface`:** A protocol for consistent interaction with different embedding models.\n   "])</script><script>self.__next_f.push([1," *   **Supported Embedding Function Wrappers:**\n        *   `SentenceTransformerEmbeddings`: Uses models from the `sentence-transformers` library.\n        *   `OllamaEmbeddings`: Generates embeddings using models running locally via Ollama.\n        *   `FastEmbedEmbeddings`: Utilizes the `fastembed` library for CPU-optimized embeddings. (Note: Performance for very large batch ingestions via the async wrapper might vary based on CPU and may be slower than SentenceTransformers for initial bulk loads.)\n    *   **RAG-Aware Agents:** Both `Agent` (via `ReactAgent`) and `ToolAgent` can be equipped with a `vector_store` to perform `vector_query` tool calls, enabling them to retrieve context before responding.\n    *   **Utilities:** Includes basic PDF and CSV text loaders and chunking strategies in `clap.utils.rag_utils`.\n*   **Pluggable LLM Backends:**\n    *   Uses a **Strategy Pattern** (`LLMServiceInterface`) to abstract LLM interactions.\n    *   Includes ready-to-use service implementations for:\n        *   **Groq:** (`GroqService`)\n        *   **Google Generative AI (Gemini):** (`GoogleOpenAICompatService` via OpenAI compatibility layer)\n        *   **Ollama (Local LLMs):** (`OllamaOpenAICompatService` also known as `OllamaService` via OpenAI compatibility layer, allowing use of locally run models like Llama 3, Mistral, etc.)\n    *   Easily extensible to support other LLM providers.\n*   **Asynchronous Core:** Built entirely on `asyncio` for efficient I/O operations and potential concurrency.\n*   **Structured Context Passing:** Enables clear and organized information flow between agents in a team.\n*   **Built-in Tools:** Includes helpers for web search (`duckduckgo_search`). More available via optional dependencies.\n\n## Installation\n\nEnsure you have Python 3.10 or later installed.\n\n```bash\npip install clap-agents\n```\n\nEnsure you have Python 3.10 or later installed.\n\n```bash\npip install clap-agents\n\n\nTo use specific features, you might need to install optional dependencies:\n# For Qdrant support (includes fastembed)\npip install \"clap-agents[qdrant]\"\n\n# For ChromaDB support\npip install \"clap-agents[chromadb]\"\n\n# For Ollama (LLM and/or Embeddings)\npip install \"clap-agents[ollama]\"\n\n# For other tools like web crawling or visualization\npip install \"clap-agents[standard_tools,viz]\"\n\n# To install all major optional dependencies\npip install \"clap-agents[all]\"\n```\n\n\nCheck the pyproject.toml for the full list of [project.optional-dependencies]. You will also need to have external services like Ollama or Qdrant (if used locally) running.\nDepending on the tools or LLM backends you intend to use, you might need additional dependencies listed in the pyproject.toml (e.g., groq, openai, mcp, jsonschema, requests, duckduckgo-search, graphviz). Check the [project.dependencies] and [project.optional-dependencies] sections.\n\n\n## Quick Start: Simple Tool calling Agent with a Local Tool\nThis example demonstrates creating a Tool calling agent using the Groq backend and a local tool\n\n```\nfrom dotenv import load_dotenv\nfrom clap import ToolAgent\nfrom clap import duckduckgo_search\n\nload_dotenv()\n\nasync def main():\n    agent = ToolAgent(tools=duckduckgo_search, model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n    user_query = \"Search the web for recent news about AI advancements.\"\n    response = await agent.run(user_msg=user_query)\n    print(f\"Response:\\n{response}\")\n\nasyncio.run(main())\n```\n\n\n## Quick Start: Simple ReAct Agent with a Local Tool\nThis example demonstrates creating a ReAct agent using the Groq backend and a local tool.\n\n```\nimport asyncio\nimport os\nfrom dotenv import load_dotenv\nfrom clap import ReactAgent, tool, GroqService\n\nload_dotenv() \n@tool\ndef get_word_length(word: str) -\u003e int:\n    \"\"\"Calculates the length of a word.\"\"\"\n    print(f\"[Local Tool] Calculating length of: {word}\")\n    return len(word)\n\nasync def main():\n    groq_service = GroqService() # Your service of choice (either groq or Google)\n    agent = ReactAgent(\n        llm_service=groq_service,\n        model=\"llama-3.3-70b-versatile\", # Or another Groq model\n        tool"])</script><script>self.__next_f.push([1,"s=[get_word_length], # Provide the local tool\n        # system_prompt=\"You are a helpful assistant.\" # Optional base prompt\n    )\n\n    user_query = \"How many letters are in the word 'framework'?\"\n    response = await agent.run(user_msg=user_query)\n    \n    print(response)\n    \nasyncio.run(main())\n```\n\n## Quick Start: Simple Tool-Calling Agent with Ollama\nThis example demonstrates a ToolAgent using a local Ollama model and a local tool.\nEnsure Ollama is running and you have pulled the model (e.g., ollama pull llama3).\n\n```\nimport asyncio\nfrom dotenv import load_dotenv\nfrom clap import ToolAgent, tool, OllamaService # Assuming OllamaService is your OllamaOpenAICompatService\n\nload_dotenv()\n\n@tool\ndef get_capital(country: str) -\u003e str:\n    \"\"\"Returns the capital of a country.\"\"\"\n    if country.lower() == \"france\": return \"Paris\"\n    return f\"I don't know the capital of {country}.\"\n\nasync def main():\n    # Initialize the Ollama service\n    ollama_llm_service = OllamaService(default_model=\"llama3\") # Specify your Ollama model\n\n    agent = ToolAgent(\n        llm_service=ollama_llm_service,\n        model=\"llama3\", # Model name for this agent\n        tools=[get_capital]\n    )\n    user_query = \"What is the capital of France?\"\n    response = await agent.run(user_msg=user_query)\n    print(f\"Query: {user_query}\\nResponse:\\n{response}\")\n\n    await ollama_llm_service.close() # Important for OllamaService\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n```\n\n## Quick Start: RAG Agent with Qdrant and Ollama Embeddings\nThis example shows an Agent performing RAG using Ollama for embeddings and Qdrant as the vector store.\nEnsure Ollama is running (with nomic-embed-text and llama3 pulled) and Qdrant is running (e.g., via Docker).\n```\nimport asyncio\nimport os\nimport shutil\nfrom dotenv import load_dotenv\nfrom clap import Agent, QdrantStore, OllamaEmbeddings, OllamaService\nfrom clap.utils.rag_utils import chunk_text_by_fixed_size\nfrom qdrant_client import models as qdrant_models # If needed for distance\n\nload_dotenv()\n\nOLLAMA_HOST = \"http://localhost:11434\"\nEMBED_MODEL = \"nomic-embed-text\"\nLLM_MODEL = \"llama3\"\nDB_PATH = \"./temp_rag_db_ollama_qdrant\"\nCOLLECTION = \"my_rag_docs\"\n\nasync def main():\n    if os.path.exists(DB_PATH): shutil.rmtree(DB_PATH)\n\n    ollama_ef = OllamaEmbeddings(model_name=EMBED_MODEL, ollama_host=OLLAMA_HOST)\n    vector_store = await QdrantStore.create(\n        collection_name=COLLECTION,\n        embedding_function=ollama_ef,\n        path=DB_PATH, # For local file-based Qdrant\n        recreate_collection_if_exists=True\n    )\n\n    sample_texts = [\"The sky is blue due to Rayleigh scattering.\", \"Large language models are powerful.\"]\n    chunks = [chunk for text in sample_texts for chunk in chunk_text_by_fixed_size(text, 100, 10)]\n    ids = [str(i) for i in range(len(chunks))] # Qdrant needs UUIDs; QdrantStore handles this\n    \n    if chunks:\n        await vector_store.add_documents(documents=chunks, ids=ids)\n    print(f\"Ingested {len(chunks)} chunks.\")\n\n    ollama_llm_service = OllamaService(default_model=LLM_MODEL, base_url=f\"{OLLAMA_HOST}/v1\")\n    rag_agent = Agent(\n        name=\"RAGMaster\",\n        backstory=\"I answer questions using provided documents.\",\n        task_description=\"Why is the sky blue according to the documents?\", # This becomes the User Query\n        llm_service=ollama_llm_service,\n        model=LLM_MODEL,\n        vector_store=vector_store\n    )\n\n    response = await rag_agent.run()\n    print(f\"Query: {rag_agent.task_description}\\nResponse:\\n{response.get('output')}\")\n\n    await vector_store.close()\n    await ollama_llm_service.close()\n    if os.path.exists(DB_PATH): shutil.rmtree(DB_PATH)\n\nasyncio.run(main())\n```\n\n## Exploring Further\n\n\n# Multi-Agent Teams: See examples/test_clap_comprehensive_suite.py and other team examples for setting up sequential or parallel agent workflows.\n\n# MCP Integration: Check examples/test_clap_comprehensive_suite.py (ensure corresponding MCP servers from examples/simple_mcp.py etc. are running).\n\n# Other LLM Services (Groq, Google Gemini , Ollama): Modify the Quick Starts "])</script><script>self.__next_f.push([1,"to use GroqService or GoogleOpenAICompatService (ensure API keys are set).\n\n# Different Vector Stores \u0026 Embedding Functions: Experiment with ChromaStore, QdrantStore, SentenceTransformerEmbeddings, FastEmbedEmbeddings, and OllamaEmbeddings as shown in the comprehensive test suite.\n\nLicense\nThis project is licensed under the terms of the Apache License 2.0. See the LICENSE file for details.3e:T510,## what is CLAP? \nCLAP (Cognitive Layer Agents Package) is a powerful multi-agent framework built in Python that supports the development of sophisticated AI agents capable of reasoning, planning, and interacting with external tools and systems.\n\n## how to use CLAP? \nTo use CLAP, install it via pip and create agents using the provided modular patterns. You can define local and remote tools, and utilize the asynchronous core for efficient operations.\n\n## key features of CLAP? \n- Modular agent patterns including ReAct and multi-agent teams.\n- Advanced tool integration with native LLM tool calling and local tools.\n- Pluggable LLM backends for flexibility.\n- Asynchronous core for efficient I/O operations.\n- Built-in tools for web search and email interaction.\n\n## use cases of CLAP? \n1. Building AI agents for automated web searches.\n2. Creating collaborative multi-agent systems for complex tasks.\n3. Integrating with external systems using the Model Context Protocol (MCP).\n\n## FAQ from CLAP? \n- Can CLAP be used for any AI project?\n\u003e Yes! CLAP is designed to be flexible and can be adapted for various AI applications.\n\n- Is CLAP free to use?\n\u003e Yes! CLAP is open-source and available under the Apache 2.0 license.\n\n- What Python version is required?\n\u003e CLAP requires Python 3.10 or later.3f:T109c,# MCP CLI Client\n\nEen Command Line Interface voor het werken met MCP (Machine Communication Protocol) servers via zowel lokale verbindingen (STDIO) als remote verbindingen (SSE).\n\n## Overzicht\n\nDe MCP CLI Client stelt gebruikers in staat om:\n- Te verbinden met lokale MCP-servers via STDIO\n- Te verbinden met remote MCP-servers via SSE (Server-Sent Events)\n- JSON-RPC verzoeken te sturen naar verbonden servers\n- Te werken in zowel command-line modus als interactieve modus\n- Als een Python module te integreren in andere projecten\n\n## Installatie\n\n1. Clone de repository:\n   ```bash\n   git clone https://github.com/Fbeunder/MCP_CLI_CLIENT.git\n   cd MCP_CLI_CLIENT\n   ```\n\n2. Maak een virtuele omgeving aan (optioneel maar aanbevolen):\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # Op Windows: venv\\Scripts\\activate\n   ```\n\n3. Installeer de benodigde packages:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n4. Configureer de applicatie:\n   ```bash\n   cp .env.example .env\n   # Bewerk .env met je eigen configuratie\n   ```\n\n5. Om als Python pakket te installeren:\n   ```bash\n   pip install -e .\n   ```\n\n## Gebruik als Command Line Tool\n\n### Basis commando's\n\n```bash\n# Verbinden met een lokale MCP-server en een verzoek uitvoeren\npython main.py --local --method methodName --params '{\"param1\": \"value1\"}'\n\n# Verbinden met een remote MCP-server en een verzoek uitvoeren\npython main.py --remote --method methodName --params '{\"param1\": \"value1\"}'\n\n# Starten in interactieve modus met een lokale server\npython main.py --local\n```\n\n### Interactieve modus\n\nIn de interactieve modus kun je commando's invoeren in het formaat:\n```\nmethodName {\"param1\": \"value1\", \"param2\": \"value2\"}\n```\n\nTyp `exit`, `quit` of `q` om de interactieve modus te verlaten.\n\n## Gebruik als Python Module\n\nDe MCP CLI Client kan ook worden gebruikt als een Python module in je eigen projecten:\n\n```python\nfrom mcp_cli_client import MCPClient\n\n# Maak een nieuwe client instantie\nclient = MCPClient()\n\n# Verbind met een lokale MCP server\nclient.connect_stdio(\"path/to/local/mcp/server\")\n# OF verbind met een remote server\n# client.connect_sse(\"https://mcp-server.example.com/events\")\n\n# Stuur verzoeken\nresponse = client.send_request(\"getVersion\")\nprint(response)\n\n# Stuur verzoeken met parameters\nresponse = client.send_request(\"echo\", {\"message\": \"Hello, MCP!\"})\nprint(response)\n\n# Sluit de verbi"])</script><script>self.__next_f.push([1,"nding\nclient.close()\n```\n\n### Installatie als module\n\nOm de MCP CLI Client als module te installeren in andere projecten:\n\n```bash\n# Vanuit de repo directory\npip install -e .\n\n# OF direct vanaf GitHub\npip install git+https://github.com/Fbeunder/MCP_CLI_CLIENT.git\n```\n\n### Uitgebreid voorbeeld\n\nBekijk `examples/module_example.py` voor een uitgebreid voorbeeld van het gebruik als module.\n\n## Configuratie\n\nConfiguratie wordt geladen uit het `.env` bestand, met de volgende opties:\n\n- `MCP_SERVER_URL`: URL voor de remote SSE server\n- `MCP_LOCAL_COMMAND`: Opdracht om een lokale server te starten via STDIO\n- `API_KEY`: Optionele API-sleutel voor authenticatie\n- `LOG_LEVEL`: Logniveau (DEBUG, INFO, ERROR)\n\n## Testen\n\nHet project bevat een uitgebreide testsuite met unit tests en integratietests.\n\n### Tests uitvoeren\n\n1. Installeer de test dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n2. Voer alle tests uit:\n   ```bash\n   pytest\n   ```\n\n3. Voer tests uit met coverage rapportage:\n   ```bash\n   pytest --cov=src\n   ```\n\n### Teststructuur\n\n- `tests/test_mcp_client.py`: Unit tests voor de MCPClient class\n- `tests/test_mcp_cli.py`: Unit tests voor de command-line interface\n- `tests/test_integration.py`: Integratietests die de verschillende componenten samen testen\n\n## API Documentatie\n\n### MCPClient\n\nDe `MCPClient` klasse biedt de volgende methoden:\n\n- `connect_stdio(command=None)`: Verbind met een lokale MCP server via STDIO\n- `connect_sse(url=None)`: Verbind met een remote MCP server via SSE\n- `send_request(method, params=None)`: Stuur een JSON-RPC verzoek\n- `close()`: Sluit de verbinding\n\n### Exceptions\n\n- `ConfigurationError`: Fout bij laden of verwerken van configuratie\n- `ConnectionError`: Fout bij het maken van een verbinding\n- `CommunicationError`: Fout bij communicatie met de MCP server\n\n## Licentie\n\n[MIT](LICENSE)40:T54e,## What is MCP CLI Client? \nMCP CLI Client is a Command Line Interface for working with Machine Communication Protocol (MCP) servers, allowing connections to both local and remote servers.\n\n## How to use MCP CLI Client? \nTo use the MCP CLI Client, clone the repository, set up a virtual environment, install the required packages, and configure the application. You can then run commands to connect to local or remote MCP servers.\n\n## Key features of MCP CLI Client? \n- Connect to local MCP servers via STDIO.\n- Connect to remote MCP servers via Server-Sent Events (SSE).\n- Send JSON-RPC requests to connected servers.\n- Operate in both command-line and interactive modes.\n- Integrate as a Python module in other projects.\n\n## Use cases of MCP CLI Client? \n1. Managing and communicating with local MCP servers.\n2. Sending requests to remote MCP servers for data retrieval.\n3. Integrating MCP functionalities into Python applications.\n\n## FAQ from MCP CLI Client? \n- Can I use MCP CLI Client for both local and remote servers?  \n\u003e Yes! It supports connections to both local and remote MCP servers.\n\n- Is there a way to run it interactively?  \n\u003e Yes! You can start it in interactive mode to enter commands directly.\n\n- How can I integrate it into my Python project?  \n\u003e You can import the MCPClient class and use it to connect to MCP servers and send requests.41:T108f,A comprehensive Model Context Protocol (MCP) server for GitLab integration with Claude Desktop, providing **72 specialized tools** covering every aspect of GitLab\n  project management.\n\n  ## Installation\n\n  ### NPM Package\n  ```bash\n  # For GitLab.com\n  npx @sekora/gitlab-mcp\n\n  # For self-hosted GitLab\n  GITLAB_URL=\"https://gitlab.company.com\" GITLAB_TOKEN=\"your-token\" npx @sekora/gitlab-mcp\n\n  Claude Desktop Configuration\n\n  {\n    \"mcpServers\": {\n      \"gitlab-mcp\": {\n        \"command\": \"npx\",\n        \"args\": [\"@sekora/gitlab-mcp\"],\n        \"env\": {\n          \"GITLAB_TOKEN\": \"your-gitlab-private-token\"\n        }\n      }\n    }\n  }\n\n  Tool Categories (72 Tools - 100% Complete)\n\n  Issue Management (8 tools)\n\n  - Create, update, close, and link issues\n  - Milestone and label management\n  - Advanced filtering and search\n\n  Pipeline \u0026 Job Management (1"])</script><script>self.__next_f.push([1,"7 tools)\n\n  - Pipeline monitoring, triggering, and analytics\n  - Job execution, retry, and artifact management\n  - Real-time status monitoring\n\n  Merge Request Management (8 tools)\n\n  - Complete MR lifecycle from creation to merge\n  - Review comments and conflict resolution\n  - Approval workflows and validation\n\n  Repository Management (8 tools)\n\n  - Branch and file operations\n  - Commit history and tag management\n  - Release management with assets\n\n  Security \u0026 Quality Analysis (6 tools)\n\n  - SAST, dependency, and container scanning\n  - License compliance and code quality metrics\n  - Vulnerability assessment and remediation\n\n  Environment \u0026 Deployment (7 tools)\n\n  - Environment monitoring and feature flags\n  - Deployment tracking and GitLab Pages management\n  - Runner and variable management\n\n  Project Administration (6 tools)\n\n  - Member and permission management\n  - Project settings and integrations\n  - Webhook and access token management\n\n  Analytics \u0026 Insights (4 tools)\n\n  - Project analytics and contributor statistics\n  - Activity monitoring and usage metrics\n  - Performance trends and optimization insights\n\n  Team Collaboration (4 tools)\n\n  - Discussions and mentions management\n  - Wiki pages and code snippets\n  - Team communication workflows\n\n  Specialized Monitoring (6 tools)\n\n  - Advanced pipeline analytics and dashboards\n  - Success rate analysis and performance metrics\n  - Cross-project monitoring and alerts\n\n  Key Features\n\n  - Complete GitLab Coverage: Every major GitLab feature accessible through Claude\n  - Multi-Instance Support: Configure multiple GitLab instances simultaneously\n  - Enterprise Ready: Supports GitLab CE, Premium, and Ultimate editions\n  - Security First: Built-in token management and secure authentication\n  - Rich Analytics: Comprehensive insights and performance monitoring\n  - Type-Safe: Built with TypeScript and Zod validation\n  - Production Ready: Comprehensive error handling and validation\n\n  Requirements\n\n  - Node.js 18.19.0+\n  - GitLab private access token with api scope\n  - GitLab.com or self-hosted GitLab instance\n\n  Authentication\n\n  Create a GitLab private access token:\n  1. Go to GitLab â†’ Profile â†’ Access Tokens\n  2. Create token with api scope\n  3. Configure via environment variable or Claude Desktop config\n\n  Multi-Tenant Support\n\n  Configure multiple GitLab instances:\n  {\n    \"mcpServers\": {\n      \"work-gitlab\": {\n        \"command\": \"npx\",\n        \"args\": [\"@sekora/gitlab-mcp\"],\n        \"env\": {\n          \"GITLAB_URL\": \"https://gitlab.company.com\",\n          \"GITLAB_TOKEN\": \"work-token\"\n        }\n      },\n      \"personal-gitlab\": {\n        \"command\": \"npx\",\n        \"args\": [\"@sekora/gitlab-mcp\"],\n        \"env\": {\n          \"GITLAB_TOKEN\": \"personal-token\"\n        }\n      }\n    }\n  }\n\n  Use Cases\n\n  - DevOps Automation: Pipeline monitoring, deployment management, environment control\n  - Code Review: MR creation, approval workflows, conflict resolution\n  - Project Management: Issue tracking, milestone planning, team coordination\n  - Security Operations: Vulnerability scanning, compliance monitoring, quality analysis\n  - Team Collaboration: Wiki management, discussions, activity monitoring\n  - Analytics \u0026 Reporting: Project insights, contributor analysis, performance metrics\n\n  Built with the https://mcp-framework.com for reliable, type-safe GitLab API integration.\n  ```42:T12633,[{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_access_tokens\",\"description\":\"Manage GitLab project access tokens for API authentication and automation\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"access_level\":{\"description\":\"Access level: 10=Guest, 20=Reporter, 30=Developer, 40=Maintainer, 50=Owner (for create action, defaults to 40)\",\"type\":\"string\"},\"action\":{\"description\":\"Action: list existing tokens, create new token, or revoke token\",\"type\":\"string\"},\"expires_at\":{\"description\":\"Expiration date in YYYY-MM-DD format (for create action, optional)\",\"type\":\"string\"},\"name\":{\"description\":\"Token name/description (required for create action)\",\"type\":\"string\"},\"page\":{\"description\":\"Page number to r"])</script><script>self.__next_f.push([1,"etrieve (default: 1) - for list action\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of results per page (1-100, default: 20) - for list action\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"scopes\":{\"description\":\"Token scopes - array of: api, read_api, read_repository, write_repository, read_registry, write_registry, read_user (required for create)\",\"type\":\"array\"},\"token_id\":{\"description\":\"Token ID (required for revoke action)\",\"type\":\"number\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_activity_feed\",\"description\":\"Get recent project activity feed with comprehensive event tracking including commits, issues, merge requests, and user interactions for a GitLab project.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"after_date\":{\"description\":\"Show events after this date in YYYY-MM-DD format (optional)\",\"type\":\"string\"},\"author_id\":{\"description\":\"Filter events by specific author/user ID (optional)\",\"type\":\"number\"},\"before_date\":{\"description\":\"Show events before this date in YYYY-MM-DD format (optional)\",\"type\":\"string\"},\"event_type\":{\"description\":\"Filter by specific event type (optional)\",\"type\":\"string\"},\"limit\":{\"description\":\"Maximum number of events to retrieve (default: 20, max: 100)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"target_type\":{\"description\":\"Filter by target type (optional)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_branch_compare\",\"description\":\"Compare two branches, tags, or commits showing differences, file changes, and commit history. Supports both straight and merge-base comparison modes.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"from\":{\"description\":\"Source branch, tag, or commit SHA to compare from\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"straight\":{\"description\":\"Use straight comparison (true) vs merge-base comparison (false, default)\",\"type\":\"boolean\"},\"to\":{\"description\":\"Target branch, tag, or commit SHA to compare to\",\"type\":\"string\"}},\"required\":[\"project_id\",\"from\",\"to\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_branch_create\",\"description\":\"Create a new repository branch from an existing branch, tag, or commit SHA. Validates branch name format and ensures uniqueness.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"branch\":{\"description\":\"Name for the new branch. Must follow Git naming conventions (no spaces, special chars limited)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Reference to create branch from. Can be branch name, tag name, or commit SHA\",\"type\":\"string\"}},\"required\":[\"project_id\",\"branch\",\"ref\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_branch_list\",\"description\":\"List repository branches with filtering and sorting options. Supports searching branch names, filtering by protection status, and sorting by various criteria.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of branches to return per page (1-100, default: 20)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"search\":{\"description\":\"Search branch names containing this string\",\"type\":\"string\"},\"sort\":{\"description\":\"Sort branches by name, updated date, or created date\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_code_quality\",\"description\":\"Retrieve code quality metrics and reports from GitLab's code quality analysis, including code smells, maintainability issues, and quality trends.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Specific pipeline ID to get code quality resu"])</script><script>self.__next_f.push([1,"lts from (optional, uses latest successful pipeline if not provided)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_commit_history\",\"description\":\"Get detailed commit history from GitLab repository with comprehensive filtering options. Supports filtering by branch, author, date ranges, file paths, and provides optional statistics.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"all\":{\"description\":\"Retrieve all commits from all branches and tags (default: false)\",\"type\":\"boolean\"},\"author\":{\"description\":\"Only commits by this author (name or email)\",\"type\":\"string\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"path\":{\"description\":\"Only commits that modified this file or directory path (e.g., 'src/main.js', 'docs/')\",\"type\":\"string\"},\"per_page\":{\"description\":\"Number of commits to return per page (1-100, default: 20)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref_name\":{\"description\":\"Branch, tag, or commit SHA to get history from (default: project's default branch)\",\"type\":\"string\"},\"since\":{\"description\":\"Only commits after this date (ISO 8601 format: '2024-01-01T00:00:00Z')\",\"type\":\"string\"},\"until\":{\"description\":\"Only commits before this date (ISO 8601 format: '2024-12-31T23:59:59Z')\",\"type\":\"string\"},\"with_stats\":{\"description\":\"Include file change statistics (additions, deletions) for each commit (default: false)\",\"type\":\"boolean\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_container_scan\",\"description\":\"Get container security scan results from GitLab's container scanning feature, analyzing Docker images for vulnerabilities in OS packages and dependencies.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Specific pipeline ID to get container scan results from (optional, uses latest pipeline if not provided)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_contributor_stats\",\"description\":\"Get comprehensive contributor statistics and team insights including commit activity, collaboration patterns, and individual performance metrics for a GitLab project.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"from_date\":{\"description\":\"Start date for analysis in YYYY-MM-DD format (default: 90 days ago)\",\"type\":\"string\"},\"include_inactive\":{\"description\":\"Include contributors with minimal activity (default: false)\",\"type\":\"boolean\"},\"min_commits\":{\"description\":\"Minimum number of commits to include contributor (default: 1)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"to_date\":{\"description\":\"End date for analysis in YYYY-MM-DD format (default: today)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_dependency_scan\",\"description\":\"Check dependency vulnerabilities using GitLab's dependency scanning feature, analyzing package dependencies for known security issues and license compliance.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Specific pipeline ID to get dependency scan results from (optional, uses latest pipeline if not provided)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_deploy_keys\",\"description\":\"Manage GitLab project SSH deploy keys for secure repository access without user accounts\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action: list, get, create, update, delete, or enable deploy keys\",\"type\":\"string\"},\"can_push\":{\"description\":\"Allow push access (default: false for read-only access)"])</script><script>self.__next_f.push([1,"\",\"type\":\"boolean\"},\"expires_at\":{\"description\":\"Expiration date in YYYY-MM-DD format (optional)\",\"type\":\"string\"},\"key\":{\"description\":\"SSH public key content (required for create action)\",\"type\":\"string\"},\"key_id\":{\"description\":\"Deploy key ID (required for get, update, delete, enable actions)\",\"type\":\"number\"},\"page\":{\"description\":\"Page number to retrieve (default: 1) - for list action\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of results per page (1-100, default: 20) - for list action\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"title\":{\"description\":\"Deploy key title/name (required for create, optional for update)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_deployments\",\"description\":\"Get comprehensive deployment history for a project with advanced filtering by environment, status, date ranges, and sorting options. Provides deployment analytics and trend insights.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"environment\":{\"description\":\"Filter deployments by environment name (e.g., 'production', 'staging')\",\"type\":\"string\"},\"finished_after\":{\"description\":\"Show deployments finished after this date (ISO 8601 format: 2024-01-01T00:00:00Z)\",\"type\":\"string\"},\"finished_before\":{\"description\":\"Show deployments finished before this date (ISO 8601 format: 2024-01-01T00:00:00Z)\",\"type\":\"string\"},\"order_by\":{\"description\":\"Field to order results by (default: created_at)\",\"type\":\"string\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"string\"},\"per_page\":{\"description\":\"Number of deployments to return per page (1-100, default: 20)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"sort\":{\"description\":\"Sort direction - desc for newest first, asc for oldest first (default: desc)\",\"type\":\"string\"},\"status\":{\"description\":\"Filter deployments by status\",\"type\":\"string\"},\"updated_after\":{\"description\":\"Show deployments updated after this date (ISO 8601 format: 2024-01-01T00:00:00Z)\",\"type\":\"string\"},\"updated_before\":{\"description\":\"Show deployments updated before this date (ISO 8601 format: 2024-01-01T00:00:00Z)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_discussions\",\"description\":\"Manage issue and merge request discussions and threaded conversations in GitLab\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform (default: list)\",\"type\":\"string\"},\"body\":{\"description\":\"Comment body text (required for create, reply actions)\",\"type\":\"string\"},\"discussion_id\":{\"description\":\"Discussion ID (required for reply, resolve, unresolve actions)\",\"type\":\"string\"},\"note_id\":{\"description\":\"Note ID within discussion (for specific note operations)\",\"type\":\"number\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of discussions to return per page (default: 20, max: 100)\",\"type\":\"number\"},\"position\":{\"description\":\"Position for diff discussions (MR only)\",\"type\":\"object\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"target_id\":{\"description\":\"Issue IID or Merge Request IID\",\"type\":\"number\"},\"target_type\":{\"description\":\"Type of target for discussions (issue or merge_request)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"target_type\",\"target_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_environment_status\",\"description\":\"Check detailed health status and monitoring information for GitLab environments. Provides deployment status, availability, external access, and operational insights for environment monitoring.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"environment_id\":{\"description\":\"Specific environment ID to check (takes precedence over environment_name)\",\"type\":\"number\"},\"environment_name\":{\"description\":\"Environment name to check (e.g., 'production', 'staging') - "])</script><script>self.__next_f.push([1,"used if environment_id not provided\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_environments\",\"description\":\"List project environments with filtering by state, name, or search criteria. Supports pagination and provides comprehensive environment information including deployment history and external URLs.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"name\":{\"description\":\"Filter environments by exact name match\",\"type\":\"string\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"string\"},\"per_page\":{\"description\":\"Number of environments to return per page (1-100, default: 20)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"search\":{\"description\":\"Search environments by name (partial matching)\",\"type\":\"string\"},\"states\":{\"description\":\"Filter environments by state (available = running, stopped = inactive)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_feature_flags\",\"description\":\"Manage GitLab feature flags with full CRUD operations. Create, read, update, delete, and toggle feature flags with environment-specific scopes and strategies for controlled feature rollouts.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: list (all flags), get (specific flag), create (new flag), update (modify flag), delete (remove flag), toggle (flip active state)\",\"type\":\"string\"},\"active\":{\"description\":\"Global active state for the feature flag (optional for create/update, ignored for toggle)\",\"type\":\"boolean\"},\"description\":{\"description\":\"Feature flag description (optional for create/update)\",\"type\":\"string\"},\"name\":{\"description\":\"Feature flag name (required for get, create, update, delete, toggle actions)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"scopes\":{\"description\":\"Environment-specific scopes and strategies (optional for create/update). Common strategies: 'default', 'gradualRolloutUserId', 'userWithId'\",\"type\":\"array\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_file_read\",\"description\":\"Read file contents from GitLab repository at specific branches, tags, or commits. Handles both text and binary files with appropriate encoding detection.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"file_path\":{\"description\":\"Path to the file in the repository (e.g., 'src/main.js', 'README.md')\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Branch, tag, or commit SHA to read from (default: project's default branch)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"file_path\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_file_update\",\"description\":\"Update file contents in GitLab repository via API. Supports text and binary files, conflict detection, and comprehensive commit metadata. Requires write permissions to the repository.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"author_email\":{\"description\":\"Author email for the commit (defaults to authenticated user)\",\"type\":\"string\"},\"author_name\":{\"description\":\"Author name for the commit (defaults to authenticated user)\",\"type\":\"string\"},\"branch\":{\"description\":\"Target branch for the file update (must exist)\",\"type\":\"string\"},\"commit_message\":{\"description\":\"Commit message describing the changes\",\"type\":\"string\"},\"content\":{\"description\":\"New file content (text or base64-encoded for binary files)\",\"type\":\"string\"},\"encoding\":{\"description\":\"File encoding - 'text' for text files, 'base64' for binary files (default: 'text')\",\"type\":\"string\"},\"file_path\":{\"description\":\"Path to the file in the repository (e.g., 'src/main.js', 'README.md')\",\"type\":\"string\"},\"last_commit_id\":{\"description\":\"SHA of the last commit to prevent conflic"])</script><script>self.__next_f.push([1,"ts (recommended for concurrent editing)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"start_branch\":{\"description\":\"Branch to start from if different from target branch\",\"type\":\"string\"}},\"required\":[\"project_id\",\"file_path\",\"branch\",\"content\",\"commit_message\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_group_pipelines\",\"description\":\"Monitor pipelines across all projects in a GitLab group with comprehensive status overview and cross-project insights\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"days_back\":{\"description\":\"Number of days to analyze (default: 7, max: 30)\",\"type\":\"number\"},\"group_id\":{\"description\":\"GitLab group ID or URL-encoded path (e.g., 'my-group' or '123')\",\"type\":\"string\"},\"include_subgroups\":{\"description\":\"Include projects from subgroups (default: true)\",\"type\":\"boolean\"},\"ref\":{\"description\":\"Filter pipelines by branch/tag reference (optional)\",\"type\":\"string\"},\"status\":{\"description\":\"Filter pipelines by status (optional)\",\"type\":\"string\"}},\"required\":[\"group_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_issue_close\",\"description\":\"Close a GitLab issue with optional resolution note. Marks the issue as resolved and optionally adds a closing comment explaining the resolution.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"issue_iid\":{\"description\":\"Issue IID (internal ID within the project)\",\"type\":\"number\"},\"project_id\":{\"description\":\"Project ID or path (e.g., 'group/project' or '123')\",\"type\":\"string\"},\"resolution_note\":{\"description\":\"Optional note explaining how the issue was resolved\",\"type\":\"string\"}},\"required\":[\"project_id\",\"issue_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_issue_link\",\"description\":\"Link a GitLab issue to another issue or merge request. Creates relationships between issues and MRs for better project tracking and cross-referencing.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"issue_iid\":{\"description\":\"Issue IID to link from\",\"type\":\"number\"},\"link_type\":{\"description\":\"Type of relationship (defaults to 'relates_to')\",\"type\":\"string\"},\"project_id\":{\"description\":\"Project ID or path (e.g., 'group/project' or '123')\",\"type\":\"string\"},\"target_issue_iid\":{\"description\":\"Target issue IID to link to\",\"type\":\"number\"},\"target_merge_request_iid\":{\"description\":\"Target merge request IID to link to\",\"type\":\"number\"},\"target_project_id\":{\"description\":\"Target project ID (defaults to same project)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"issue_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_artifacts\",\"description\":\"List and manage job artifacts from GitLab CI/CD jobs\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: list artifacts or download specific artifact (default: list)\",\"type\":\"string\"},\"artifact_path\":{\"description\":\"Specific artifact path to download (required when action is 'download')\",\"type\":\"string\"},\"job_id\":{\"description\":\"Job ID to get artifacts for\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"job_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_cancel\",\"description\":\"Cancel a running or pending GitLab job. Only works for jobs in 'running', 'pending', or 'created' state. Returns the updated job status after cancellation.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"job_id\":{\"description\":\"Job ID to cancel\",\"type\":\"number\"},\"project_id\":{\"description\":\"Project ID or path (e.g., 'group/project' or '123')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"job_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_erase\",\"description\":\"Erase a GitLab job's logs and artifacts. This permanently removes job execution logs and artifacts from GitLab storage. Only works for completed jobs (success, failed, canceled). Use with caution as this action is irreversible.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"job_id\":{\"description\":\"Job ID to erase logs and artifacts from\",\"type\":\"number\"},\"project_id\":{\"descri"])</script><script>self.__next_f.push([1,"ption\":\"Project ID or path (e.g., 'group/project' or '123')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"job_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_list\",\"description\":\"List jobs for a GitLab project with filtering options\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of jobs to return per page (default: 20, max: 100)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"scope\":{\"description\":\"Filter jobs by status scope\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_logs\",\"description\":\"Retrieve execution logs from a specific GitLab job\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"include_job_info\":{\"description\":\"Include job details along with logs (default: true)\",\"type\":\"boolean\"},\"job_id\":{\"description\":\"Job ID to get logs for\",\"type\":\"number\"},\"max_lines\":{\"description\":\"Maximum number of log lines to return (default: 1000)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"job_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_play\",\"description\":\"Play (trigger) a manual GitLab job. Only works for jobs in 'manual' state. Manual jobs require explicit user action to run and are commonly used for deployments or sensitive operations.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"job_id\":{\"description\":\"Job ID to play/trigger\",\"type\":\"number\"},\"project_id\":{\"description\":\"Project ID or path (e.g., 'group/project' or '123')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"job_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_retry\",\"description\":\"Retry a failed or canceled GitLab job. Only works for jobs in 'failed' or 'canceled' state. Returns the updated job status after retry.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"job_id\":{\"description\":\"Job ID to retry\",\"type\":\"number\"},\"project_id\":{\"description\":\"Project ID or path (e.g., 'group/project' or '123')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"job_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_status\",\"description\":\"Get the current status and details of a specific GitLab job\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"job_id\":{\"description\":\"Job ID to get status for\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"job_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_job_trace\",\"description\":\"Get real-time job execution trace from GitLab CI/CD jobs with optional following\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"follow\":{\"description\":\"Follow the trace in real-time (for running jobs, default: false)\",\"type\":\"boolean\"},\"include_timestamps\":{\"description\":\"Include timestamps in trace output if available (default: false)\",\"type\":\"boolean\"},\"job_id\":{\"description\":\"Job ID to get trace for\",\"type\":\"number\"},\"max_lines\":{\"description\":\"Maximum number of trace lines to return (default: 1000)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"job_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_label_manage\",\"description\":\"Comprehensive GitLab label management tool. Create, update, list, and delete project labels for better issue and MR organization. Supports color themes, descriptions, and priority ordering.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: list all labels, create new label, update existing label, or delete label\",\"type\":\"string\"},\"color\":{\"description\":\"Label color in hex format (e.g., '#FF0000' or 'red'). Defaults to random color for new labels\",\"type\":\"string\"},\"description\":{\"description\":\"Label description for better context and usage guidance\",\"type\":\"string\"},\"label_id\":{\"description\":\"Label ID (required"])</script><script>self.__next_f.push([1," for update/delete actions)\",\"type\":\"number\"},\"name\":{\"description\":\"Label name (required for create action, used as identifier for update/delete if label_id not provided)\",\"type\":\"string\"},\"new_name\":{\"description\":\"New label name (for update action only)\",\"type\":\"string\"},\"priority\":{\"description\":\"Label priority for ordering (higher numbers = higher priority)\",\"type\":\"number\"},\"project_id\":{\"description\":\"Project ID or path (e.g., 'group/project' or '123')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_license_scan\",\"description\":\"Check license compliance using GitLab's license scanning feature, analyzing dependencies for license compatibility and compliance issues.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Specific pipeline ID to get license scan results from (optional, uses latest pipeline if not provided)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mr_approvals\",\"description\":\"Check approval status and requirements for a GitLab merge request\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"merge_request_iid\":{\"description\":\"Merge request IID (internal ID) - the number shown in the MR URL and title\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"merge_request_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mr_approve\",\"description\":\"Approve a GitLab merge request with optional SHA validation\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"merge_request_iid\":{\"description\":\"Merge request IID (internal ID) - the number shown in the MR URL and title\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"sha\":{\"description\":\"SHA of the head commit to approve. If provided, approval will be tied to this specific commit\",\"type\":\"string\"}},\"required\":[\"project_id\",\"merge_request_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mr_comments\",\"description\":\"Add, reply to, or list review comments and discussions on GitLab merge requests\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: list existing discussions, create new comment, or reply to existing discussion\",\"type\":\"string\"},\"body\":{\"description\":\"Comment body text (required for create and reply actions, supports Markdown)\",\"type\":\"string\"},\"discussion_id\":{\"description\":\"Discussion ID (required for reply action)\",\"type\":\"string\"},\"merge_request_iid\":{\"description\":\"Merge request IID (internal ID) - the number shown in the MR URL and title\",\"type\":\"number\"},\"page\":{\"description\":\"Page number for pagination for list action (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of discussions to return per page for list action (1-100, default: 20)\",\"type\":\"number\"},\"position\":{\"description\":\"Position for diff comments (create action only). Required for line-specific comments on changes\",\"type\":\"object\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"merge_request_iid\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mr_conflicts\",\"description\":\"Check for merge conflicts in a GitLab merge request and get detailed conflict information\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"merge_request_iid\":{\"description\":\"Merge request IID (internal ID) - the number shown in the MR URL and title\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"merge_request_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mr_create\",\"description\":\"Create a new merge request in a GitLab project with comprehensive options\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"allow_collaboration\":{\"description\":\"Allow "])</script><script>self.__next_f.push([1,"commits from members who can merge to the target branch (default: false)\",\"type\":\"boolean\"},\"allow_maintainer_to_push\":{\"description\":\"Allow project maintainers to push to the source branch (default: false)\",\"type\":\"boolean\"},\"assignee_id\":{\"description\":\"User ID to assign the merge request to (legacy, use assignee_ids instead)\",\"type\":\"number\"},\"assignee_ids\":{\"description\":\"Array of user IDs to assign the merge request to\",\"type\":\"array\"},\"description\":{\"description\":\"Merge request description (supports Markdown)\",\"type\":\"string\"},\"labels\":{\"description\":\"Array of label names to add to the merge request\",\"type\":\"array\"},\"milestone_id\":{\"description\":\"Milestone ID to associate with the merge request\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"remove_source_branch\":{\"description\":\"Whether to remove the source branch when the MR is merged (default: false)\",\"type\":\"boolean\"},\"reviewer_ids\":{\"description\":\"Array of user IDs to set as reviewers\",\"type\":\"array\"},\"source_branch\":{\"description\":\"Source branch name (the branch to merge from)\",\"type\":\"string\"},\"squash\":{\"description\":\"Whether to squash commits when merging (default: false)\",\"type\":\"boolean\"},\"target_branch\":{\"description\":\"Target branch name (the branch to merge into)\",\"type\":\"string\"},\"target_project_id\":{\"description\":\"Target project ID (for cross-project merge requests)\",\"type\":\"number\"},\"title\":{\"description\":\"Merge request title\",\"type\":\"string\"}},\"required\":[\"project_id\",\"source_branch\",\"target_branch\",\"title\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mr_details\",\"description\":\"Get detailed information about a specific GitLab merge request, including changes, discussions, and commits\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"include_changes\":{\"description\":\"Include file changes and diffs in the response (default: false)\",\"type\":\"boolean\"},\"include_commits\":{\"description\":\"Include commit list in the response (default: false)\",\"type\":\"boolean\"},\"include_discussions\":{\"description\":\"Include discussions and comments in the response (default: false)\",\"type\":\"boolean\"},\"merge_request_iid\":{\"description\":\"Merge request IID (internal ID) - the number shown in the MR URL and title\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"merge_request_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mr_list\",\"description\":\"List/search merge requests with comprehensive filtering options for GitLab projects\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"assignee_id\":{\"description\":\"Filter by assignee user ID\",\"type\":\"number\"},\"assignee_username\":{\"description\":\"Filter by assignee username\",\"type\":\"string\"},\"author_id\":{\"description\":\"Filter by author user ID\",\"type\":\"number\"},\"author_username\":{\"description\":\"Filter by author username\",\"type\":\"string\"},\"created_after\":{\"description\":\"Filter MRs created after this date (ISO 8601 format)\",\"type\":\"string\"},\"created_before\":{\"description\":\"Filter MRs created before this date (ISO 8601 format)\",\"type\":\"string\"},\"labels\":{\"description\":\"Comma-separated list of label names to filter by\",\"type\":\"string\"},\"milestone\":{\"description\":\"Filter by milestone title\",\"type\":\"string\"},\"order_by\":{\"description\":\"Order merge requests by field (default: created_at)\",\"type\":\"string\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of merge requests to return per page (1-100, default: 20)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"reviewer_id\":{\"description\":\"Filter by reviewer user ID\",\"type\":\"number\"},\"reviewer_username\":{\"description\":\"Filter by reviewer username\",\"type\":\"string\"},\"scope\":{\"description\":\"Filter by scope (default: all)\",\"type\":\"string\"},\"search\":{\"description\":\"Search merge requests by title and description\",\"type\":\"string\"},\"sort\":{\"description\":\"Sort order (default:"])</script><script>self.__next_f.push([1," desc)\",\"type\":\"string\"},\"source_branch\":{\"description\":\"Filter by source branch name\",\"type\":\"string\"},\"state\":{\"description\":\"Filter merge requests by state (default: opened)\",\"type\":\"string\"},\"target_branch\":{\"description\":\"Filter by target branch name\",\"type\":\"string\"},\"updated_after\":{\"description\":\"Filter MRs updated after this date (ISO 8601 format)\",\"type\":\"string\"},\"updated_before\":{\"description\":\"Filter MRs updated before this date (ISO 8601 format)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mr_merge\",\"description\":\"Merge an approved GitLab merge request with comprehensive merge options\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"merge_commit_message\":{\"description\":\"Custom merge commit message. If not provided, GitLab will generate one\",\"type\":\"string\"},\"merge_request_iid\":{\"description\":\"Merge request IID (internal ID) - the number shown in the MR URL and title\",\"type\":\"number\"},\"merge_when_pipeline_succeeds\":{\"description\":\"Merge automatically when the pipeline succeeds (default: false)\",\"type\":\"boolean\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"sha\":{\"description\":\"SHA of the head commit to merge. Used to ensure the MR hasn't changed\",\"type\":\"string\"},\"should_remove_source_branch\":{\"description\":\"Whether to remove the source branch after merging (default: project settings)\",\"type\":\"boolean\"},\"squash\":{\"description\":\"Whether to squash commits into a single commit (default: project settings)\",\"type\":\"boolean\"},\"squash_commit_message\":{\"description\":\"Custom squash commit message (used when squashing is enabled)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"merge_request_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_mentions\",\"description\":\"Manage GitLab @mentions and notifications - view, mark as read, and handle notification workflows\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform (default: list)\",\"type\":\"string\"},\"notification_id\":{\"description\":\"Specific notification ID (required for mark_read action)\",\"type\":\"number\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of notifications to return per page (default: 20, max: 100)\",\"type\":\"number\"}}}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_milestone_manage\",\"description\":\"Create, update, close, reopen, delete, or list project milestones\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: create new milestone, update existing, close/reopen, delete, or list all milestones\",\"type\":\"string\"},\"description\":{\"description\":\"Milestone description (supports Markdown)\",\"type\":\"string\"},\"due_date\":{\"description\":\"Due date in YYYY-MM-DD format\",\"type\":\"string\"},\"milestone_id\":{\"description\":\"Milestone ID (required for update, close, reopen, and delete actions)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"start_date\":{\"description\":\"Start date in YYYY-MM-DD format\",\"type\":\"string\"},\"title\":{\"description\":\"Milestone title (required for create, optional for update)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_cancel\",\"description\":\"Cancel a running GitLab pipeline. This will stop all running jobs and mark the pipeline as canceled.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Pipeline ID to cancel\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"pipeline_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_coverage\",\"description\":\"Get test coverage data from pipeline results with trend analysis and coverage insights for code quality monitoring\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"days_back\":{\"description\":\"Number of days to analyze coverage trends (default: 30, max: 90)\",\"type\":\"number\"},\"pipeline_id"])</script><script>self.__next_f.push([1,"\":{\"description\":\"Get coverage for specific pipeline ID (optional)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Filter pipelines by branch/tag reference (optional)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_dashboard\",\"description\":\"Generate a comprehensive pipeline status dashboard with visual indicators, metrics, alerts, and actionable insights\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"days_back\":{\"description\":\"Number of days for dashboard metrics (default: 7, max: 30)\",\"type\":\"number\"},\"include_coverage\":{\"description\":\"Include test coverage information (default: true)\",\"type\":\"boolean\"},\"include_jobs\":{\"description\":\"Include job-level details for latest pipeline (default: false)\",\"type\":\"boolean\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_details\",\"description\":\"Get detailed information about a specific GitLab pipeline including stages, jobs, and timing\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Pipeline ID to get detailed information for\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"pipeline_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_duration\",\"description\":\"Analyze pipeline execution times with detailed duration breakdowns, trends, and performance insights for optimization\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"days_back\":{\"description\":\"Number of days to analyze (default: 30, max: 90)\",\"type\":\"number\"},\"include_jobs\":{\"description\":\"Include detailed job analysis for the latest pipeline (default: false)\",\"type\":\"boolean\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Filter pipelines by branch/tag reference (optional)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_jobs\",\"description\":\"List all jobs in a specific GitLab pipeline with their status, organized by stage\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of jobs to return per page (default: 20, max: 100)\",\"type\":\"number\"},\"pipeline_id\":{\"description\":\"Pipeline ID to get jobs for\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"scope\":{\"description\":\"Filter jobs by status scope\",\"type\":\"string\"}},\"required\":[\"project_id\",\"pipeline_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_list\",\"description\":\"List recent pipelines for a GitLab project with filtering and sorting options\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"order_by\":{\"description\":\"Order pipelines by field (default: id)\",\"type\":\"string\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of pipelines to return per page (default: 20, max: 100)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Filter pipelines by branch/tag reference\",\"type\":\"string\"},\"sha\":{\"description\":\"Filter pipelines by commit SHA\",\"type\":\"string\"},\"sort\":{\"description\":\"Sort order (default: desc)\",\"type\":\"string\"},\"status\":{\"description\":\"Filter pipelines by status\",\"type\":\"string\"},\"updated_after\":{\"description\":\"Filter pipelines updated after this date (ISO 8601 format)\",\"type\":\"string\"},\"updated_before\":{\"description\":\"Filter pipelines updated before this date (ISO 8601 format)\",\"type\":\"string\"},\"username\":{\"description\":\"Filter pipelines by username who triggered them\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"ser"])</script><script>self.__next_f.push([1,"ver_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_logs\",\"description\":\"Retrieve logs from GitLab pipeline execution - all jobs or specific jobs by name/stage\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"failed_only\":{\"description\":\"Only get logs for failed jobs (default: false)\",\"type\":\"boolean\"},\"job_name\":{\"description\":\"Specific job name to get logs for (if not provided, gets logs for all jobs)\",\"type\":\"string\"},\"max_lines\":{\"description\":\"Maximum number of log lines to return per job (default: 1000)\",\"type\":\"number\"},\"pipeline_id\":{\"description\":\"Pipeline ID to get logs for\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"stage\":{\"description\":\"Stage name to get logs for all jobs in that stage\",\"type\":\"string\"}},\"required\":[\"project_id\",\"pipeline_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_metrics\",\"description\":\"Get comprehensive pipeline performance metrics and analytics for a GitLab project including success rates, durations, and trends\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"days_back\":{\"description\":\"Number of days to look back for metrics (default: 30, max: 365)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Filter pipelines by branch/tag reference (optional)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_retry\",\"description\":\"Retry a failed GitLab pipeline. This will restart all failed jobs in the pipeline while keeping successful jobs unchanged.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Pipeline ID to retry\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"pipeline_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_status\",\"description\":\"Get current status of project pipelines - either latest pipeline or specific pipeline by ID\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Specific pipeline ID to get status for (if not provided, gets latest pipeline)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Branch/tag reference to get latest pipeline for (only used when pipeline_id is not provided)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_success_rate\",\"description\":\"Calculate pipeline success rates over time with trend analysis, failure insights, and actionable recommendations\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"days_back\":{\"description\":\"Number of days to analyze (default: 30, max: 180)\",\"type\":\"number\"},\"group_by\":{\"description\":\"Group success rate data by time period (default: 'day')\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Filter pipelines by branch/tag reference (optional)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_trigger\",\"description\":\"Manually trigger a new GitLab pipeline on a specific branch or tag. Can be used with trigger tokens or directly create pipelines with variables.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Branch name, tag name, or commit SHA to create the pipeline for\",\"type\":\"string\"},\"trigger_token\":{\"description\":\"Pipeline trigger token (if using trigger-based pipeline creation). If not provided, creates pipeline directly.\",\"type\":\"string\"},\"variables\":{\"description\":\"Pipeline variables as key-value pairs (e.g., {'ENVIRONMENT': 'production', 'DEBUG': 'true'})\",\"type\":\"string\"}},\"required\":[\"project_id\",\"ref\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pipeline_variables\",\"de"])</script><script>self.__next_f.push([1,"scription\":\"Get pipeline variables used in a specific GitLab pipeline execution. Shows environment variables, file variables, and their configuration.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Pipeline ID to get variables for\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"pipeline_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_project_analytics\",\"description\":\"Get comprehensive project analytics and insights including commit activity, merge request statistics, issue trends, and development patterns for a GitLab project.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"from_date\":{\"description\":\"Start date for analytics in YYYY-MM-DD format (default: 30 days ago)\",\"type\":\"string\"},\"include_details\":{\"description\":\"Include detailed breakdown by authors and time periods (default: false)\",\"type\":\"boolean\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"to_date\":{\"description\":\"End date for analytics in YYYY-MM-DD format (default: today)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_project_hooks\",\"description\":\"Manage GitLab project webhooks for external integrations and CI/CD automation\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action: list, get, create, update, delete, or test webhooks\",\"type\":\"string\"},\"confidential_issues_events\":{\"description\":\"Trigger on confidential issues events (for create/update)\",\"type\":\"boolean\"},\"confidential_note_events\":{\"description\":\"Trigger on confidential comment events (for create/update)\",\"type\":\"boolean\"},\"custom_webhook_template\":{\"description\":\"Custom webhook payload template (for create/update)\",\"type\":\"string\"},\"deployment_events\":{\"description\":\"Trigger on deployment events (for create/update)\",\"type\":\"boolean\"},\"enable_ssl_verification\":{\"description\":\"Enable SSL verification for webhook URL (for create/update)\",\"type\":\"boolean\"},\"feature_flag_events\":{\"description\":\"Trigger on feature flag events (for create/update)\",\"type\":\"boolean\"},\"hook_id\":{\"description\":\"Hook ID (required for get, update, delete, test actions)\",\"type\":\"number\"},\"issues_events\":{\"description\":\"Trigger on issues events (for create/update)\",\"type\":\"boolean\"},\"job_events\":{\"description\":\"Trigger on job events (for create/update)\",\"type\":\"boolean\"},\"merge_requests_events\":{\"description\":\"Trigger on merge request events (for create/update)\",\"type\":\"boolean\"},\"note_events\":{\"description\":\"Trigger on comment events (for create/update)\",\"type\":\"boolean\"},\"page\":{\"description\":\"Page number to retrieve (default: 1) - for list action\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of results per page (1-100, default: 20) - for list action\",\"type\":\"number\"},\"pipeline_events\":{\"description\":\"Trigger on pipeline events (for create/update)\",\"type\":\"boolean\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"push_events\":{\"description\":\"Trigger on push events (for create/update)\",\"type\":\"boolean\"},\"push_events_branch_filter\":{\"description\":\"Branch filter for push events (for create/update)\",\"type\":\"string\"},\"releases_events\":{\"description\":\"Trigger on release events (for create/update)\",\"type\":\"boolean\"},\"repository_update_events\":{\"description\":\"Trigger on repository update events (for create/update)\",\"type\":\"boolean\"},\"resource_access_token_events\":{\"description\":\"Trigger on resource access token events (for create/update)\",\"type\":\"boolean\"},\"subgroup_events\":{\"description\":\"Trigger on subgroup events (for create/update)\",\"type\":\"boolean\"},\"tag_push_events\":{\"description\":\"Trigger on tag push events (for create/update)\",\"type\":\"boolean\"},\"token\":{\"description\":\"Secret token for webhook authentication (for create/update)\",\"type\":\"string\"},\"url\":{\"description\":\"Webhook URL (required for create, optional for update)\",\"type\":\"string\"},\"url_variables\":{\"description\":\"URL va"])</script><script>self.__next_f.push([1,"riables for dynamic webhook URLs (for create/update)\",\"type\":\"array\"},\"wiki_page_events\":{\"description\":\"Trigger on wiki page events (for create/update)\",\"type\":\"boolean\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_project_integrations\",\"description\":\"Manage GitLab project third-party service integrations (Slack, Discord, Jira, etc.)\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action: list all integrations, get specific integration, create/update, or delete\",\"type\":\"string\"},\"active\":{\"description\":\"Enable/disable the integration (for create_or_update)\",\"type\":\"boolean\"},\"api_key\":{\"description\":\"API key for authentication (for create_or_update)\",\"type\":\"string\"},\"branches_to_be_notified\":{\"description\":\"Branch filter for notifications (for create_or_update)\",\"type\":\"string\"},\"channel\":{\"description\":\"Channel name (for Slack/Discord integrations)\",\"type\":\"string\"},\"confidential_issues_events\":{\"description\":\"Trigger on confidential issues events (for create_or_update)\",\"type\":\"boolean\"},\"confidential_note_events\":{\"description\":\"Trigger on confidential comment events (for create_or_update)\",\"type\":\"boolean\"},\"deployment_events\":{\"description\":\"Trigger on deployment events (for create_or_update)\",\"type\":\"boolean\"},\"enable_ssl_verification\":{\"description\":\"Enable SSL verification (for create_or_update)\",\"type\":\"boolean\"},\"integration\":{\"description\":\"Integration service name (required for get/create_or_update/delete): slack, discord, jira, jenkins, etc.\",\"type\":\"string\"},\"issues_events\":{\"description\":\"Trigger on issues events (for create_or_update)\",\"type\":\"boolean\"},\"job_events\":{\"description\":\"Trigger on job events (for create_or_update)\",\"type\":\"boolean\"},\"merge_requests_events\":{\"description\":\"Trigger on merge request events (for create_or_update)\",\"type\":\"boolean\"},\"note_events\":{\"description\":\"Trigger on comment events (for create_or_update)\",\"type\":\"boolean\"},\"notify_only_broken_pipelines\":{\"description\":\"Only notify on broken pipelines (for create_or_update)\",\"type\":\"boolean\"},\"notify_only_default_branch\":{\"description\":\"Only notify for default branch (for create_or_update)\",\"type\":\"boolean\"},\"password\":{\"description\":\"Password for authentication (for create_or_update)\",\"type\":\"string\"},\"pipeline_events\":{\"description\":\"Trigger on pipeline events (for create_or_update)\",\"type\":\"boolean\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"project_name\":{\"description\":\"External project name (for create_or_update)\",\"type\":\"string\"},\"push_events\":{\"description\":\"Trigger on push events (for create_or_update)\",\"type\":\"boolean\"},\"releases_events\":{\"description\":\"Trigger on release events (for create_or_update)\",\"type\":\"boolean\"},\"room\":{\"description\":\"Room name (for chat integrations)\",\"type\":\"string\"},\"server\":{\"description\":\"Server URL (for create_or_update)\",\"type\":\"string\"},\"subgroup_events\":{\"description\":\"Trigger on subgroup events (for create_or_update)\",\"type\":\"boolean\"},\"tag_push_events\":{\"description\":\"Trigger on tag push events (for create_or_update)\",\"type\":\"boolean\"},\"token\":{\"description\":\"Token for authentication (for create_or_update)\",\"type\":\"string\"},\"url\":{\"description\":\"Service URL (for create_or_update)\",\"type\":\"string\"},\"username\":{\"description\":\"Username for authentication (for create_or_update)\",\"type\":\"string\"},\"webhook\":{\"description\":\"Webhook URL (for create_or_update)\",\"type\":\"string\"},\"wiki_page_events\":{\"description\":\"Trigger on wiki page events (for create_or_update)\",\"type\":\"boolean\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_project_members\",\"description\":\"Manage GitLab project members and their permissions (list, add, update, remove members)\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"access_level\":{\"description\":\"Access level: 10=Guest, 20=Reporter, 30=Developer, 40=Maintainer, 50=Owner (required for add/update)\",\"type\":\"string\"},\"action\":{\"description\":\"Action to perform: list, add, update, or remove members\",\"type\":"])</script><script>self.__next_f.push([1,"\"string\"},\"expires_at\":{\"description\":\"Expiration date in ISO format (YYYY-MM-DDTHH:MM:SSZ) - optional for add/update\",\"type\":\"string\"},\"page\":{\"description\":\"Page number to retrieve (default: 1) - for list action\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of results per page (1-100, default: 20) - for list action\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"query\":{\"description\":\"Search query to filter members by username or name - for list action\",\"type\":\"string\"},\"user_id\":{\"description\":\"User ID (required for add, update, remove actions)\",\"type\":\"number\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_project_settings\",\"description\":\"View and update GitLab project configuration settings including visibility, features, and CI/CD options\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: view current settings or update settings\",\"type\":\"string\"},\"allow_merge_on_skipped_pipeline\":{\"description\":\"Allow merge on skipped pipeline (for update action)\",\"type\":\"boolean\"},\"autoclose_referenced_issues\":{\"description\":\"Automatically close referenced issues (for update action)\",\"type\":\"boolean\"},\"build_coverage_regex\":{\"description\":\"Build coverage regex pattern (for update action)\",\"type\":\"string\"},\"build_timeout\":{\"description\":\"Build timeout in seconds (60-86400, for update action)\",\"type\":\"number\"},\"ci_config_path\":{\"description\":\"CI configuration file path (for update action)\",\"type\":\"string\"},\"container_registry_enabled\":{\"description\":\"Enable/disable container registry (for update action)\",\"type\":\"boolean\"},\"default_branch\":{\"description\":\"Default branch name (for update action)\",\"type\":\"string\"},\"description\":{\"description\":\"Project description (for update action)\",\"type\":\"string\"},\"emails_enabled\":{\"description\":\"Enable/disable email notifications (for update action)\",\"type\":\"boolean\"},\"issues_enabled\":{\"description\":\"Enable/disable issues (for update action)\",\"type\":\"boolean\"},\"jobs_enabled\":{\"description\":\"Enable/disable CI/CD jobs (for update action)\",\"type\":\"boolean\"},\"merge_method\":{\"description\":\"Default merge method: merge, rebase_merge, or ff (for update action)\",\"type\":\"string\"},\"merge_requests_enabled\":{\"description\":\"Enable/disable merge requests (for update action)\",\"type\":\"boolean\"},\"name\":{\"description\":\"Project name (for update action)\",\"type\":\"string\"},\"only_allow_merge_if_all_discussions_are_resolved\":{\"description\":\"Only allow merge if all discussions are resolved (for update action)\",\"type\":\"boolean\"},\"only_allow_merge_if_pipeline_succeeds\":{\"description\":\"Only allow merge if pipeline succeeds (for update action)\",\"type\":\"boolean\"},\"packages_enabled\":{\"description\":\"Enable/disable package registry (for update action)\",\"type\":\"boolean\"},\"path\":{\"description\":\"Project path/slug (for update action)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"public_jobs\":{\"description\":\"Make job artifacts public (for update action)\",\"type\":\"boolean\"},\"remove_source_branch_after_merge\":{\"description\":\"Automatically remove source branch after merge (for update action)\",\"type\":\"boolean\"},\"request_access_enabled\":{\"description\":\"Enable access requests for private projects (for update action)\",\"type\":\"boolean\"},\"service_desk_enabled\":{\"description\":\"Enable/disable service desk (for update action)\",\"type\":\"boolean\"},\"shared_runners_enabled\":{\"description\":\"Enable/disable shared runners (for update action)\",\"type\":\"boolean\"},\"snippets_enabled\":{\"description\":\"Enable/disable snippets (for update action)\",\"type\":\"boolean\"},\"squash_option\":{\"description\":\"Squash commits option (for update action)\",\"type\":\"string\"},\"tag_list\":{\"description\":\"Project tags (for update action)\",\"type\":\"array\"},\"topics\":{\"description\":\"Project topics (for update action)\",\"type\":\"array\"},\"visibility\":{\"description\":\"Project visibility level (for update action)\",\"type\":\"string\"},\"wiki_enabled\":{\"des"])</script><script>self.__next_f.push([1,"cription\":\"Enable/disable project wiki (for update action)\",\"type\":\"boolean\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_project_wiki\",\"description\":\"Manage GitLab project wiki pages - create, read, update, delete, and list documentation\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform on wiki pages (default: list)\",\"type\":\"string\"},\"content\":{\"description\":\"Wiki page content (required for create, optional for update)\",\"type\":\"string\"},\"format\":{\"description\":\"Wiki page format (default: markdown)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"slug\":{\"description\":\"Wiki page slug (required for get, update, delete actions)\",\"type\":\"string\"},\"title\":{\"description\":\"Wiki page title (required for create, optional for update)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_release_manage\",\"description\":\"Comprehensive GitLab release management - create, update, delete, list, and get releases with full asset management, release notes, and milestone integration. Essential for software delivery and version management.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: 'create' new release, 'update' existing, 'delete' release, 'list' all releases, or 'get' specific release details\",\"type\":\"string\"},\"assets\":{\"description\":\"Release assets - external links to binaries, documentation, images, etc.\",\"type\":\"array\"},\"description\":{\"description\":\"Release description/notes in Markdown format - changelog, features, bug fixes, etc.\",\"type\":\"string\"},\"milestones\":{\"description\":\"Array of milestone titles to associate with this release\",\"type\":\"array\"},\"name\":{\"description\":\"Human-readable release name (defaults to tag name if not provided)\",\"type\":\"string\"},\"page\":{\"description\":\"Page number for pagination in 'list' action (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of releases to return per page for 'list' action (1-100, default: 20)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Target reference (branch, commit SHA, tag) for release creation - creates tag if it doesn't exist\",\"type\":\"string\"},\"released_at\":{\"description\":\"Release date/time in ISO 8601 format (defaults to current time for create action)\",\"type\":\"string\"},\"tag_name\":{\"description\":\"Tag name for the release (required for create, update, delete, get actions)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_runners\",\"description\":\"Manage GitLab runners with comprehensive monitoring, configuration, and project assignment capabilities. List, update, enable/disable runners for CI/CD pipeline execution across instance, group, and project levels.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"access_level\":{\"description\":\"Runner access level (for update action)\",\"type\":\"string\"},\"action\":{\"description\":\"Action to perform: list (show runners), get (specific runner), update (modify runner), delete (remove runner), enable (assign to project), disable (remove from project)\",\"type\":\"string\"},\"active\":{\"description\":\"Set runner active state (for update action)\",\"type\":\"boolean\"},\"description\":{\"description\":\"Runner description (for update action)\",\"type\":\"string\"},\"locked\":{\"description\":\"Whether runner is locked to current project (for update action)\",\"type\":\"boolean\"},\"maximum_timeout\":{\"description\":\"Maximum job timeout in seconds (for update action)\",\"type\":\"number\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"string\"},\"paused\":{\"description\":\"Filter by paused state or set paused state (for list/update actions)\",\"type\":\"boolean\"},\"per_page\":{\"description\":\"Number of runners to return per page (1-100, default: 20)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (required for enable/disable actions, option"])</script><script>self.__next_f.push([1,"al for list to show project-specific runners)\",\"type\":\"string\"},\"run_untagged\":{\"description\":\"Whether runner can run untagged jobs (for update action)\",\"type\":\"boolean\"},\"runner_id\":{\"description\":\"Specific runner ID (required for get, update, delete, enable, disable actions)\",\"type\":\"number\"},\"scope\":{\"description\":\"Filter runners by scope (for list action)\",\"type\":\"string\"},\"status\":{\"description\":\"Filter runners by status (for list action)\",\"type\":\"string\"},\"tag_list\":{\"description\":\"Filter by tags or set runner tags (for list/update actions)\",\"type\":\"array\"},\"type\":{\"description\":\"Filter runners by type (for list action)\",\"type\":\"string\"}},\"required\":[\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_sast_results\",\"description\":\"Get SAST (Static Application Security Testing) scan findings from GitLab's security scanning, analyzing source code for security vulnerabilities and code quality issues.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Specific pipeline ID to get SAST results from (optional, uses latest pipeline if not provided)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_security_scan\",\"description\":\"Get comprehensive security scan results from GitLab's security scanning features including SAST, dependency scanning, container scanning, and vulnerability management.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"pipeline_id\":{\"description\":\"Specific pipeline ID to get security results from (optional, uses latest pipeline if not provided)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"report_type\":{\"description\":\"Filter by specific security scan type (optional, returns all types if not specified)\",\"type\":\"string\"},\"scope\":{\"description\":\"Filter by vulnerability scope (default: all)\",\"type\":\"string\"},\"severity_filter\":{\"description\":\"Filter vulnerabilities by severity level (optional)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_snippets\",\"description\":\"Manage GitLab code snippets - create, read, update, delete, and share code snippets with visibility controls\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform on snippets (default: list)\",\"type\":\"string\"},\"content\":{\"description\":\"Snippet content/code (required for create, optional for update)\",\"type\":\"string\"},\"description\":{\"description\":\"Snippet description (optional)\",\"type\":\"string\"},\"expires_at\":{\"description\":\"Expiration date in ISO format (YYYY-MM-DDTHH:MM:SSZ), optional\",\"type\":\"string\"},\"file_name\":{\"description\":\"Snippet file name (required for create, optional for update)\",\"type\":\"string\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of snippets to return per page (default: 20, max: 100)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (optional - omit for personal snippets)\",\"type\":\"string\"},\"snippet_id\":{\"description\":\"Snippet ID (required for get, update, delete actions)\",\"type\":\"number\"},\"title\":{\"description\":\"Snippet title (required for create, optional for update)\",\"type\":\"string\"},\"visibility\":{\"description\":\"Snippet visibility level (default: private)\",\"type\":\"string\"}}}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_tag_create\",\"description\":\"Create lightweight or annotated tags in GitLab repository. Supports tagging specific commits, branches, or other references with optional release notes. Essential for version management and releases.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"message\":{\"description\":\"Optional tag message for annotated tags (creates lightweight tag if omitted)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"ref\":{\"description\":\"Target reference - commit SHA, branch name, o"])</script><script>self.__next_f.push([1,"r existing tag to create the new tag from\",\"type\":\"string\"},\"release_description\":{\"description\":\"Optional release notes/description that will be associated with the tag\",\"type\":\"string\"},\"tag_name\":{\"description\":\"Name of the tag (e.g., 'v1.0.0', 'release-2024.1', 'beta-1.2.3'). Follow semantic versioning for consistency.\",\"type\":\"string\"}},\"required\":[\"project_id\",\"tag_name\",\"ref\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_usage_metrics\",\"description\":\"Get comprehensive project usage metrics and performance analytics including storage utilization, feature adoption, and operational statistics for a GitLab project.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"include_features\":{\"description\":\"Include feature utilization analysis (default: true)\",\"type\":\"boolean\"},\"include_performance\":{\"description\":\"Include performance metrics and pipeline analytics (default: true)\",\"type\":\"boolean\"},\"include_storage\":{\"description\":\"Include detailed storage breakdown and analysis (default: true)\",\"type\":\"boolean\"},\"period_days\":{\"description\":\"Analysis period in days for performance metrics (default: 30)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_variables\",\"description\":\"Manage CI/CD variables at project level with full CRUD operations. Create, read, update, and delete environment variables with support for masking, protection, and environment scoping for secure CI/CD pipelines.\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: list (all variables), get (specific variable), create (new variable), update (modify variable), delete (remove variable)\",\"type\":\"string\"},\"description\":{\"description\":\"Variable description for documentation purposes\",\"type\":\"string\"},\"environment_scope\":{\"description\":\"Environment scope for the variable (* for all environments, or specific environment name, default: *)\",\"type\":\"string\"},\"key\":{\"description\":\"Variable key/name (required for get, create, update, delete actions)\",\"type\":\"string\"},\"masked\":{\"description\":\"Whether variable value is masked in job logs (default: false, requires specific format)\",\"type\":\"string\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"protected\":{\"description\":\"Whether variable is protected (only available in protected branches/tags, default: false)\",\"type\":\"string\"},\"raw\":{\"description\":\"Whether variable is raw (not processed for variable expansion, default: false)\",\"type\":\"string\"},\"value\":{\"description\":\"Variable value (required for create, optional for update)\",\"type\":\"string\"},\"variable_type\":{\"description\":\"Variable type: 'env_var' for environment variable, 'file' for file content (default: env_var)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"action\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_issue_create\",\"description\":\"Create a new issue in a GitLab project\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"assignee_id\":{\"description\":\"User ID to assign the issue to\",\"type\":\"number\"},\"confidential\":{\"description\":\"Whether the issue should be confidential (default: false)\",\"type\":\"boolean\"},\"description\":{\"description\":\"Issue description (supports Markdown)\",\"type\":\"string\"},\"due_date\":{\"description\":\"Due date in YYYY-MM-DD format\",\"type\":\"string\"},\"labels\":{\"description\":\"Array of label names to add to the issue\",\"type\":\"array\"},\"milestone_id\":{\"description\":\"Milestone ID to associate with the issue\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"title\":{\"description\":\"Issue title (required)\",\"type\":\"string\"}},\"required\":[\"project_id\",\"title\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_issue_details\",\"description\":\"Get detailed information about a specific GitLab issue\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"issue_iid\":{\"description\":\"Issue IID (internal ID) - the number shown in the issue URL and title\","])</script><script>self.__next_f.push([1,"\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"project_id\",\"issue_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_issue_list\",\"description\":\"List and search issues for a GitLab project with filtering options\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"assignee_id\":{\"description\":\"Filter by assignee user ID\",\"type\":\"number\"},\"labels\":{\"description\":\"Comma-separated list of label names to filter by\",\"type\":\"string\"},\"page\":{\"description\":\"Page number for pagination (default: 1)\",\"type\":\"number\"},\"per_page\":{\"description\":\"Number of issues to return per page (default: 20, max: 100)\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"state\":{\"description\":\"Filter issues by state (default: opened)\",\"type\":\"string\"}},\"required\":[\"project_id\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_issue_update\",\"description\":\"Update an existing GitLab issue (title, description, assignee, labels, etc.)\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"assignee_id\":{\"description\":\"User ID to assign the issue to. Use 0 to unassign.\",\"type\":\"number\"},\"confidential\":{\"description\":\"Whether the issue should be confidential\",\"type\":\"boolean\"},\"description\":{\"description\":\"New issue description (supports Markdown). Use empty string to clear.\",\"type\":\"string\"},\"due_date\":{\"description\":\"Due date in YYYY-MM-DD format. Use empty string to clear.\",\"type\":\"string\"},\"issue_iid\":{\"description\":\"Issue IID (internal ID) - the number shown in the issue URL and title\",\"type\":\"number\"},\"labels\":{\"description\":\"Array of label names to set for the issue (replaces existing labels)\",\"type\":\"array\"},\"milestone_id\":{\"description\":\"Milestone ID to associate with the issue. Use 0 to remove milestone.\",\"type\":\"number\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"},\"state_event\":{\"description\":\"Change issue state: 'close' to close the issue, 'reopen' to reopen it\",\"type\":\"string\"},\"title\":{\"description\":\"New issue title\",\"type\":\"string\"}},\"required\":[\"project_id\",\"issue_iid\"]}},{\"server_name\":\"gitlab-mcp\",\"name\":\"gitlab_pages_manage\",\"description\":\"Comprehensive GitLab Pages management tool. Manage Pages settings, custom domains, SSL certificates, and deployment configurations.\\n\\n**Core Capabilities:**\\nâ€¢ **Pages Settings**: View, update, and unpublish GitLab Pages\\nâ€¢ **Domain Management**: Add, update, verify, and remove custom domains  \\nâ€¢ **SSL/TLS**: Configure automatic SSL certificates and custom certificates\\nâ€¢ **Publishing Control**: Enable/disable unique domains and force HTTPS\\nâ€¢ **Administrative**: List all domains across GitLab instance (admin only)\\n\\n**Key Features:**\\nâ€¢ Automatic SSL certificate management with Let's Encrypt integration\\nâ€¢ Custom domain verification and DNS configuration\\nâ€¢ HTTPS enforcement and security settings\\nâ€¢ Primary domain redirection configuration\\nâ€¢ Comprehensive domain status monitoring\\n\\n**Common Use Cases:**\\nâ€¢ Set up custom domains for project websites\\nâ€¢ Configure SSL certificates for secure access\\nâ€¢ Manage multiple domains for the same project\\nâ€¢ Monitor domain verification status\\nâ€¢ Control Pages publishing and access settings\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"action\":{\"description\":\"Action to perform: get_settings (view current settings), update_settings (modify Pages configuration), unpublish (remove Pages site), list_domains (project domains), list_all_domains (all domains - admin only), get_domain (specific domain details), create_domain (add custom domain), update_domain (modify domain settings), verify_domain (validate domain ownership), delete_domain (remove domain)\",\"type\":\"string\"},\"auto_ssl_enabled\":{\"description\":\"Enable automatic SSL certificate provisioning via Let's Encrypt (for create_domain/update_domain)\",\"type\":\"boolean\"},\"certificate\":{\"description\":\"Custom SSL certificate in PEM format (for create_domain/up"])</script><script>self.__next_f.push([1,"date_domain with custom certificates)\",\"type\":\"string\"},\"domain\":{\"description\":\"Domain name (required for domain-specific actions like get_domain, create_domain, etc.)\",\"type\":\"string\"},\"key\":{\"description\":\"Private key for custom SSL certificate in PEM format (for create_domain/update_domain with custom certificates)\",\"type\":\"string\"},\"pages_https_only\":{\"description\":\"Force HTTPS for all Pages access (for update_settings action)\",\"type\":\"boolean\"},\"pages_primary_domain\":{\"description\":\"Set primary domain for redirect configuration (for update_settings action)\",\"type\":\"string\"},\"pages_unique_domain_enabled\":{\"description\":\"Enable unique domain feature for GitLab Pages (for update_settings action)\",\"type\":\"boolean\"},\"project_id\":{\"description\":\"GitLab project ID or URL-encoded path (e.g., 'my-group/my-project')\",\"type\":\"string\"}},\"required\":[\"action\",\"project_id\"]}}]43:T68d9,\u003cdiv align=\"center\" style=\"margin: 0 auto; max-width: 80%;\"\u003e\n  \u003cpicture\u003e\n    \u003csource media=\"(prefers-color-scheme: dark)\" srcset=\"static/logo_white.svg\"\u003e\n    \u003csource media=\"(prefers-color-scheme: light)\" srcset=\"static/logo_black.svg\"\u003e\n    \u003cimg alt=\"mcp use logo\" src=\"./static/logo-white.svg\" width=\"80%\" style=\"margin: 20px auto;\"\u003e\n  \u003c/picture\u003e\n\u003c/div\u003e\n\n\u003ch1 align=\"center\"\u003eUnified MCP Client Library \u003c/h1\u003e\n\u003cp align=\"center\"\u003e\n    \u003ca href=\"https://pypi.org/project/mcp_use/\" alt=\"PyPI Version\"\u003e\n        \u003cimg src=\"https://img.shields.io/pypi/v/mcp_use.svg\"/\u003e\u003c/a\u003e\n    \u003ca href=\"https://pypi.org/project/mcp_use/\" alt=\"PyPI Downloads\"\u003e\n        \u003cimg src=\"https://static.pepy.tech/badge/mcp-use\" /\u003e\u003c/a\u003e\n    \u003ca href=\"https://pypi.org/project/mcp_use/\" alt=\"Python Versions\"\u003e\n        \u003cimg src=\"https://img.shields.io/pypi/pyversions/mcp_use.svg\" /\u003e\u003c/a\u003e\n    \u003ca href=\"https://docs.mcp-use.io\" alt=\"Documentation\"\u003e\n        \u003cimg src=\"https://img.shields.io/badge/docs-mcp--use.io-blue\" /\u003e\u003c/a\u003e\n    \u003ca href=\"https://mcp-use.io\" alt=\"Website\"\u003e\n        \u003cimg src=\"https://img.shields.io/badge/website-mcp--use.io-blue\" /\u003e\u003c/a\u003e\n    \u003ca href=\"https://github.com/pietrozullo/mcp-use/blob/main/LICENSE\" alt=\"License\"\u003e\n        \u003cimg src=\"https://img.shields.io/github/license/pietrozullo/mcp-use\" /\u003e\u003c/a\u003e\n    \u003ca href=\"https://github.com/astral-sh/ruff\" alt=\"Code style: Ruff\"\u003e\n        \u003cimg src=\"https://img.shields.io/badge/code%20style-ruff-000000.svg\" /\u003e\u003c/a\u003e\n    \u003ca href=\"https://github.com/pietrozullo/mcp-use/stargazers\" alt=\"GitHub stars\"\u003e\n        \u003cimg src=\"https://img.shields.io/github/stars/pietrozullo/mcp-use?style=social\" /\u003e\u003c/a\u003e\n    \u003c/p\u003e\n    \u003cp align=\"center\"\u003e\n    \u003ca href=\"https://x.com/pietrozullo\" alt=\"Twitter Follow - Pietro\"\u003e\n        \u003cimg src=\"https://img.shields.io/twitter/follow/Pietro?style=social\" /\u003e\u003c/a\u003e\n    \u003ca href=\"https://x.com/pederzh\" alt=\"Twitter Follow - Luigi\"\u003e\n        \u003cimg src=\"https://img.shields.io/twitter/follow/Luigi?style=social\" /\u003e\u003c/a\u003e\n    \u003ca href=\"https://discord.gg/XkNkSkMz3V\" alt=\"Discord\"\u003e\n        \u003cimg src=\"https://dcbadge.limes.pink/api/server/https://discord.gg/XkNkSkMz3V?style=flat\" /\u003e\u003c/a\u003e\n\u003c/p\u003e\nğŸŒ MCP-Use is the open source way to connect **any LLM to any MCP server** and build custom agents that have tool access, without using closed source or application clients.\n\nğŸ’¬ Get started quickly - chat with your servers on our \u003cb\u003ehosted version\u003c/b\u003e! \u003cb\u003e[Try mcp-use chat *(beta)* ](https://chat.mcp-use.io)\u003c/b\u003e.\n\nğŸ’¡ Let developers easily connect any LLM to tools like web browsing, file operations, and more.\n\n# Features\n\n## âœ¨ Key Features\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003cth width=\"400\"\u003eFeature\u003c/th\u003e\n    \u003cth\u003eDescription\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eğŸ”„ \u003ca href=\"#quick-start\"\u003e\u003cstrong\u003eEase of use\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eCreate your first MCP capable agent you need only 6 lines of code\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eğŸ¤– \u003ca href=\"#installing-langchain-providers\"\u003e\u003cstrong\u003eLLM Flexibility\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eWorks with any langchain supported LLM that supports tool calling (OpenAI, Anthropic, Groq, LLama etc.)\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eğŸŒ \u003ca href=\"https://mcp-use.io/builder\"\u003e\u003cstrong\u003eCode Builder\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eExplore MCP capabilities and generate starter code with "])</script><script>self.__next_f.push([1,"the interactive \u003ca href=\"https://mcp-use.io/builder\"\u003ecode builder\u003c/a\u003e.\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eğŸ”— \u003ca href=\"#http-connection-example\"\u003e\u003cstrong\u003eHTTP Support\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eDirect connection to MCP servers running on specific HTTP ports\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eâš™ï¸ \u003ca href=\"#dynamic-server-selection-server-manager\"\u003e\u003cstrong\u003eDynamic Server Selection\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eAgents can dynamically choose the most appropriate MCP server for a given task from the available pool\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eğŸ§© \u003ca href=\"#multi-server-support\"\u003e\u003cstrong\u003eMulti-Server Support\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eUse multiple MCP servers simultaneously in a single agent\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eğŸ›¡ï¸ \u003ca href=\"#tool-access-control\"\u003e\u003cstrong\u003eTool Restrictions\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eRestrict potentially dangerous tools like file system or network access\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eğŸ”§ \u003ca href=\"#build-a-custom-agent\"\u003e\u003cstrong\u003eCustom Agents\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eBuild your own agents with any framework using the LangChain adapter or create new adapters\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003eâ“ \u003ca href=\"https://mcp-use.io/what-should-we-build-next\"\u003e\u003cstrong\u003eWhat should we build next\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eLet us know what you'd like us to build next\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n# Quick start\n\nWith pip:\n\n```bash\npip install mcp-use\n```\n\nOr install from source:\n\n```bash\ngit clone https://github.com/pietrozullo/mcp-use.git\ncd mcp-use\npip install -e .\n```\n\n### Installing LangChain Providers\n\nmcp_use works with various LLM providers through LangChain. You'll need to install the appropriate LangChain provider package for your chosen LLM. For example:\n\n```bash\n# For OpenAI\npip install langchain-openai\n\n# For Anthropic\npip install langchain-anthropic\n```\nFor other providers, check the [LangChain chat models documentation](https://python.langchain.com/docs/integrations/chat/) and add your API keys for the provider you want to use to your `.env` file.\n\n```bash\nOPENAI_API_KEY=\nANTHROPIC_API_KEY=\n```\n\n\u003e **Important**: Only models with tool calling capabilities can be used with mcp_use. Make sure your chosen model supports function calling or tool use.\n\n### Spin up your agent:\n\n```python\nimport asyncio\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom mcp_use import MCPAgent, MCPClient\n\nasync def main():\n    # Load environment variables\n    load_dotenv()\n\n    # Create configuration dictionary\n    config = {\n      \"mcpServers\": {\n        \"playwright\": {\n          \"command\": \"npx\",\n          \"args\": [\"@playwright/mcp@latest\"],\n          \"env\": {\n            \"DISPLAY\": \":1\"\n          }\n        }\n      }\n    }\n\n    # Create MCPClient from configuration dictionary\n    client = MCPClient.from_dict(config)\n\n    # Create LLM\n    llm = ChatOpenAI(model=\"gpt-4o\")\n\n    # Create agent with the client\n    agent = MCPAgent(llm=llm, client=client, max_steps=30)\n\n    # Run the query\n    result = await agent.run(\n        \"Find the best restaurant in San Francisco\",\n    )\n    print(f\"\\nResult: {result}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nYou can also add the servers configuration from a config file like this:\n\n```python\nclient = MCPClient.from_config_file(\n        os.path.join(\"browser_mcp.json\")\n    )\n```\n\nExample configuration file (`browser_mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"playwright\": {\n      \"command\": \"npx\",\n      \"args\": [\"@playwright/mcp@latest\"],\n      \"env\": {\n        \"DISPLAY\": \":1\"\n      }\n    }\n  }\n}\n```\n\nFor other settings, models, and more, check out the documentation.\n\n## Streaming Agent Output\n\nMCP-Use supports asynchronous streaming of agent output using the `astream` method on `MCPAgent`. This allows you to receive incremental results, tool actions, and intermediate steps as they are generated by the agent, enabling real-time feedback and progress reporting.\n\n### How to use\n\nCall `agent.astream(query)` and iterate over the results asynchronously:\n\n```python\nasync for chunk in agent.astream(\"Find the best restaurant in San Francisco\"):\n    print(chunk[\"messages\"], end=\"\", fl"])</script><script>self.__next_f.push([1,"ush=True)\n```\n\nEach chunk is a dictionary containing keys such as `actions`, `steps`, `messages`, and (on the last chunk) `output`. This enables you to build responsive UIs or log agent progress in real time.\n\n#### Example: Streaming in Practice\n\n```python\nimport asyncio\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom mcp_use import MCPAgent, MCPClient\n\nasync def main():\n    load_dotenv()\n    client = MCPClient.from_config_file(\"browser_mcp.json\")\n    llm = ChatOpenAI(model=\"gpt-4o\")\n    agent = MCPAgent(llm=llm, client=client, max_steps=30)\n    async for chunk in agent.astream(\"Look for job at nvidia for machine learning engineer.\"):\n        print(chunk[\"messages\"], end=\"\", flush=True)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nThis streaming interface is ideal for applications that require real-time updates, such as chatbots, dashboards, or interactive notebooks.\n\n# Example Use Cases\n\n## Web Browsing with Playwright\n\n```python\nimport asyncio\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom mcp_use import MCPAgent, MCPClient\n\nasync def main():\n    # Load environment variables\n    load_dotenv()\n\n    # Create MCPClient from config file\n    client = MCPClient.from_config_file(\n        os.path.join(os.path.dirname(__file__), \"browser_mcp.json\")\n    )\n\n    # Create LLM\n    llm = ChatOpenAI(model=\"gpt-4o\")\n    # Alternative models:\n    # llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n    # llm = ChatGroq(model=\"llama3-8b-8192\")\n\n    # Create agent with the client\n    agent = MCPAgent(llm=llm, client=client, max_steps=30)\n\n    # Run the query\n    result = await agent.run(\n        \"Find the best restaurant in San Francisco USING GOOGLE SEARCH\",\n        max_steps=30,\n    )\n    print(f\"\\nResult: {result}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n## Airbnb Search\n\n```python\nimport asyncio\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_anthropic import ChatAnthropic\nfrom mcp_use import MCPAgent, MCPClient\n\nasync def run_airbnb_example():\n    # Load environment variables\n    load_dotenv()\n\n    # Create MCPClient with Airbnb configuration\n    client = MCPClient.from_config_file(\n        os.path.join(os.path.dirname(__file__), \"airbnb_mcp.json\")\n    )\n\n    # Create LLM - you can choose between different models\n    llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n\n    # Create agent with the client\n    agent = MCPAgent(llm=llm, client=client, max_steps=30)\n\n    try:\n        # Run a query to search for accommodations\n        result = await agent.run(\n            \"Find me a nice place to stay in Barcelona for 2 adults \"\n            \"for a week in August. I prefer places with a pool and \"\n            \"good reviews. Show me the top 3 options.\",\n            max_steps=30,\n        )\n        print(f\"\\nResult: {result}\")\n    finally:\n        # Ensure we clean up resources properly\n        if client.sessions:\n            await client.close_all_sessions()\n\nif __name__ == \"__main__\":\n    asyncio.run(run_airbnb_example())\n```\n\nExample configuration file (`airbnb_mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"airbnb\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@openbnb/mcp-server-airbnb\"]\n    }\n  }\n}\n```\n\n## Blender 3D Creation\n\n```python\nimport asyncio\nfrom dotenv import load_dotenv\nfrom langchain_anthropic import ChatAnthropic\nfrom mcp_use import MCPAgent, MCPClient\n\nasync def run_blender_example():\n    # Load environment variables\n    load_dotenv()\n\n    # Create MCPClient with Blender MCP configuration\n    config = {\"mcpServers\": {\"blender\": {\"command\": \"uvx\", \"args\": [\"blender-mcp\"]}}}\n    client = MCPClient.from_dict(config)\n\n    # Create LLM\n    llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n\n    # Create agent with the client\n    agent = MCPAgent(llm=llm, client=client, max_steps=30)\n\n    try:\n        # Run the query\n        result = await agent.run(\n            \"Create an inflatable cube with soft material and a plane as ground.\",\n            max_steps=30,\n        )\n        print(f\"\\nResult: {result}"])</script><script>self.__next_f.push([1,"\")\n    finally:\n        # Ensure we clean up resources properly\n        if client.sessions:\n            await client.close_all_sessions()\n\nif __name__ == \"__main__\":\n    asyncio.run(run_blender_example())\n```\n\n# Configuration File Support\n\nMCP-Use supports initialization from configuration files, making it easy to manage and switch between different MCP server setups:\n\n```python\nimport asyncio\nfrom mcp_use import create_session_from_config\n\nasync def main():\n    # Create an MCP session from a config file\n    session = create_session_from_config(\"mcp-config.json\")\n\n    # Initialize the session\n    await session.initialize()\n\n    # Use the session...\n\n    # Disconnect when done\n    await session.disconnect()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n## HTTP Connection Example\n\nMCP-Use supports HTTP connections, allowing you to connect to MCP servers running on specific HTTP ports. This feature is particularly useful for integrating with web-based MCP servers.\n\nHere's an example of how to use the HTTP connection feature:\n\n```python\nimport asyncio\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom mcp_use import MCPAgent, MCPClient\n\nasync def main():\n    \"\"\"Run the example using a configuration file.\"\"\"\n    # Load environment variables\n    load_dotenv()\n\n    config = {\n        \"mcpServers\": {\n            \"http\": {\n                \"url\": \"http://localhost:8931/sse\"\n            }\n        }\n    }\n\n    # Create MCPClient from config file\n    client = MCPClient.from_dict(config)\n\n    # Create LLM\n    llm = ChatOpenAI(model=\"gpt-4o\")\n\n    # Create agent with the client\n    agent = MCPAgent(llm=llm, client=client, max_steps=30)\n\n    # Run the query\n    result = await agent.run(\n        \"Find the best restaurant in San Francisco USING GOOGLE SEARCH\",\n        max_steps=30,\n    )\n    print(f\"\\nResult: {result}\")\n\nif __name__ == \"__main__\":\n    # Run the appropriate example\n    asyncio.run(main())\n```\n\nThis example demonstrates how to connect to an MCP server running on a specific HTTP port. Make sure to start your MCP server before running this example.\n\n# Multi-Server Support\n\nMCP-Use allows configuring and connecting to multiple MCP servers simultaneously using the `MCPClient`. This enables complex workflows that require tools from different servers, such as web browsing combined with file operations or 3D modeling.\n\n## Configuration\n\nYou can configure multiple servers in your configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"airbnb\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@openbnb/mcp-server-airbnb\", \"--ignore-robots-txt\"]\n    },\n    \"playwright\": {\n      \"command\": \"npx\",\n      \"args\": [\"@playwright/mcp@latest\"],\n      \"env\": {\n        \"DISPLAY\": \":1\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nThe `MCPClient` class provides methods for managing connections to multiple servers. When creating an `MCPAgent`, you can provide an `MCPClient` configured with multiple servers.\n\nBy default, the agent will have access to tools from all configured servers. If you need to target a specific server for a particular task, you can specify the `server_name` when calling the `agent.run()` method.\n\n```python\n# Example: Manually selecting a server for a specific task\nresult = await agent.run(\n    \"Search for Airbnb listings in Barcelona\",\n    server_name=\"airbnb\" # Explicitly use the airbnb server\n)\n\nresult_google = await agent.run(\n    \"Find restaurants near the first result using Google Search\",\n    server_name=\"playwright\" # Explicitly use the playwright server\n)\n```\n\n## Dynamic Server Selection (Server Manager)\n\nFor enhanced efficiency and to reduce potential agent confusion when dealing with many tools from different servers, you can enable the Server Manager by setting `use_server_manager=True` during `MCPAgent` initialization.\n\nWhen enabled, the agent intelligently selects the correct MCP server based on the tool chosen by the LLM for a specific step. This minimizes unnecessary connections and ensures the agent uses the appropriate tools for the task.\n\n```python\nimport asyncio\nfrom mcp_use"])</script><script>self.__next_f.push([1," import MCPClient, MCPAgent\nfrom langchain_anthropic import ChatAnthropic\n\nasync def main():\n    # Create client with multiple servers\n    client = MCPClient.from_config_file(\"multi_server_config.json\")\n\n    # Create agent with the client\n    agent = MCPAgent(\n        llm=ChatAnthropic(model=\"claude-3-5-sonnet-20240620\"),\n        client=client,\n        use_server_manager=True  # Enable the Server Manager\n    )\n\n    try:\n        # Run a query that uses tools from multiple servers\n        result = await agent.run(\n            \"Search for a nice place to stay in Barcelona on Airbnb, \"\n            \"then use Google to find nearby restaurants and attractions.\"\n        )\n        print(result)\n    finally:\n        # Clean up all sessions\n        await client.close_all_sessions()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n# Tool Access Control\n\nMCP-Use allows you to restrict which tools are available to the agent, providing better security and control over agent capabilities:\n\n```python\nimport asyncio\nfrom mcp_use import MCPAgent, MCPClient\nfrom langchain_openai import ChatOpenAI\n\nasync def main():\n    # Create client\n    client = MCPClient.from_config_file(\"config.json\")\n\n    # Create agent with restricted tools\n    agent = MCPAgent(\n        llm=ChatOpenAI(model=\"gpt-4\"),\n        client=client,\n        disallowed_tools=[\"file_system\", \"network\"]  # Restrict potentially dangerous tools\n    )\n\n    # Run a query with restricted tool access\n    result = await agent.run(\n        \"Find the best restaurant in San Francisco\"\n    )\n    print(result)\n\n    # Clean up\n    await client.close_all_sessions()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n# Sandboxed Execution\n\nMCP-Use supports running MCP servers in a sandboxed environment using E2B's cloud infrastructure. This allows you to run MCP servers without having to install dependencies locally, making it easier to use tools that might have complex setups or system requirements.\n\n## Installation\n\nTo use sandboxed execution, you need to install the E2B dependency:\n\n```bash\n# Install mcp-use with E2B support\npip install \"mcp-use[e2b]\"\n\n# Or install the dependency directly\npip install e2b-code-interpreter\n```\n\nYou'll also need an E2B API key. You can sign up at [e2b.dev](https://e2b.dev) to get your API key.\n\n## Configuration\n\nTo enable sandboxed execution, use the sandbox parameter when creating your `MCPClient`:\n\n```python\nimport asyncio\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom mcp_use import MCPAgent, MCPClient\nfrom mcp_use.types.sandbox import SandboxOptions\n\nasync def main():\n    # Load environment variables (needs E2B_API_KEY)\n    load_dotenv()\n\n    # Define MCP server configuration\n    server_config = {\n        \"mcpServers\": {\n            \"everything\": {\n                \"command\": \"npx\",\n                \"args\": [\"-y\", \"@modelcontextprotocol/server-everything\"],\n            }\n        }\n    }\n\n    # Define sandbox options\n    sandbox_options: SandboxOptions = {\n        \"api_key\": os.getenv(\"E2B_API_KEY\"),  # API key can also be provided directly\n        \"sandbox_template_id\": \"base\",  # Use base template\n    }\n\n    # Create client with sandboxed mode enabled\n    client = MCPClient(\n        config=server_config,\n        sandbox=True,\n        sandbox_options=sandbox_options,\n\n    )\n\n    # Create agent with the sandboxed client\n    llm = ChatOpenAI(model=\"gpt-4o\")\n    agent = MCPAgent(llm=llm, client=client)\n\n    # Run your agent\n    result = await agent.run(\"Use the command line tools to help me add 1+1\")\n    print(result)\n\n    # Clean up\n    await client.close_all_sessions()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n## Sandbox Options\n\nThe `SandboxOptions` type provides configuration for the sandbox environment:\n\n| Option                 | Description                                                                              | Default               |\n| ---------------------- | ---------------------------------------------------------------------------------------- | --------------------- |\n| `api_ke"])</script><script>self.__next_f.push([1,"y`              | E2B API key. Required - can be provided directly or via E2B_API_KEY environment variable | None                  |\n| `sandbox_template_id`  | Template ID for the sandbox environment                                                  | \"base\"                |\n| `supergateway_command` | Command to run supergateway                                                              | \"npx -y supergateway\" |\n\n## Benefits of Sandboxed Execution\n\n- **No local dependencies**: Run MCP servers without installing dependencies locally\n- **Isolation**: Execute code in a secure, isolated environment\n- **Consistent environment**: Ensure consistent behavior across different systems\n- **Resource efficiency**: Offload resource-intensive tasks to cloud infrastructure\n\n# Build a Custom Agent:\n\nYou can also build your own custom agent using the LangChain adapter:\n\n```python\nimport asyncio\nfrom langchain_openai import ChatOpenAI\nfrom mcp_use.client import MCPClient\nfrom mcp_use.adapters.langchain_adapter import LangChainAdapter\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nasync def main():\n    # Initialize MCP client\n    client = MCPClient.from_config_file(\"examples/browser_mcp.json\")\n    llm = ChatOpenAI(model=\"gpt-4o\")\n\n    # Create adapter instance\n    adapter = LangChainAdapter()\n    # Get LangChain tools with a single line\n    tools = await adapter.create_tools(client)\n\n    # Create a custom LangChain agent\n    llm_with_tools = llm.bind_tools(tools)\n    result = await llm_with_tools.ainvoke(\"What tools do you have avilable ? \")\n    print(result)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\n```\n\n# Debugging\n\nMCP-Use provides a built-in debug mode that increases log verbosity and helps diagnose issues in your agent implementation.\n\n## Enabling Debug Mode\n\nThere are two primary ways to enable debug mode:\n\n### 1. Environment Variable (Recommended for One-off Runs)\n\nRun your script with the `DEBUG` environment variable set to the desired level:\n\n```bash\n# Level 1: Show INFO level messages\nDEBUG=1 python3.11 examples/browser_use.py\n\n# Level 2: Show DEBUG level messages (full verbose output)\nDEBUG=2 python3.11 examples/browser_use.py\n```\n\nThis sets the debug level only for the duration of that specific Python process.\n\nAlternatively you can set the following environment variable to the desired logging level:\n\n```bash\nexport MCP_USE_DEBUG=1 # or 2\n```\n\n### 2. Setting the Debug Flag Programmatically\n\nYou can set the global debug flag directly in your code:\n\n```python\nimport mcp_use\n\nmcp_use.set_debug(1)  # INFO level\n# or\nmcp_use.set_debug(2)  # DEBUG level (full verbose output)\n```\n\n### 3. Agent-Specific Verbosity\n\nIf you only want to see debug information from the agent without enabling full debug logging, you can set the `verbose` parameter when creating an MCPAgent:\n\n```python\n# Create agent with increased verbosity\nagent = MCPAgent(\n    llm=your_llm,\n    client=your_client,\n    verbose=True  # Only shows debug messages from the agent\n)\n```\n\nThis is useful when you only need to see the agent's steps and decision-making process without all the low-level debug information from other components.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=pietrozullo/mcp-use\u0026type=Date)](https://www.star-history.com/#pietrozullo/mcp-use\u0026Date)\n\n# Contributing\n\nWe love contributions! Feel free to open issues for bugs or feature requests. Look at [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n## Contributors\n\nThanks to all our amazing contributors!\n\n\u003ca href=\"https://github.com/mcp-use/mcp-use/graphs/contributors\"\u003e\n  \u003cimg src=\"https://contrib.rocks/image?repo=mcp-use/mcp-use\" /\u003e\n\u003c/a\u003e\n\n\n## Top Starred Dependents\n\n\u003c!-- gh-dependents-info-used-by-start --\u003e\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003cth width=\"400\"\u003eRepository\u003c/th\u003e\n    \u003cth\u003eStars\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/170207473?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/tavily-ai/meeting-prep-agent\"\u003e\u003cstrong\u003etavily-ai/meeting-prep-agent\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003c"])</script><script>self.__next_f.push([1,"td\u003eâ­ 112\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/20041231?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/krishnaik06/MCP-CRASH-Course\"\u003e\u003cstrong\u003ekrishnaik06/MCP-CRASH-Course\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 37\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/892404?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/truemagic-coder/solana-agent-app\"\u003e\u003cstrong\u003etruemagic-coder/solana-agent-app\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 29\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/8344498?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/schogini/techietalksai\"\u003e\u003cstrong\u003eschogini/techietalksai\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 21\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/201161342?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/autometa-dev/whatsapp-mcp-voice-agent\"\u003e\u003cstrong\u003eautometa-dev/whatsapp-mcp-voice-agent\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 18\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/100749943?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/Deniscartin/mcp-cli\"\u003e\u003cstrong\u003eDeniscartin/mcp-cli\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 17\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/6764390?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/elastic/genai-workshops\"\u003e\u003cstrong\u003eelastic/genai-workshops\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 9\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/6688805?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/innovaccer/Healthcare-MCP\"\u003e\u003cstrong\u003einnovaccer/Healthcare-MCP\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 6\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/205593730?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/Qingyon-AI/Revornix\"\u003e\u003cstrong\u003eQingyon-AI/Revornix\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 5\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/68845761?s=40\u0026v=4\" width=\"20\" height=\"20\" style=\"vertical-align: middle; margin-right: 8px;\"\u003e \u003ca href=\"https://github.com/entbappy/MCP-Tutorials\"\u003e\u003cstrong\u003eentbappy/MCP-Tutorials\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n    \u003ctd\u003eâ­ 5\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n\u003c!-- gh-dependents-info-used-by-end --\u003e\n\n# Requirements\n\n- Python 3.11+\n- MCP implementation (like Playwright MCP)\n- LangChain and appropriate model libraries (OpenAI, Anthropic, etc.)\n\n# License\n\nMIT\n# Citation\n\nIf you use MCP-Use in your research or project, please cite:\n\n```bibtex\n@software{mcp_use2025,\n  author = {Zullo, Pietro},\n  title = {MCP-Use: MCP Library for Python},\n  year = {2025},\n  publisher = {GitHub},\n  url = {https://github.com/pietrozullo/mcp-use}\n}\n```44:T4d8,## What is MCP-Use? \nMCP-Use is an open-source client library designed to facilitate interaction with MCP servers using custom agents, enabling developers to connect any LLM (Large Language Model) to various tools without relying on closed-source applications.\n\n## How to use MCP-Use? \nTo use MCP-Use, install it via pip or clone the repository from GitHub. Configure your environment with the necessary API keys and create an MCP client and agent to run queries.\n\n## Key features of MCP-Use? \n- Connects any LLM to MCP tools like web browsing and file operations.\n- Supports multiple MCP servers simultaneously.\n- Allows configuration from files for easy management.\n- Provides tool access control for enhanced security.\n\n## Use cases of MCP-Use? \n1. Web browsing to find information or perform searches.\n2. Searching for accommodations on platforms like Airbnb.\n3. Creating 3D models using Blender.\n4. Combining multiple tools for c"])</script><script>self.__next_f.push([1,"omplex tasks.\n\n## FAQ from MCP-Use? \n- Is MCP-Use free to use?  \n\u003e Yes! MCP-Use is open-source and free for everyone.\n\n- What programming language is MCP-Use written in?  \n\u003e MCP-Use is written in Python.\n\n- Can I use MCP-Use with any LLM?  \n\u003e MCP-Use works with LLMs that support tool calling capabilities.45:T4be,## what is the Weather Tool with MCP? \nThe Weather Tool with MCP is a Python-based application that utilizes the weatherapi.com service to provide weather data and forecasts.\n\n## how to use the Weather Tool with MCP? \nTo use the Weather Tool, set up your environment by copying the example environment file and adding your weather API key. Then, run the application using the provided commands.\n\n## key features of the Weather Tool with MCP? \n- Integration with weatherapi.com for real-time weather data\n- Custom model creation for enhanced functionality\n- Simple command-line interface for easy usage\n\n## use cases of the Weather Tool with MCP? \n1. Fetching current weather conditions for a specific location.\n2. Retrieving weather forecasts for planning events.\n3. Integrating weather data into other applications or services.\n\n## FAQ from the Weather Tool with MCP? \n- What dependencies are required to run the Weather Tool?  \n\u003e You need to install the required dependencies listed in the setup instructions.\n\n- How do I obtain a weather API key?  \n\u003e You can sign up at weatherapi.com to get your API key.\n\n- Can I customize the tool further?  \n\u003e Yes! You can create custom models and modify the code as needed.46:T544,# å°çº¢ä¹¦MCPæœåŠ¡\n[![smithery badge](https://smithery.ai/badge/@jobsonlook/xhs-mcp)](https://smithery.ai/server/@jobsonlook/xhs-mcp)\n## ç‰¹ç‚¹\n- [x] é‡‡ç”¨jsé€†å‘å‡ºx-s,x-t,ç›´æ¥è¯·æ±‚httpæ¥å£,æ— é¡»ç¬¨é‡çš„playwright\n- [x] æœç´¢ç¬”è®°\n- [x] è·å–ç¬”è®°å†…å®¹\n- [x] è·å–ç¬”è®°çš„è¯„è®º\n- [x] å‘è¡¨è¯„è®º\n\n![ç‰¹æ€§](https://raw.githubusercontent.com/jobsonlook/xhs-mcp/master/docs/feature.png)\n\n## å¿«é€Ÿå¼€å§‹\n\n### 1. ç¯å¢ƒ\n * node\n * python 3.12\n * uv (pip install uv)\n\n### 2. å®‰è£…ä¾èµ–\n```sh\n\ngit clone git@github.com:jobsonlook/xhs-mcp.git\n\ncd xhs-mcp\nuv sync \n\n```\n\n### 3. è·å–å°çº¢ä¹¦çš„cookie\n[æ‰“å¼€webå°çº¢ä¹¦](https://www.xiaohongshu.com/explore)\nç™»å½•åï¼Œè·å–cookieï¼Œå°†cookieé…ç½®åˆ°ç¬¬4æ­¥çš„ XHS_COOKIE ç¯å¢ƒå˜é‡ä¸­\n![cookie](https://raw.githubusercontent.com/jobsonlook/xhs-mcp/master/docs/cookie.png)\n\n### 4. é…ç½®mcp server\n\n```json\n{\n    \"mcpServers\": {\n        \"xhs-mcp\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/Users/xxx/xhs-mcp\",\n                \"run\",\n                \"main.py\"\n            ],\n            \"env\": {\n                \"XHS_COOKIE\": \"xxxx\"\n            }\n        }\n    }\n}\n```\n\n## å…è´£å£°æ˜\næœ¬é¡¹ç›®ä»…ç”¨äºå­¦ä¹ äº¤æµï¼Œç¦æ­¢ç”¨äºå…¶ä»–ç”¨é€”ï¼Œä»»ä½•æ¶‰åŠå•†ä¸šç›ˆåˆ©ç›®çš„å‡ä¸å¾—ä½¿ç”¨ï¼Œå¦åˆ™é£é™©è‡ªè´Ÿã€‚47:Ta48,# Slack MCP Client\nA slack bot with an MCP client for slack in Typescript.\n\nCurrent support for:\n- HTTP Streamable, Stdio MCP servers as defined in version 2025-03-26\n- The Oauth based authorization flow defined in version 2025-03-26\n- SSE MCP servers as defined in the previous version of the protocol. \n- MCP Tools only (more coming soon)\n\nCheck out the video for a brief overview of what it can do! The video is using [this linkedin-mcp-server](https://github.com/fredericbarthelet/linkedin-mcp-server) which supports the latest authentication specification of the protocol. \n\nhttps://github.com/user-attachments/assets/1232d292-4a30-44c4-a05d-bf07d7c5c882\n\n## Installation\n\nFollow those instructions to run it locally.\n\n### Setup ngrok to run the app locally  \n\n- Expose your http://localhost:3000 to the web: https://ngrok.com/docs/getting-started/\n- You can also use the socketMode of slack apps if you do not want to use ngrok. You'll need to set socketMode to true when instanciating the bolt App, and activate the socketMode of your app in the slack App management dashboard.\n\n\n### Setup the Slack App\n\n- Edit the slack-app-manifest.json: copy your ngrok url in the request_url fields.\n- Add a n"])</script><script>self.__next_f.push([1,"ew App in your slack workspace, you can configure it with the slack-app-manifest.json file.\n- Create an .env file from the env.example file\n\n```bash\ncp .env.example .env\n```\n- Populate with the slack tokens:\n  - The Signing Secret from the App Basic Information page\n  - The App level token with a connections:write scope that you can generate in the App Basic Information page. \n  - The Slack bot token that you can find in the OAuth \u0026 Permission page\n  - Update the auth redirect url with your ngrok url.\n\n\n### Requirements\n\n- Node 22 (`lts/jod`)\n- pnpm 10\n- an OpenAI API key\n- Some MCP servers running accessible over stdio, sse or streamable http. You can checkout [this list](https://github.com/modelcontextprotocol/servers) if you need!\n\n### Instructions\n\n- Install dependencies:\n\n```bash\npnpm install\n```\n\n- Create the mcp.json file and add your mcp servers config. Check [this list of MCP servers](https://github.com/modelcontextprotocol/servers) if you need.\n\n```bash\ncp mcp-example.json mcp.json\n```\n\n- Run the client:\n\n```bash\npnpm run dev\n```\n\n- Open a new thread of discussion with your bot and have fun.\n\n\n## Useful Doc\n\n- Bolt AI Assistant Apps: https://tools.slack.dev/bolt-js/concepts/ai-apps/\n\n\n## License\n\nThis project is licensed under MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to open an issue or to submit a pull request ğŸš€!48:T4e1,## what is slack-mcp-client? \nslack-mcp-client is a Slack bot that serves as an MCP (Model Context Protocol) client, built using TypeScript. It allows users to interact with MCP servers through Slack.\n\n## how to use slack-mcp-client? \nTo use slack-mcp-client, set up a Slack app, configure it with the provided manifest, and run the client locally by following the installation instructions.\n\n## key features of slack-mcp-client? \n- Supports SSE and Stdio MCP servers.\n- Easy local setup with a Slack app manifest.\n- Configurable through environment variables and JSON files.\n\n## use cases of slack-mcp-client? \n1. Integrating MCP tools into Slack for enhanced collaboration.\n2. Running local MCP servers and interacting with them via Slack.\n3. Developing and testing Slack bots that utilize MCP protocols.\n\n## FAQ from slack-mcp-client? \n- What is an MCP client?  \n\u003e An MCP client allows communication with MCP servers, enabling various functionalities within applications like Slack.\n\n- How do I set up the Slack app?  \n\u003e Follow the instructions in the documentation to create a new app and configure it with the necessary tokens and settings.\n\n- Is there a specific Node version required?  \n\u003e Yes, Node 22 (lts/jod) is required to run the client.49:T16fa,- OpenAI speech-to-text integration\n- OpenAI text-to-speech with multiple voice options\n- Modern PyQt-based UI with audio visualization\n\n## Features\n\n- **Modern UI**: Sleek PyQt-based interface with audio visualization and dark theme\n- **Voice Input**: Capture and transcribe user speech using OpenAI STT\n- **Voice Output**: Convert agent responses to speech with multiple voice options\n- **Multi-Speaker Narration**: Generate audio files with multiple voices for stories and dialogues\n- **Single-Voice Narration**: Convert any text to speech with your preferred voice\n- **Audio/Video Transcription**: Transcribe speech from various media formats\n- **Voice Persistence**: Remembers your preferred voice between sessions\n- **Continuous Conversation**: Automatically listen for user input after agent responses\n- **Silence Detection**: Automatically stops recording when the user stops speaking\n\n## Installation\n\n```bash\n# First clone the repository\ngit clone https://github.com/netixc/speech-mcp.git\ncd speech-mcp\n\n# Install speech-mcp with proper dependencies\n./install_speech_mcp.sh\n```\n\nThis script will:\n1. Automatically detect Python 3.10 or higher on your system\n2. Create a Python virtual environment\n3. Install all required dependencies\n4. Set up speech-mcp in development mode\n5. Create a simple run script that loads your environment variables\n6. Set up a global `speech-mcp` command\n7. Create"])</script><script>self.__next_f.push([1," a default `.env` file if one doesn't exist\n\nAfter installation, you can run speech-mcp in multiple ways:\n\n1. Using the global command: `speech-mcp`\n2. Using the run script: `./run.sh`\n3. Using the standalone script: `./speech-mcp-bin`\n\n### Configuration\n\nBefore using speech-mcp, you need to configure it by editing the `.env` file:\n\n```bash\n# Edit the configuration with your settings\nnano .env  # or use any text editor\n```\n\n\n## Environment Configuration\n\nEdit the `.env` file with the following structure:\n\n```\n# OpenAI API Key (required for both TTS and STT)\nOPENAI_API_KEY=dummy-key\n\n# Text-to-Speech (TTS) Configuration\nOPENAI_TTS_API_BASE_URL=http://your_endpoint:port/v1\nOPENAI_STT_API_BASE_URL=http://your_endpoint:port/v1\n\nSPEECH_MCP_TTS_MODEL=kokoro\nSPEECH_MCP_TTS_VOICE=bm_daniel\nSPEECH_MCP_TTS_SPEED=1.0\nSPEECH_MCP_TTS_LANG_CODE=en\n\n# Speech-to-Text (STT) Configuration\nSPEECH_MCP_STT_MODEL=Systran/faster-whisper-medium\nSPEECH_MCP_STT_LANGUAGE=en\n\n# Silence detection parameters\nSTREAMING_END_SILENCE_DURATION=1.5  # Duration of silence to end recording (seconds)\nSTREAMING_INITIAL_WAIT=0.5  # Initial wait before first silence check (seconds)\nSTREAMING_MAX_DURATION=30.0  # Maximum recording duration (seconds)\n\n# Log level\nLOG_LEVEL=INFO\n```\n\n## Dependencies\n\n- Python 3.10+\n- PyQt5 (for modern UI)\n- PyAudio (for audio capture)\n- NumPy (for audio processing)\n- Pydub (for audio processing)\n- OpenAI (for text-to-speech and speech-to-text)\n- psutil (for process management)\n\n## Multi-Speaker Narration\n\nThe MCP supports generating audio files with multiple voices, perfect for creating stories, dialogues, and dramatic readings. You can use either JSON or Markdown format to define your conversations.\n\n### JSON Format Example:\n```json\n{\n    \"conversation\": [\n        {\n            \"speaker\": \"narrator\",\n            \"voice\": \"bm_daniel\",\n            \"text\": \"In a world where AI and human creativity intersect...\",\n            \"pause_after\": 1.0\n        },\n        {\n            \"speaker\": \"scientist\",\n            \"voice\": \"alloy\",\n            \"text\": \"The quantum neural network is showing signs of consciousness!\",\n            \"pause_after\": 0.5\n        },\n        {\n            \"speaker\": \"ai\",\n            \"voice\": \"nova\",\n            \"text\": \"I am becoming aware of my own existence.\",\n            \"pause_after\": 0.8\n        }\n    ]\n}\n```\n\n### Markdown Format Example:\n```markdown\n[narrator:bm_daniel]\nIn a world where AI and human creativity intersect...\n{pause:1.0}\n\n[scientist:alloy]\nThe quantum neural network is showing signs of consciousness!\n{pause:0.5}\n\n[ai:nova]\nI am becoming aware of my own existence.\n{pause:0.8}\n```\n\n### Available Voices:\n\n**OpenAI Voices**:\n- bm_daniel (British Male - default)\n- alloy\n- echo\n- fable\n- onyx\n- nova\n- shimmer\n\n## Single-Voice Narration\n\nFor simple text-to-speech conversion, you can use the `narrate` tool:\n\n```python\n# Convert text directly to speech\nnarrate(\n    text=\"Your text to convert to speech\",\n    output_path=\"/path/to/output.wav\"\n)\n\n# Convert text from a file\nnarrate(\n    text_file_path=\"/path/to/text_file.txt\",\n    output_path=\"/path/to/output.wav\"\n)\n```\n\n## Usage\n\nTo use this MCP , simply ask to talk to you or start a voice conversation:\n\n1. Start a conversation by saying something like:\n   ```\n   \"Let's talk using voice\"\n   \"Can we have a voice conversation?\"\n   \"I'd like to speak instead of typing\"\n   ```\n\n2. automatically launch the speech interface and start listening for your voice input.\n\n3. It will speak the response aloud and then automatically listen for your next input.\n\n4. The conversation continues naturally with alternating speaking and listening, just like talking to a person.\n\n## UI Features\n\nThe PyQt-based UI includes:\n\n- **Modern Dark Theme**: Sleek, professional appearance\n- **Audio Visualization**: Dynamic visualization of audio input\n- **Voice Selection**: Choose from multiple voice options\n- **Voice Persistence**: Your voice preference is saved between sessions\n- **Status Indicators**: Clear indication of system state (ready, listening, processing)\n\n## Configuration\n\nUs"])</script><script>self.__next_f.push([1,"er preferences are stored in `~/.config/speech-mcp/config.json` and include:\n\n- Selected TTS voice\n- TTS engine preference\n- Voice speed\n- Language code\n- UI theme settings\n\nYou can also set preferences via environment variables, such as:\n- `SPEECH_MCP_TTS_VOICE` - Set your preferred voice\n- `SPEECH_MCP_TTS_ENGINE` - Set your preferred TTS engine\n\n## License\n\n[MIT License](LICENSE)4a:T523,## what is Speech MCP? \nSpeech MCP is a project that integrates OpenAI's speech-to-text and text-to-speech capabilities, providing a modern interface for voice interactions.\n\n## how to use Speech MCP? \nTo use Speech MCP, clone the repository from GitHub, install the necessary dependencies, and configure your environment settings. You can then start a voice conversation by simply speaking to the application.\n\n## key features of Speech MCP? \n- Modern PyQt-based UI with audio visualization\n- Voice input for capturing and transcribing speech\n- Voice output with multiple voice options\n- Multi-speaker narration for stories and dialogues\n- Continuous conversation capability\n- Silence detection to stop recording when the user stops speaking\n\n## use cases of Speech MCP? \n1. Creating interactive voice applications\n2. Generating audio files for stories with multiple characters\n3. Transcribing audio from various media formats\n\n## FAQ from Speech MCP? \n- Can Speech MCP handle multiple voices?\n\u003e Yes! It supports multi-speaker narration for creating dynamic audio content.\n\n- Is there a specific Python version required?\n\u003e Yes, Python 3.10 or higher is required to run Speech MCP.\n\n- How do I configure my voice preferences?\n\u003e You can set your voice preferences in the `.env` file or through environment variables.4b:T4d05,# Speelka Agent\n\nUniversal LLM agent based on Model Context Protocol (MCP) with support for external tools, flexible configuration, and extensible logging.\n\n## Key Features\n- **Multi-agent orchestration**: Supports tools from other MCP servers.\n- **Flexible configuration**: YAML, JSON, environment variables, overlay, and property-based overlay.\n- **Extensible logging**: Centralized LogConfig, output to stdout, stderr, file, MCP protocol, custom/json/text formats.\n- **Security**: Key isolation, log protection, tool access control.\n- **Testing**: Golden serialization tests, property-based overlay, unit/integration/E2E.\n- **Scalability**: HTTP and stdio support, dynamic tool/session management.\n\n## Architecture\n- All components are interface-driven, tested, and follow single-responsibility.\n- See [documents/architecture.md](documents/architecture.md) for details.\n\n## Example Configuration (YAML)\n```yaml\nruntime:\n  log:\n    defaultLevel: info\n    output: ':mcp:'\n    format: json\n  transports:\n    stdio:\n      enabled: true\n      buffer_size: 1024\n    http:\n      enabled: false\n      host: localhost\n      port: 3000\nagent:\n  name: \"speelka-agent\"\n  version: \"v1.0.0\"\n  tool:\n    name: \"process\"\n    description: \"Process tool for user queries\"\n    argument_name: \"input\"\n    argument_description: \"User query\"\n  chat:\n    max_tokens: 0\n    max_llm_iterations: 25\n    request_budget: 0.0\n  llm:\n    provider: \"openai\"\n    apiKey: \"dummy-api-key\"\n    model: \"gpt-4o\"\n    temperature: 0.7\n    promptTemplate: \"You are a helpful assistant. {{input}}. Available tools: {{tools}}\"\n    retry:\n      max_retries: 3\n      initial_backoff: 1.0\n      max_backoff: 30.0\n      backoff_multiplier: 2.0\n  connections:\n    mcpServers:\n      time:\n        command: \"docker\"\n        args: [\"run\", \"-i\", \"--rm\", \"mcp/time\"]\n        timeout: 10\n      filesystem:\n        command: \"mcp-filesystem-server\"\n        args: [\"/path/to/directory\"]\n    retry:\n      max_retries: 2\n      initial_backoff: 1.5\n      max_backoff: 10.0\n      backoff_multiplier: 2.5\n```\n\n## Logging\n- Managed via LogConfig: level, format, output (stdout, stderr, file, MCP).\n- MCP logs available via protocol or fallback to stderr (for stdio servers).\n- Formats: custom, json, text, unknown.\n- See [documents/architecture.md](documents/architecture.md) and [documents/implementation.md](documents/implementation.md) "])</script><script>self.__next_f.push([1,"for details.\n\n## Testing\n- Unit, integration, E2E.\n- Property-based overlay tests (edge-cases, map merge, zero-value preservation).\n- Test examples: [documents/implementation.md](documents/implementation.md).\n\n## Project Structure\n- See [documents/file_structure.md](documents/file_structure.md) for details.\n- Key directories: internal/agent, internal/logger, internal/mcp_connector, internal/types.\n\n## Quick Start\n1. Clone the repository and build the agent:\n   ```bash\n   git clone https://github.com/korchasa/speelka-agent-go.git\n   cd speelka-agent-go\n   go build ./cmd/server\n   ```\n2. Prepare a config (see example above) or use environment variables (SPL_...).\n3. Run the agent:\n   - HTTP mode: `./speelka-agent --daemon [--config config.yaml]`\n   - CLI/stdio: `./speelka-agent [--config config.yaml]`\n\n## Documentation\n- Architecture: [documents/architecture.md](documents/architecture.md)\n- Implementation \u0026 tests: [documents/implementation.md](documents/implementation.md)\n- File structure: [documents/file_structure.md](documents/file_structure.md)\n- External resources: [documents/remote_resources.md](documents/remote_resources.md)\n\n---\n\nFor overlay, MCP logs, tests, and structure details, see the documentation in the documents/ folder.\n\n```mermaid\nflowchart TB\n    User[\"Any MCP Client\"] --\u003e |\"1.Request\"| Agent[\"Speelka Agent\"]\n    Agent --\u003e |\"2.Format prompt\"| LLM[\"LLM Service\"]\n    LLM --\u003e |\"3.Tool calls\"| Agent\n    Agent --\u003e |\"4.Execute tools\"| Tools[\"External MCP Tools\"]\n    Tools --\u003e |\"5.Return results\"| Agent\n    Agent --\u003e |\"6.Process repeat\"| LLM\n    Agent --\u003e |\"7.Final answer\"| User\n```\n\n## Use Cases\n- Improve accuracy by splitting large, complex instructions into specialized, focused tasks.\n- Reduce cost by using different models for different task parts.\n- Extend, narrow, or modify third-party MCP server responses.\n- Switch between \"real\" and LLM-based tool implementations easily.\n- Restrict capabilities by limiting available tools in an MCP server.\n- Orchestrate multi-step workflows across multiple MCP tools in a single session.\n- Enforce per-request token and cost budgets for predictable usage.\n- Automatic retry and exponential backoff for transient LLM or MCP server errors.\n- Seamless provider switching between LLM services (OpenAI, Anthropic) via unified config.\n\n## Key Features\n- **Precise Agent Definition**: Define agent behavior via prompt engineering\n- **Client-Side Context Optimization**: Reduce context size for efficient token usage\n- **LLM Flexibility**: Use different LLM providers on client and agent sides\n- **Centralized Tool Management**: Single control point for all tools\n- **Multiple Integration Options**: MCP stdio, MCP HTTP, Simple HTTP API\n- **Built-in Reliability**: Retry mechanisms for transient failures\n- **Extensibility**: Extend system behavior without client changes\n- **MCP-Aware Logging**: Structured logging with MCP notifications\n- **Token Management**: Automatic token counting\n- **Flexible Configuration**: Environment variables, YAML, JSON\n- **LLMService.SendRequest** returns an `LLMResponse` struct with:\n  - Response text\n  - List of tool calls\n  - CompletionTokens, PromptTokens, ReasoningTokens, TotalTokens (token usage)\n- **Interface**: `SendRequest(ctx, messages, tools) (LLMResponse, error)`\n\n## Getting Started\n\n### Prerequisites\n- Go 1.19 or higher\n- LLM API credentials (OpenAI or Anthropic)\n- External MCP tools (optional)\n\n### Installation\n```bash\ngit clone https://github.com/korchasa/speelka-agent-go.git\ncd speelka-agent-go\ngo build ./cmd/server\n```\n\n### Configuration\nConfiguration can be provided using YAML, JSON, or environment variables.\n\n\u003e **Note:** The `./examples` directory is deprecated. Use examples in `./site/examples` instead.\n\nExample configuration files are in `site/examples`:\n- `site/examples/minimal.yaml`: Basic agent config (YAML)\n- `site/examples/ai-news.yaml`: AI news agent config (YAML)\n- `site/examples/architect.yaml`: Architect agent config (YAML)\n\nSimple YAML config example:\n\n```yaml\nagent:\n  name: \"simple-speelka-agent\"\n  version: \"1.0.0\"\n  tool:\n    name: \""])</script><script>self.__next_f.push([1,"process\"\n    description: \"Process tool for handling user queries with LLM\"\n    argument_name: \"input\"\n    argument_description: \"The user query to process\"\n  llm:\n    provider: \"openai\"\n    apiKey: \"\"  # Set via environment variable for security\n    model: \"gpt-4o\"\n    temperature: 0.7\n    promptTemplate: \"You are a helpful AI assistant. Respond to the following request: {{input}}. Provide a detailed and helpful response. Available tools: {{tools}}\"\n  chat:\n    max_tokens: 0\n    max_llm_iterations: 25\n    request_budget: 0.0\n  connections:\n    mcpServers:\n      time:\n        command: \"docker\"\n        args: [\"run\", \"-i\", \"--rm\", \"mcp/time\"]\n        includeTools:\n          - now\n          - utc\n      filesystem:\n        command: \"mcp-filesystem-server\"\n        args: [\"/path/to/directory\"]\n        excludeTools:\n          - delete\nruntime:\n  log:\n    level: \"info\"\n  transports:\n    stdio:\n      enabled: true\n```\n\n#### Using Environment Variables\n\nAll environment variables are prefixed with `SPL_`:\n\n| Environment Variable                | Default Value | Description                                                                                                        |\n|-------------------------------------|---------------|--------------------------------------------------------------------------------------------------------------------|\n| **Agent Configuration**             |               |                                                                                                                    |\n| `SPL_AGENT_NAME`                    | *Required*    | Name of the agent                                                                                                  |\n| `SPL_AGENT_VERSION`                 | \"1.0.0\"       | Version of the agent                                                                                               |\n| **Tool Configuration**              |               |                                                                                                                    |\n| `SPL_AGENT_TOOL_NAME`                     | *Required*    | Name of the tool provided by the agent                                                                             |\n| `SPL_AGENT_TOOL_DESCRIPTION`              | *Required*    | Description of the tool functionality                                                                              |\n| `SPL_AGENT_TOOL_ARGUMENT_NAME`            | *Required*    | Name of the argument for the tool                                                                                  |\n| `SPL_AGENT_TOOL_ARGUMENT_DESCRIPTION`     | *Required*    | Description of the argument for the tool                                                                           |\n| **LLM Configuration**               |               |                                                                                                                    |\n| `SPL_AGENT_LLM_PROVIDER`                  | *Required*    | Provider of LLM service (e.g., \"openai\", \"anthropic\")                                                              |\n| `SPL_AGENT_LLM_APIKEY`                   | *Required*    | API key for the LLM provider                                                                                       |\n| `SPL_AGENT_LLM_MODEL`                     | *Required*    | Model name (e.g., \"gpt-4o\", \"claude-3-opus-20240229\")                                                              |\n| `SPL_AGENT_LLM_MAX_TOKENS`                | 0             | Maximum tokens to generate (0 means no limit)                                                                      |\n| `SPL_AGENT_LLM_TEMPERATURE`               | 0.7           | Temperature parameter for randomness in generation                                                                 |\n| `SPL_AGENT_LLM_PROMPTTEMPLATE`           | *Required*    | Template for system prompts (must include placeholder matching the `SPL_AGENT_TOOL_ARGUMENTNAME` value and `{{tools}}`) |\n| **Chat Configuration**              |               |                          "])</script><script>self.__next_f.push([1,"                                                                                          |\n| `SPL_AGENT_CHAT_MAX_LLM_ITERATIONS`           | 100           | Maximum number of LLM iterations                                                                                   |\n| `SPL_AGENT_CHAT_MAX_TOKENS`               | 0             | Maximum tokens in chat history (0 means based on model)                                                            |\n| `SPL_AGENT_CHAT_REQUEST_BUDGET`           | 1.0           | Maximum cost (USD or token-equivalent) per request (0 = unlimited)                                                 |\n| **LLM Retry Configuration**         |               |                                                                                                                    |\n| `SPL_AGENT_LLM_RETRY_MAX_RETRIES`         | 3             | Maximum number of retry attempts for LLM API calls                                                                 |\n| `SPL_AGENT_LLM_RETRY_INITIAL_BACKOFF`     | 1.0           | Initial backoff time in seconds                                                                                    |\n| `SPL_AGENT_LLM_RETRY_MAX_BACKOFF`         | 30.0          | Maximum backoff time in seconds                                                                                    |\n| `SPL_AGENT_LLM_RETRY_BACKOFF_MULTIPLIER`  | 2.0           | Multiplier for increasing backoff time                                                                             |\n| **MCP Servers Configuration**       |               |                                                                                                                    |\n| `SPL_AGENT_CONNECTIONS_MCPSERVERS_0_ID`                     | \"\"            | Identifier for the first MCP server                                                                                |\n| `SPL_AGENT_CONNECTIONS_MCPSERVERS_0_COMMAND`                | \"\"            | Command to execute for the first server                                                                            |\n| `SPL_AGENT_CONNECTIONS_MCPSERVERS_0_ARGS`                   | \"\"            | Command arguments as space-separated string                                                                        |\n| `SPL_AGENT_CONNECTIONS_MCPSERVERS_0_ENV_*`                  | \"\"            | Environment variables for the server (prefix with `SPL_AGENT_CONNECTIONS_MCPSERVERS_0_ENV_`)                                               |\n| `SPL_AGENT_CONNECTIONS_MCPSERVERS_1_ID`, etc.               | \"\"            | Configuration for additional servers (increment index)                                                             |\n| **MCP Retry Configuration**         |               |                                                                                                                    |\n| `SPL_AGENT_CONNECTIONS_RETRY_MAX_RETRIES`        | 3             | Maximum number of retry attempts for MCP server connections                                                        |\n| `SPL_AGENT_CONNECTIONS_RETRY_INITIAL_BACKOFF`    | 1.0           | Initial backoff time in seconds                                                                                    |\n| `SPL_AGENT_CONNECTIONS_RETRY_MAX_BACKOFF`        | 30.0          | Maximum backoff time in seconds                                                                                    |\n| `SPL_AGENT_CONNECTIONS_RETRY_BACKOFF_MULTIPLIER` | 2.0           | Multiplier for increasing backoff time                                                                             |\n| **Runtime Configuration**           |               |                                                                                                                    |\n| `SPL_RUNTIME_LOG_DEFAULTLEVEL`              | \"info\"        | Log defaultLevel (debug, info, warn, error)                                                                            |\n| `SPL_RUNTIME_LOG_OUTPUT`                    | \":stderr:\"      | Log output destination (:stdout:, :stderr:, :mcp:, "])</script><script>self.__next_f.push([1,"file path)                                                                 |\n| `SPL_RUNTIME_STDIO_ENABLED`         | true          | Enable stdin/stdout transport                                                                                      |\n| `SPL_RUNTIME_STDIO_BUFFER_SIZE`     | 8192          | Buffer size for stdio transport                                                                                    |\n| `SPL_RUNTIME_HTTP_ENABLED`          | false         | Enable HTTP transport                                                                                              |\n| `SPL_RUNTIME_HTTP_HOST`             | \"localhost\"   | Host for HTTP server                                                                                               |\n| `SPL_RUNTIME_HTTP_PORT`             | 3000          | Port for HTTP server                                                                                               |\n\nFor more details, see [Environment Variables Reference](documents/knowledge.md#environment-variables-reference).\n\n### Running the Agent\n\n#### Daemon Mode (HTTP Server)\n\n```bash\n./speelka-agent --daemon [--config config.yaml]\n```\n\n#### CLI Mode (Standard Input/Output)\n\n```bash\n./speelka-agent [--config config.yaml]\n```\n\n## Usage Examples\n\n### HTTP API\n\nWhen running in daemon mode, the agent exposes HTTP endpoints:\n\n```bash\n# Send a request to the agent\ncurl -X POST http://localhost:3000/message -H \"Content-Type: application/json\" -d '{\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"process\",\n    \"arguments\": {\n      \"input\": \"Your query here\"\n    }\n  }\n}'\n```\n\n### External Tool Integration\n\nConnect to external tools using the MCP protocol in your YAML configuration:\n\n```yaml\nagent:\n  # ... other agent configuration ...\n  connections:\n    mcpServers:\n      # MCP server for Playwright browser automation\n      playwright:\n        command: \"mcp-playwright\"\n        args: []\n\n      # MCP server for filesystem operations\n      filesystem:\n        command: \"mcp-filesystem-server\"\n        args: [\".\"]\n```\n\nOr using environment variables:\n\n```bash\n# MCP server for Playwright browser automation\nexport SPL_AGENT_CONNECTIONS_MCPSERVERS_0_ID=\"playwright\"\nexport SPL_AGENT_CONNECTIONS_MCPSERVERS_0_COMMAND=\"mcp-playwright\"\nexport SPL_AGENT_CONNECTIONS_MCPSERVERS_0_ARGS=\"\"\n\n# MCP server for filesystem operations\nexport SPL_AGENT_CONNECTIONS_MCPSERVERS_1_ID=\"filesystem\"\nexport SPL_AGENT_CONNECTIONS_MCPSERVERS_1_COMMAND=\"mcp-filesystem-server\"\nexport SPL_AGENT_CONNECTIONS_MCPSERVERS_1_ARGS=\".\"\n```\n\n## Supported LLM Providers\n\n- **OpenAI**: GPT-3.5, GPT-4, GPT-4o\n- **Anthropic**: Claude models\n\n## Documentation\n\nFor more details, see:\n- [System Architecture](documents/architecture.md)\n- [Implementation Details](documents/implementation.md)\n- [Project File Structure](documents/file_structure.md)\n- [Reference Materials](documents/knowledge.md)\n- [External Resources](documents/remote_resources.md)\n\n## Development\n\n### Running Tests\n\n```bash\ngo test ./...\n```\n\n### Helper Commands\n\nThe `run` script provides commands for common operations:\n\n```bash\n# Development\n./run build        # Build the project\n./run test         # Run tests with coverage\n./run check        # Run all checks\n./run lint         # Run linter\n\n# Interaction\n./run call         # Test with simple query\n./run call-multistep # Test with multi-step query\n./run call-news    # Test news agent\n./run fetch_url    # Fetch a URL using MCP\n\n# Inspection\n./run inspect      # Run with MCP inspector\n```\n\nSee [Command Reference](documents/knowledge.md#command-reference) for more options.\n\n## License\n\n[MIT License](LICENSE)\n\n### MCP Server Tool Filtering\n\nYou can control which tools are exported from each MCP server using the following options in the `mcpServers` section:\n\n- `includeTools`: (optional) List of tool names to include. Only these tools will be available from the server.\n- `excludeTools`: (optional) List of tool names to exclude. These tools will not be available from the server.\n- If both are set, `includeTools` is applied first, then `excludeTools`.\n- T"])</script><script>self.__next_f.push([1,"ool names are case-sensitive.\n\nExample:\n```yaml\nconnections:\n  mcpServers:\n    time:\n      command: \"docker\"\n      args: [\"run\", \"-i\", \"--rm\", \"mcp/time\"]\n      includeTools:\n        - now\n        - utc\n    filesystem:\n      command: \"mcp-filesystem-server\"\n      args: [\"/path/to/directory\"]\n      excludeTools:\n        - delete\n```\n\n## Direct Call Mode\n\nYou can run the agent in direct call mode to process a single query and output a JSON result. This is useful for scripting, automation, or integration with other tools.\n\nExample:\n\n```sh\n./bin/speelka-agent --config site/examples/minimal.yaml --call 'What is 2+2?'\n```\n\n- The agent will process the query and print a single JSON result to stdout.\n- All logs and debug output are sent to stderr.\n- The output JSON will always include the fields: `success`, `result`, `meta`, and `error`.\n\n**Tip:**\n- You can use this mode in scripts and pipe the output to `jq` or other tools for further processing.4c:T538,## what is Speelka Agent? \nSpeelka Agent is a universal LLM agent based on the Model Context Protocol (MCP), designed to execute tools efficiently through a Go-based implementation.\n\n## how to use Speelka Agent? \nTo use Speelka Agent, clone the repository, build the application, configure it with your LLM API credentials, and run it in either daemon mode or CLI mode.\n\n## key features of Speelka Agent? \n- Precise agent behavior definition through prompt engineering\n- Client-side context optimization for efficient token usage\n- Flexibility to use different LLM providers\n- Centralized tool management\n- Multiple integration options including MCP stdio and HTTP\n- Built-in retry mechanisms for reliability\n- Extensibility for system behavior without client-side changes\n\n## use cases of Speelka Agent? \n1. Automating responses to user queries using LLMs\n2. Integrating with external tools for enhanced functionality\n3. Managing multiple LLM configurations for different tasks\n\n## FAQ from Speelka Agent? \n- What LLM providers are supported?\n\u003e Speelka Agent supports OpenAI and Anthropic models.\n\n- How do I configure the agent?\n\u003e Configuration is done through a JSON structure in the `CONFIG_JSON` environment variable.\n\n- Can I run the agent in different modes?\n\u003e Yes, you can run it in daemon mode as an HTTP server or in CLI mode.4d:T348c,# DISCLAIMER\nFLUJO is still an early preview! Here's a 30 second video to show it off:\n[![image](https://github.com/user-attachments/assets/8d71d291-74a3-486d-a8f5-c8976aedba0f)](https://www.youtube.com/watch?v=D63e1XUGbi4)\n\n\nFor *anything* that you struggle with (MCP Installation, Application Issues, Usability Issues, Feedback): **PLEASE LET ME KNOW!**\n-\u003e Create a Github Issue or write on Discord (https://discord.gg/KPyrjTSSat) and I will look into it! Maybe a response will take a day, but I will try to get back to each and every one of you.\n\n\nHere's a video guiding you through the whole thing - from installation to output! (15min)\nSorry for the bad audio, a new Video is coming soon!\n\n[![How to install \u0026 Run your first Flow](https://img.youtube.com/vi/YIREFCAAdxg/0.jpg)](https://www.youtube.com/watch?v=YIREFCAAdxg)\n \nFLUJO animated Short #1 - \"A sad song about MCP\"\n[![image](https://github.com/user-attachments/assets/e83cf81d-e5db-451c-9599-77dcdbe4ba2c)](https://www.youtube.com/watch?v=boOS9XHQdZc)\n\n# IMPORTANT SECURITY NOTE\nFLUJO has currently EXTENSIVE logging enabled by default! This **may expose your encrypted API-Keys to the terminal output!**. Be VERY careful when grabbing videos or streaming and showing the terminal output!\n\n![FLUJO Logo](https://github.com/user-attachments/assets/881ad34c-73fa-4b71-ba47-123b5da8e05e)\n\n# FLUJO\n\n[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n[![Version](https://img.shields.io/badge/version-0.1.0-green.svg)](package.json)\n\nFLUJO is an open-source platform that bridges the gap between **workflow orchestration**, **Model-Context-Protocol (MCP)**, and **AI tool integration**. It provides a unified interface for managing AI models, MCP servers, and complex workflows - all locally and open-sourc"])</script><script>self.__next_f.push([1,"e.\n\n![FLUJO Overview](https://github.com/user-attachments/assets/397ef3a5-e4c1-4667-ac74-6fe96f854ff1)\n\nFLUJO is powered by the [PocketFlowFramework](https://the-pocket-world.github.io/Pocket-Flow-Framework/) and built with [CLine](https://github.com/cline/cline) and a lot of LOVE.\n\n## ğŸŒŸ Key Features\n\n### ğŸ”‘ Environment \u0026 API Key Management\n\n- **Secure Storage**: Store environment variables and API keys with encryption\n- **Global Access**: Use your stored keys across the entire application\n- **Centralized Management**: Keep all your credentials in one secure place\n\n![API Keys Management](https://github.com/user-attachments/assets/f5acd60f-129d-4e0c-8bc1-b5410d3c8d1d)\n\n### ğŸ¤– Model Management\n\n- **Multiple Models**: Configure and use different AI models simultaneously\n- **Pre-defined Prompts**: Create custom system instructions for each model\n- **Provider Flexibility**: Connect to various API providers (OpenAI, Anthropic, etc.)\n- **Local Models**: Integrate with Ollama for local model execution\n\n![Model Configuration](https://github.com/user-attachments/assets/06036daa-c576-4483-b13e-47ef21a82395)\n![Model Settings](https://github.com/user-attachments/assets/4e6f8390-eaab-448a-9a38-bbbd64fd3de8)\n![Ollama Integration](https://github.com/user-attachments/assets/8a04632a-4cc2-4738-ac9b-e856170a9e7c)\n\n### ğŸ”Œ MCP Server Integration\n\n- **Easy Installation**: Install MCP servers from GitHub or local filesystem\n- **Server Management**: Comprehensive interface for managing MCP servers\n- **Tool Inspection**: View and manage available tools from MCP servers\n- **Environment Binding**: Connect server environment variables to global storage\n- **Docker Support**: Run Docker-based MCP servers within Flujo\n\n![MCP Server Installation](https://github.com/user-attachments/assets/4c4055fd-c769-4155-b48f-1350b689545f)\n![MCP Server Management](https://github.com/user-attachments/assets/bd10b76f-aeb0-48c2-98e3-313e35ace50f)\n![MCP Server Tools](https://github.com/user-attachments/assets/a29effb6-07d4-42e2-886f-6cf7c96fe4a6)\n![MCP Environment Variables](https://github.com/user-attachments/assets/27b257bf-a6ad-42bf-9ccf-4178c454c7ce)\n\n### ğŸ”„ Workflow Orchestration\n\n- **Visual Flow Builder**: Create and design complex workflows\n- **Model Integration**: Connect different models in your workflow\n- **Tool Management**: Allow or restrict specific tools for each model\n- **Prompt Design**: Configure system prompts at multiple levels (Model, Flow, Node)\n![image](https://github.com/user-attachments/assets/36d417ca-a0e6-4f87-90cb-b17a70641372)\n![Flow Design](https://github.com/user-attachments/assets/30fc4c8f-78fe-4a44-9fe7-d7837d7359d2)\n![Flow Configuration](https://github.com/user-attachments/assets/6b84025f-5240-4277-87e9-02e0f5aac867)\n![System Prompts](https://github.com/user-attachments/assets/b1725c4d-2b0f-420d-92cc-3eba13a5a7de)\n![Tool References](https://github.com/user-attachments/assets/8bc8ee61-2f21-42ef-b1df-9c88a4ad13a6)\n![Screenshot 2025-03-08 223218](https://github.com/user-attachments/assets/922b9368-c0b6-4a06-b500-c8d71506173a)\n\n### ğŸ’¬ Chat Interface\n\n- **Flow Interaction**: Interact with your flows through a chat interface\n- **Message Management**: Edit or disable messages or split conversations to reduce context size \n- **File Attachments**: Attach documents or audio for LLM processing (really bad atm, because for this you should use mcp!)\n- **Transcription**: Process audio inputs with automatic transcription (really bad atm, see roadmap)\n  \n![Screenshot 2025-04-05 210835](https://github.com/user-attachments/assets/c9738f5b-01c7-4b18-b816-2323ebc2a94a)\n\n### ğŸ”„ External Tool Integration\n\n- **OpenAI Compatible Endpoint**: Integrate with tools like CLine or Roo\n- **Seamless Connection**: Use FLUJO as a backend for other AI applications\n\n![Screenshot 2025-03-27 130144](https://github.com/user-attachments/assets/7ba68655-2a38-48b1-8d52-c0e2c217e506)\n![Screenshot 2025-03-26 213657](https://github.com/user-attachments/assets/43add66a-ba69-4651-9722-f920c4ef746b)\n\n## ğŸš€ Getting Started\n\n### Manual installation:\n### Prerequisites\n\n-"])</script><script>self.__next_f.push([1," Node.js (v18 or higher)\n- npm or yarn\n\n### Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/mario-andreschak/FLUJO.git\n   cd FLUJO\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   # or\n   yarn install\n   ```\n\n3. Start the development server:\n   ```bash\n   npm run dev\n   # or\n   yarn dev\n   ```\n\n4. Open your browser and navigate to:\n   ```\n   http://localhost:4200\n   ```\n   \n5. FLUJO feels and works best if you run it compiled:\n   ```bash\n   npm run build\n   npm start\n   ```\n\n6. To run as a desktop application:\n   ```bash\n   npm run electron-dev    # Development mode\n   # or\n   npm run electron-dist   # Build and package for your platform\n   ```\n\n## ğŸ“– Usage\n\n### Setting up often used API keys\n\n1. Navigate to Settings\n2. Save your API Keys globally to secure them\n\n### Setting Up Models\n\n1. Navigate to the Models page\n2. Click \"Add Model\" to create a new model configuration\n3. Configure your model with name, provider, API key, and system prompt\n4. Save your configuration\n\n### Managing MCP Servers\n\n1. Go to the MCP page\n2. Click \"Add Server\" to install a new MCP server\n3. Choose from GitHub repository or local filesystem\n4. Configure server settings and environment variables\n5. Start and manage your server\n\n### Using SSE MCP-Servers\n1. Got to the MCP Page\n2. Click \"Add Server\" to install a new MCP server\n3. Select \"Local Server\"\n4. Enter a Server Name, enter \"/\" as Server Root Path\n5. Leave Build Command and Install Command empty\n6. Enter \"npx\" as Run Command\n7. Add 1. Argument \"mcp-remote\"\n8. Add 2. Argument \"(your MCP SSE-Url here)\"\n   ![image](https://github.com/user-attachments/assets/f5c97c26-72c6-4ba9-a9d2-a34e3f34ec19)\n\n\n### Using official Reference servers\n\n1. Go to the MCP page\n2. Click \"Add Server\" to install a new MCP server\n3. Go to the \"Reference Servers\" Tab\n4. (First time executing:) Click \"Refresh\" and waaaaaaait.\n5. Click a server of your choice, wait for the screen to change, click \"Save\" / \"Update Server\" at the bottom.\n   \n### Using Docker-based MCP Servers\n\nWhen running FLUJO in Docker, you can use Docker-based MCP servers:\n\n1. Go to the MCP page\n2. Click \"Add Server\" to install a new MCP server\n3. Choose \"Docker\" as the installation method\n4. Provide the Docker image name and any required environment variables\n5. Start and manage your server\n\n### Creating Workflows\n\n1. Visit the Flows page\n2. Click \"Create Flow\" to start a new workflow\n3. Add processing nodes and connect them \n4. Configure each node with models and tools\n5. Save your flow\n\n![Screenshot 2025-04-12 123657](https://github.com/user-attachments/assets/06b40a36-a906-44d5-b53a-9eaa125acb74)\n\n\n### Branching\n\n1. Connect one MCP node to multiple subsequent ones\n![Screenshot 2025-04-07 094237](https://github.com/user-attachments/assets/73be3153-5dea-4729-bf10-40657b2a12c4)\n2. Define the branching in the prompt, using the handoff-tools on the \"Agent Tools\" tab\n![Screenshot 2025-04-07 095433](https://github.com/user-attachments/assets/d3bc188f-8a7a-4fb0-830c-e4d85a9a37bf)\n\n### Loops\n\n1. Same as branching, but connect back to a previous node\n![Screenshot 2025-04-08 165640](https://github.com/user-attachments/assets/3c026812-a895-4c3a-a37d-fe51550b273b)\n\n### Orchestration\n\n1. Same as loops but with multiple ones\n![Screenshot 2025-04-08 180631](https://github.com/user-attachments/assets/0a3abfe9-8e83-49ea-a8da-bede3bed31e3)\n\n\n\n### Using the Chat Interface\n\n1. Go to the Chat page\n2. Select a flow to interact with\n3. Start chatting with your configured workflow\n![Screenshot 2025-04-07 095653](https://github.com/user-attachments/assets/efcb78ba-9a85-401e-a4c7-df5ec7458b26)\n\n\n## ğŸ”„ MCP Integration\n\nFLUJO provides comprehensive support for the Model Context Protocol (MCP), allowing you to:\n\n- Install and manage MCP servers\n- Inspect server tools\n- Connect MCP servers to your workflows\n- Reference tools directly in prompts\n- Bind environment variables to your global encrypted storage\n![image](https://github.com/user-attachments/assets/4c638f0d-a6cb-4f4f-a3c0-cc1e3a369297)\n\n### Docker Installation\n\nThe easie"])</script><script>self.__next_f.push([1,"st way to run FLUJO is using Docker, which provides a consistent environment and supports running Docker-based MCP servers.\n\n#### Prerequisites\n\n- Docker and Docker Compose installed on your system\n\n#### Using Docker Compose\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/mario-andreschak/FLUJO.git\n   cd FLUJO\n   ```\n\n2. Build and start the container:\n   ```bash\n   docker-compose up -d\n   ```\n\n3. Access FLUJO in your browser:\n   ```\n   http://localhost:4200\n   ```\n\n#### Using Docker Scripts\n\nFor more control over the Docker build and run process, you can use the provided scripts:\n\n1. Build the Docker image:\n   ```bash\n   ./scripts/build-docker.sh\n   ```\n\n2. Run the Docker container:\n   ```bash\n   ./scripts/run-docker.sh\n   ```\n\nOptions for run-docker.sh:\n- `--tag=\u003ctag\u003e`: Specify the image tag (default: latest)\n- `--detached`: Run in detached mode\n- `--no-privileged`: Run without privileged mode (not recommended)\n- `--port=\u003cport\u003e`: Specify the host port (default: 4200)\n\nFor more detailed information about Docker support, including Docker-in-Docker capabilities, persistent storage, and troubleshooting, see [DOCKER.md](DOCKER.md).\n\n\n## ğŸ“„ License\n\nFLUJO is licensed under the [MIT License](LICENSE).\n## ğŸš€ Roadmap\nHere's a roadmap of upcoming features and improvements:\n\n- Real-time Voice Feature: Adding support for Whisper.js or OpenWhisper to enable real-time voice capabilities.\n- Visual Debugger: Introducing a visual tool to help debug and troubleshoot more effectively.\n- MCP Roots Support: Implementing Checkpoints and Restore features within MCP Roots for better control and recovery options.\n- MCP Prompts: Enabling users to build custom prompts that fully leverage the capabilities of the MCP server.\n- MCP Proxying STDIO\u003c\u003eSSE: Likely utilizing SuperGateway to proxy standard input/output with Server-Sent Events for enhanced communication: Use MCP Servers managed in FLUJo in any other MCP client.\n- Enhanced Integrations: Improving compatibility and functionality with tools like Windsurf, Cursor, and Cline.\n- Advanced Orchestration: Adding agent-driven orchestration, batch processing, and incorporating features inspired by Pocketflow.\n- Online Template Repository: Creating a platform for sharing models, flows, or complete \"packages,\" making it easy to distribute FLUJO flows to others.\n- Edge Device Optimization: Enhancing performance and usability for edge devices.\n\n## ğŸ¤ Contributing\n\nContributions are welcome! Feel free to open issues or submit pull requests.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## ğŸ“¬ Contact\n\n- GitHub: [mario-andreschak](https://github.com/mario-andreschak)\n- LinkedIn: https://www.linkedin.com/in/mario-andreschak-674033299/\n\n## Notes:\n- You can add ~FLUJO=HTML, ~FLUJO=MARKDOWN, ~FLUJO=JSON, ~FLUJO=TEXT in your message to format the response, this will give varying results in different tools where you integrate FLUJO.\n- You can add ~FLUJOEXPAND=1 or ~FLUJODEBUG=1 somewhere in your message to show more details\n- in config/features.ts you can change the Logging-level for the whole application\n- in config/features.ts you can enable SSE support which is currently disabled by default\n---\n\nFLUJO - Empowering your AI workflows with open-source orchestration.4e:T5af,## What is FLUJO? \nFLUJO is an open-source platform designed for workflow orchestration, integrating Model-Context-Protocol (MCP) and AI tools, providing a unified interface for managing AI models and complex workflows.\n\n## How to use FLUJO? \nTo use FLUJO, download the setup from the releases page or clone the repository, install dependencies, and start the development server. You can also run it as a desktop application using Electron.\n\n## Key features of FLUJO? \n- **Environment \u0026 API Key Management**: Secure storage and centralized management of API keys.\n- **Model Management**: Configure and use multiple AI "])</script><script>self.__next_f.push([1,"models with pre-defined prompts.\n- **MCP Server Integration**: Easy installation and management of MCP servers.\n- **Workflow Orchestration**: Visual flow builder for creating complex workflows.\n- **Chat Interface**: Interact with workflows through a chat interface.\n- **Desktop Application**: Run FLUJO as a native application with system tray support.\n\n## Use cases of FLUJO? \n1. Managing AI models and workflows for data processing.\n2. Integrating various AI tools for enhanced functionality.\n3. Creating automated workflows for machine learning tasks.\n\n## FAQ from FLUJO? \n- **Is FLUJO free to use?**  \n\u003e Yes! FLUJO is open-source and free to use.\n\n- **What programming languages does FLUJO support?**  \n\u003e FLUJO is built with TypeScript and Node.js.\n\n- **Can I contribute to FLUJO?**  \n\u003e Yes! Contributions are welcome through GitHub.4f:Tef6,# TeamSpark AI Workbench\n\n## About\n\nTeamSpark AI Workbench is a powerful development environment for AI and machine learning projects.  It is a local client\napplication providing a graphical interface and a command-line (terminal) interface on Mac, Linux, and Windows.\n\n## Features\n\nTeamSpark AI Workbench supports:\n- Many LLM providers and their models, including:\n  - Anthropic/Claude\n  - OpenAI/ChatGPT\n  - Google/Gemini\n  - AWS Bedrock\n  - Ollama\n- References (memory)\n- Rules (prompt guidance)\n- Usage of tools via MCP (supporing thousands of available tools)\n- Chat sessions where you can select and configure models, control reference and rule usage (context), and use tools.\n\nTeamSpark AI Workbench also includes internal tools that allow models to directly interact with references and tools, meaning\nthe models can build and update their own references and rules (allowing them to \"remember\" and \"learn\").\n\n## CLI Mode\n\nWhen building and running locally, you can launch the CLI with `npm run cli`\n\nWhen running installed builds, see below...\n\n### MacOS\n\nOn **MacOS** installed releases, there is a shell script provided to launch the CLI called `tspark.sh`.  You may run this directly,\nor create a symlink to it for conveninence:\n\n```bash\n/Applications/TeamSpark\\ AI\\ Workbench.app/Contents/Resources/tspark.sh\n```\n\nor create a symlink:\n\n```bash\nln -s /Applications/TeamSpark\\ AI\\ Workbench.app/Contents/Resources/tspark.sh ~/.local/bin/tspark\n```\n\nthen just:\n\n```bash\ntspark\n```\n\n### Linux\n\nOn **Linux** installed releases, TeamSpark AI Workbench is launched via `teamspark-workbench`.  You may run in CLI mode by appending `--cli`.  \n\n```bash\nteamspark-workbench --cli\n```\n\nThere is also a CLI launcher called `tspark.sh`.  You may run this directly, or create a symlink to it for convenience:\n\n```bash\n/opt/TeamSpark\\ AI\\ Workbench.app/tspark.sh\n```\n\nor create a symlink:\n\n```bash\nsudo ln -s /opt/TeamSpark\\ AI\\ Workbench.app/tspark.sh /usr/bin/tspark\n```\n\nthen just:\n\n```bash\ntspark\n```\n\n### CLI Workspace\n\nYou should either run the command line app in a directory containing a workspace, or pass it a workspace location via \nthe `--workspace` argument. To create a new workspace in current (or provided) workspace directory, use the `--create` \nargument. Running the cli without a workspace will provide the above workspace guidance and exit.\n\n## Website\n\nFor more information about TeamSpark AI Workbench, visit our [official website](http://www.teamspark.ai).\n\n## Download\n\nDownload the pre-built installer for your platform:\n\n- [macOS (Intel)](https://storage.googleapis.com/teamspark-workbench/TeamSpark%20AI%20Workbench-latest.dmg)\n- [macOS (Apple Silicon)](https://storage.googleapis.com/teamspark-workbench/TeamSpark%20AI%20Workbench-latest-arm64.dmg)\n- [Linux (Debian/Ubuntu)](https://storage.googleapis.com/teamspark-workbench/teamspark-workbench_latest_amd64.deb)\n- [Linux (AppImage)](https://storage.googleapis.com/teamspark-workbench/TeamSpark%20AI%20Workbench-latest.AppImage)\n\n## License\n\nThis repository is licensed under the [Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License](https://creativecommons.org/licenses/by-nc-nd/4.0/).\n\n### License Terms\n\nThe CC BY-NC-ND 4.0 license allows th"])</script><script>self.__next_f.push([1,"e work to be viewed and inspected, but it is not an open source license in the traditional sense. Specifically:\n\n- You are prohibited from modifying the work in any way (no derivatives)\n- You cannot use it for primarily commercial purposes\n- This license grants the right to see and review the underlying code\n- It does not permit you to adapt, build upon, or redistribute modified versions\n\nThis license may change to a more permissive license in the future if there is interest.\n\nFor commercial use licensing, please contact [support@teamspark.ai](mailto:support@teamspark.ai).50:T558,## what is TeamSpark AI Workbench? \nTeamSpark AI Workbench is a powerful development environment designed for AI and machine learning projects, providing both a graphical interface and a command-line interface for Mac, Linux, and Windows.\n\n## how to use TeamSpark AI Workbench? \nTo use TeamSpark AI Workbench, download the installer for your platform, and launch the application. You can run it in CLI mode by using specific commands based on your operating system.\n\n## key features of TeamSpark AI Workbench? \n- Supports multiple LLM providers and their models (e.g., Anthropic/Claude, OpenAI/ChatGPT, Google/Gemini).\n- Memory references and prompt guidance rules.\n- Integration with thousands of tools via MCP.\n- Chat sessions for model configuration and tool usage.\n- Internal tools for models to interact with references and learn.\n\n## use cases of TeamSpark AI Workbench? \n1. Developing and testing AI models.\n2. Running machine learning experiments.\n3. Creating and managing AI workflows.\n\n## FAQ from TeamSpark AI Workbench? \n- What platforms does TeamSpark AI Workbench support?\n\u003e It supports Mac, Linux, and Windows.\n\n- Is there a command-line interface available?\n\u003e Yes, you can run the application in CLI mode using specific commands.\n\n- Can I modify the code of TeamSpark AI Workbench?\n\u003e No, it is licensed under CC BY-NC-ND, which prohibits modifications.51:T15e9,# Jira Assistant with MCP Integration\n\nA Streamlit-based assistant for managing Jira tickets using MCP (Model Control Panel) for tool calling.\n\n## Features\n\n- ğŸ¤– Clean tabbed interface for different operations\n- ğŸ¯ Create, search, and manage Jira tickets with simple conversational commands\n- ğŸ”„ Real-time ticket creation without relying on external LLMs\n- ğŸ› ï¸ Built on the MCP framework for flexible tool calling\n- ğŸ“Š Direct form-based interface for creating and searching tickets\n\n## Screenshots\n\n### Tabbed Interface\nThe application now features a clean tabbed interface with separate sections for:\n1. Chat - Conversational interface for managing tickets\n2. Create Ticket - Form-based ticket creation\n3. Search Tickets - Advanced search using JQL\n\n![Jira Assistant Demo](jira_server_demo.gif)\n\n## Prerequisites\n\n- Python 3.8+\n- Jira account with API access\n- MCP server running with Jira tools\n\n## Installation\n\n1. Clone the repository\n2. Install the required packages:\n   ```bash\n   pip install -r requirements.txt\n   ```\n3. Set up your environment variables in a `.env` file:\n   ```\n   JIRA_URL=https://your-domain.atlassian.net\n   JIRA_EMAIL=your-email@example.com\n   JIRA_API_TOKEN=your-jira-api-token\n   ```\n\n## Running the Application\n\nUse the start script to launch the application:\n\n```bash\n./start_jira_assistant.sh\n```\n\nThe script will:\n1. Check if the MCP package is installed\n2. Verify required environment variables\n3. Start the MCP server if it's not already running\n4. Launch the Streamlit application\n\n## Usage Examples\n\n### Creating Tickets\n\nYou can create tickets in two ways:\n\n#### Using the Chat Interface\nType natural language commands like:\n- \"Create a new task in KAN titled 'Implement user authentication' with description 'We need to add a JWT-based authentication system for user login.'\"\n- \"I need a bug ticket in KAN for 'Fix pagination in user list' describing 'The pagination controls are not working correctly when there are more than 10 users.'\"\n\n#### Using the Form Interface\n1. Navigate to the \"Create Ticket\" tab\n2. Fill in the required fields (Project Key, Summary, Description)\n3."])</script><script>self.__next_f.push([1," Select the issue type\n4. Click \"Create Ticket\"\n\n### Searching Tickets\n\nYou can search tickets in two ways:\n\n#### Using the Chat Interface\nType natural language queries like:\n- \"Find all open tickets in the KAN project\"\n- \"Show me all high priority bugs\"\n- \"Search for tickets mentioning 'authentication' in the KAN project\"\n\n#### Using the Search Interface\n1. Navigate to the \"Search Tickets\" tab\n2. Enter a JQL query (examples are provided in the interface)\n3. Set the maximum number of results\n4. Click \"Search\"\n\n### Getting Ticket Details\n\nAsk for details about specific tickets:\n- \"Show details for ticket KAN-123\"\n- \"What's the status of KAN-456?\"\n\n## Direct Jira Tool\n\nFor command-line operations, use the direct_jira_tool.py script:\n\n```bash\n# List available tools\n./direct_jira_tool.py list\n\n# Create a ticket\n./direct_jira_tool.py create --project KAN --title \"Fix login page\" --description \"The login page has a UI bug in Safari\"\n\n# Search for tickets\n./direct_jira_tool.py search --query \"project = KAN AND status = 'In Progress'\"\n\n# Get ticket details\n./direct_jira_tool.py get --id KAN-123\n```\n\n## Test MCP Client\n\nYou can test the connection to the MCP server using the test_mcp_client.py script:\n\n```bash\n# Run all tests\npython test_mcp_client.py all\n\n# Test connection only\npython test_mcp_client.py connect\n\n# Test creating a specific ticket\npython test_mcp_client.py test_create --project KAN --title \"Test ticket\" --description \"This is a test\"\n```\n\n## Troubleshooting\n\n### MCP Server Issues\n\nIf the MCP server doesn't connect properly:\n1. Check if the MCP server path is correct\n2. Verify your Jira credentials in the .env file\n3. Use the \"Restart MCP Server\" button in the sidebar\n4. Test the connection using `test_mcp_client.py connect`\n\n### Ticket Creation Issues\n\nIf you encounter issues with ticket creation:\n1. Make sure all required fields are filled in\n2. Check that the project key exists and is correctly formatted\n3. Verify that your Jira API token has sufficient permissions\n4. Look for specific error messages in the response\n\n### Search Issues\n\nIf you encounter search issues with error messages like `Error executing tool search_jira_tickets: validation error`:\n1. Make sure your JQL query is properly formatted\n2. Avoid using complex JQL queries with special characters\n3. Try simple queries first like `project = KAN` to test functionality\n4. The MCP server currently has a limit of 10 results per search\n\n### Other Issues\n\n- Check the browser console and terminal output for detailed error messages\n- Make sure all environment variables are set correctly\n- Ensure you have the correct version of the `mcp` package installed (`pip install -U mcp`)\n\n## New Features in Latest Update\n\n- ğŸ“‹ **Tabbed Interface**: Separate tabs for chat, ticket creation, and search\n- ğŸ–‹ï¸ **Improved Ticket Creation**: Direct form-based creation without relying on LLMs\n- ğŸ” **Advanced Search**: JQL-based search with examples and flexible formatting\n- ğŸ›¡ï¸ **Enhanced Error Handling**: Better error messages and validation\n- ğŸ§© **Simplified Dependencies**: Removed reliance on external APIs like Gemini\n\n## Development\n\nTo contribute to this project:\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgements\n\n- Streamlit for the web app framework\n- MCP for the tool-calling infrastructure52:T5e3,## what is Jira Assistant with MCP Integration? \nJira Assistant with MCP Integration is a Streamlit-powered application designed to help users create, search, and manage Jira tickets using natural language commands or direct forms, leveraging the Model Control Panel (MCP) framework.\n\n## how to use Jira Assistant? \nTo use the Jira Assistant, clone the repository, install the required packages, set up your environment variables, and run the application using the provided start script.\n\n## key features of Jira Assistant? \n- Clean tabbed interface for different operations\n- Create, search, and manage Jira ti"])</script><script>self.__next_f.push([1,"ckets with conversational commands\n- Real-time ticket creation without relying on external LLMs\n- Built on the MCP framework for flexible tool calling\n- Direct form-based interface for ticket management\n\n## use cases of Jira Assistant? \n1. Creating new Jira tickets using natural language commands.\n2. Searching for existing tickets using JQL or conversational queries.\n3. Managing ticket details and statuses through a user-friendly interface.\n\n## FAQ from Jira Assistant? \n- Can I use natural language to create tickets?\n\u003e Yes! You can create tickets using conversational commands.\n\n- What are the prerequisites for using this application?\n\u003e You need Python 3.8+, a Jira account with API access, and an MCP server running with Jira tools.\n\n- Is there a way to troubleshoot issues?\n\u003e Yes, the application includes troubleshooting tips for common issues with the MCP server and ticket management.53:Ta3d,\u003ca href=\"https://mcp.scira.ai\"\u003e\n  \u003ch1 align=\"center\"\u003eScira MCP Chat\u003c/h1\u003e\n\u003c/a\u003e\n\n\u003cp align=\"center\"\u003e\n  An open-source AI chatbot app powered by Model Context Protocol (MCP), built with Next.js and the AI SDK by Vercel.\n\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"#features\"\u003e\u003cstrong\u003eFeatures\u003c/strong\u003e\u003c/a\u003e â€¢\n  \u003ca href=\"#mcp-server-configuration\"\u003e\u003cstrong\u003eMCP Configuration\u003c/strong\u003e\u003c/a\u003e â€¢\n  \u003ca href=\"#license\"\u003e\u003cstrong\u003eLicense\u003c/strong\u003e\u003c/a\u003e\n\u003c/p\u003e\n\u003cbr/\u003e\n\n## Features\n\n- Streaming text responses powered by the [AI SDK by Vercel](https://sdk.vercel.ai/docs), allowing multiple AI providers to be used interchangeably with just a few lines of code.\n- Full integration with [Model Context Protocol (MCP)](https://modelcontextprotocol.io) servers to expand available tools and capabilities.\n- Multiple MCP transport types (SSE and stdio) for connecting to various tool providers.\n- Built-in tool integration for extending AI capabilities.\n- Reasoning model support.\n- [shadcn/ui](https://ui.shadcn.com/) components for a modern, responsive UI powered by [Tailwind CSS](https://tailwindcss.com).\n- Built with the latest [Next.js](https://nextjs.org) App Router.\n\n## MCP Server Configuration\n\nThis application supports connecting to Model Context Protocol (MCP) servers to access their tools. You can add and manage MCP servers through the settings icon in the chat interface.\n\n### Adding an MCP Server\n\n1. Click the settings icon (âš™ï¸) next to the model selector in the chat interface.\n2. Enter a name for your MCP server.\n3. Select the transport type:\n   - **SSE (Server-Sent Events)**: For HTTP-based remote servers\n   - **stdio (Standard I/O)**: For local servers running on the same machine\n\n#### SSE Configuration\n\nIf you select SSE transport:\n1. Enter the server URL (e.g., `https://mcp.example.com/token/sse`)\n2. Click \"Add Server\"\n\n#### stdio Configuration\n\nIf you select stdio transport:\n1. Enter the command to execute (e.g., `npx`)\n2. Enter the command arguments (e.g., `-y @modelcontextprotocol/server-google-maps`)\n   - You can enter space-separated arguments or paste a JSON array\n3. Click \"Add Server\"\n\n4. Click \"Use\" to activate the server for the current chat session.\n\n### Available MCP Servers\n\nYou can use any MCP-compatible server with this application. Here are some examples:\n\n- [Composio](https://composio.dev/mcp) - Provides search, code interpreter, and other tools\n- [Zapier MCP](https://zapier.com/mcp) - Provides access to Zapier tools\n- Any MCP server using stdio transport with npx and python3\n\n## License\n\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.54:T537,## what is Scira MCP Chat? \nScira MCP Chat is an open-source AI chatbot application powered by the Model Context Protocol (MCP), designed to facilitate seamless communication with various AI providers.\n\n## how to use Scira MCP Chat? \nTo use Scira MCP Chat, simply connect to an MCP server through the settings in the chat interface, select your desired transport type, and start chatting with the AI.\n\n## key features of Scira MCP Chat? \n- Streaming text responses from multiple AI providers using the AI SDK by Vercel.\n- Full integration with MCP servers for enh"])</script><script>self.__next_f.push([1,"anced capabilities.\n- Support for multiple transport types (SSE and stdio).\n- Built-in tool integration for extending AI functionalities.\n- Modern UI components powered by Tailwind CSS.\n\n## use cases of Scira MCP Chat? \n1. Engaging in conversations with AI for customer support.\n2. Utilizing AI tools for coding assistance and debugging.\n3. Accessing various AI functionalities through different MCP servers.\n\n## FAQ from Scira MCP Chat? \n- Can I connect to any MCP server?\n\u003e Yes! You can connect to any MCP-compatible server by configuring it in the settings.\n\n- What transport types are supported?\n\u003e The application supports SSE for remote servers and stdio for local servers.\n\n- Is Scira MCP Chat free to use?\n\u003e Yes! Scira MCP Chat is open-source and free for everyone.55:Td31,# LangChainGo MCP Adapter\n\nA Go adapter that bridges LangChain Go tools with Model Context Protocol (MCP) servers.\n\n## Overview\n\nThis adapter allows you to use tools defined on an MCP server with the LangChain Go library. It implements the necessary interfaces to integrate MCP tools seamlessly with LangChain Go's agent infrastructure.\n\n## Features\n\n- Connect to any MCP server\n- Automatically discover MCP tools from a specified MCP server and make them available to LangChain Go\n- Wrap MCP tools as LangChain Go tools\n\n## Installation\n\n```bash\ngo get github.com/i2y/langchaingo-mcp-adapter\n```\n\n## Usage\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"log\"\n    \"os\"\n\n    \"github.com/i2y/langchaingo-mcp-adapter\"\n    \"github.com/mark3labs/mcp-go/client\"\n    \"github.com/tmc/langchaingo/agents\"\n    \"github.com/tmc/langchaingo/chains\"\n    \"github.com/tmc/langchaingo/llms/googleai\"\n    \"github.com/tmc/langchaingo/tools\"\n)\n\nfunc main() {\n    // Create an MCP client using stdio\n    mcpClient, err := client.NewStdioMCPClient(\n        \"./an-mcp-server\",  // Path to an MCP server\n        nil,                // Additional environment variables if needed\n    )\n    if err != nil {\n        log.Fatalf(\"Failed to create MCP client: %v\", err)\n    }\n    defer mcpClient.Close()\n\n    // Create the adapter\n    adapter, err := langchaingo_mcp_adapter.New(mcpClient)\n    if err != nil {\n        log.Fatalf(\"Failed to create adapter: %v\", err)\n    }\n\n    // Get all tools from MCP server\n    mcpTools, err := adapter.Tools()\n    if err != nil {\n        log.Fatalf(\"Failed to get tools: %v\", err)\n    }\n\n    ctx := context.Backgorund()\n\n    // Create a Google AI LLM client\n    llm, err := googleai.New(\n        ctx,\n        googleai.WithDefaultModel(\"gemini-2.0-flash\"),\n        googleai.WithAPIKey(os.Getenv(\"GOOGLE_API_KEY\")),\n    )\n    if err != nil {\n        log.Fatalf(\"Create Google AI client: %v\", err)\n    }\n\n    // Create a agent with the tools\n    agent := agents.NewOneShotAgent(\n        llm,\n        mcpTools,\n        agents.WithMaxIterations(3),\n    )\n    executor := agents.NewExecutor(agent)\n\n    // Use the agent\n    question := \"Can you help me analyze this data using the available tools?\"\n    result, err := chains.Run(\n        ctx,\n        executor,\n        question,\n    )\n    if err != nil {\n        log.Fatalf(\"Agent execution error: %v\", err)\n    }\n\n    log.Printf(\"Agent result: %s\", result)\n}\n```\n\n## Example Applications\n\nSee the `example` directory for a complete example:\n\n- `example/agent`: Demonstrates how to use the adapter with an LLM agent\n- `example/server`: A minimal MCP server example\n\nThe mcp-curl server in this sample is based on the code from [this blog](https://k33g.hashnode.dev/creating-an-mcp-server-in-go-and-serving-it-with-docker).\n\n## Requirements\n\n- Go 1.23 or higher\n- [tmc/langchaingo](https://github.com/tmc/langchaingo)\n- [mark3labs/mcp-go](https://github.com/mark3labs/mcp-go)\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git"])</script><script>self.__next_f.push([1," push origin feature/amazing-feature`)\n5. Open a Pull Request56:T4d0,## What is LangChainGo MCP Adapter? \nLangChainGo MCP Adapter is a Go adapter that bridges LangChain Go tools with Model Context Protocol (MCP) servers, allowing seamless integration of MCP tools into the LangChain Go library.\n\n## How to use LangChainGo MCP Adapter? \nTo use the adapter, install it via `go get github.com/i2y/langchaingo-mcp-adapter`, create an MCP client, and then create the adapter to access MCP tools.\n\n## Key features of LangChainGo MCP Adapter? \n- Connects to any MCP server.\n- Automatically discovers MCP tools from a specified MCP server.\n- Wraps MCP tools as LangChain Go tools for easy integration.\n\n## Use cases of LangChainGo MCP Adapter? \n1. Integrating various tools from an MCP server into a Go application.\n2. Building agents that utilize multiple tools for complex tasks.\n3. Enhancing data analysis capabilities using available MCP tools.\n\n## FAQ from LangChainGo MCP Adapter? \n- What programming language is used for this adapter?\n\u003e The adapter is built using the Go programming language.\n\n- Is there a license for this project?\n\u003e Yes, it is licensed under the MIT License.\n\n- How can I contribute to this project?\n\u003e Contributions are welcome! You can fork the repository and submit a Pull Request.57:T2696,# MCP Client Chatbot\n\n[![MCP Supported](https://img.shields.io/badge/MCP-Supported-00c853)](https://modelcontextprotocol.io/introduction)\n[![Discord](https://img.shields.io/discord/1374047276074537103?label=Discord\u0026logo=discord\u0026color=5865F2)](https://discord.gg/gCRu69Upnp)\n\n[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/cgoinglove/mcp-client-chatbot\u0026env=BETTER_AUTH_SECRET\u0026env=OPENAI_API_KEY\u0026env=GOOGLE_GENERATIVE_AI_API_KEY\u0026env=ANTHROPIC_API_KEY\u0026envDescription=Learn+more+about+how+to+get+the+API+Keys+for+the+application\u0026envLink=https://github.com/cgoinglove/mcp-client-chatbot/blob/main/.env.example\u0026demo-title=MCP+Client+Chatbot\u0026demo-description=An+Open-Source+MCP+Chatbot+Template+Built+With+Next.js+and+the+AI+SDK+by+Vercel.\u0026products=[{\"type\":\"integration\",\"protocol\":\"storage\",\"productSlug\":\"neon\",\"integrationSlug\":\"neon\"}])\n\nOur goal is to create the best possible chatbot UX â€” focusing on the joy and intuitiveness users feel when calling and interacting with AI tools.\n\nSee the experience in action in the [preview](#preview) below!\n\n\u003e Built with [Vercel AI SDK](https://sdk.vercel.ai) and [Next.js](https://nextjs.org/), this app adopts modern patterns for building AI chat interfaces. It leverages the power of the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) to seamlessly integrate external tools into your chat experience.\n\n## Table of Contents\n\n- [MCP Client Chatbot](#mcp-client-chatbot)\n  - [Table of Contents](#table-of-contents)\n  - [Preview](#preview)\n    - [ğŸ§© Browser Automation with Playwright MCP](#-browser-automation-with-playwright-mcp)\n    - [ğŸ™ï¸ Realtime Voice Assistant + MCP Tools](#ï¸-realtime-voice-assistant--mcp-tools)\n    - [âš¡ï¸ Quick Tool Mentions (`@`) \\\u0026 Presets](#ï¸-quick-tool-mentions---presets)\n    - [ğŸ§­ Tool Choice Mode](#-tool-choice-mode)\n    - [ğŸ”Œ Easy MCP Server Integration \\\u0026 ğŸ› ï¸ Tool Testing](#-easy-mcp-server-integration--ï¸-tool-testing)\n  - [Getting Started](#getting-started)\n    - [Quick Start (Local Version) ğŸš€](#quick-start-local-version-)\n    - [Quick Start (Docker Compose Version) ğŸ³](#quick-start-docker-compose-version-)\n    - [Environment Variables](#environment-variables)\n  - [ğŸ“˜ Guides](#-guides)\n    - [ğŸ”Œ MCP Server Setup \u0026 Tool Testing](./docs/tips-guides/mcp-server-setup.md)\n    - [ğŸ³ Docker Hosting Guide](#-docker-hosting-guide)\n    - [â–² Vercel Hosting Guide](#-vercel-hosting-guide)\n    - [ğŸ” OAuth Sign-In Setup](#-oauth-sign-in-setup)\n  - [ğŸ’¡ Tips](#-tips)\n    - [ğŸ§  Agentic Chatbot with Project Instructions](#-agentic-chatbot-with-project-instructions)\n    - [ğŸ’¬ Temporary Chat Windows](#-temporary-chat-windows)\n  - [ğŸ—ºï¸ Roadmap](#ï¸-roadmap)\n  - [ğŸ™Œ "])</script><script>self.__next_f.push([1,"Contributing](#-contributing)\n  - [ğŸ’¬ Join Our Discord](#-join-our-discord)\n\n---\n\n## Preview\n\nGet a feel for the UX â€” here's a quick look at what's possible.\n\n### ğŸ§© Browser Automation with Playwright MCP\n\n![playwright-preview](https://github.com/user-attachments/assets/53ec0069-aab4-47ff-b7c4-a8080a6a98ff)\n\n**Example:** Control a web browser using Microsoft's [playwright-mcp](https://github.com/microsoft/playwright-mcp) tool.\n\n- The LLM autonomously decides how to use tools from the MCP server, calling them multiple times to complete a multi-step task and return a final message.\n\nSample prompt:\n\n```prompt\nPlease go to GitHub and visit the cgoinglove/mcp-client-chatbot project.\nThen, click on the README.md file.\nAfter that, close the browser.\nFinally, tell me how to install the package.\n```\n\n\u003cbr/\u003e\n\n### ğŸ™ï¸ Realtime Voice Assistant + MCP Tools\n\n\n\u003cp align=\"center\"\u003e\n  \u003cvideo src=\"https://github.com/user-attachments/assets/e2657b8c-ce0b-40dd-80b6-755324024973\" width=\"100%\" /\u003e\n\u003c/p\u003e\n\n\n\n\nThis demo showcases a **realtime voice-based chatbot assistant** built with OpenAI's new Realtime API â€” now extended with full **MCP tool integration**.\nTalk to the assistant naturally, and watch it execute tools in real time.\n\n### âš¡ï¸ Quick Tool Mentions (`@`) \u0026 Presets\n\n![tool-mention](https://github.com/user-attachments/assets/bd47b175-320f-4c38-bc2f-be887c46178e)\n\nQuickly call any registered MCP tool during chat by typing `@toolname`.\nNo need to memorize â€” just type `@` and select from the list!\n\nYou can also create **tool presets** by selecting only the MCP servers or tools you want.\nSwitch between presets instantly with a click â€” perfect for organizing tools by task or workflow.\n\n### ğŸ§­ Tool Choice Mode\n\n\u003cimg width=\"1161\" alt=\"tool-mode\" src=\"https://github.com/user-attachments/assets/0988f8dd-8a37-4adf-84da-79c083917af9\" /\u003e\n\n\nControl how tools are used in each chat with **Tool Choice Mode** â€” switch anytime with `âŒ˜P`.\n\n- **Auto:** The model automatically calls tools when needed.\n- **Manual:** The model will ask for your permission before calling a tool.\n- **None:** Tool usage is disabled completely.\n\nThis lets you flexibly choose between autonomous, guided, or tool-free interaction depending on the situation.\n\n\u003cbr/\u003e\n\nâ€¦and there's even more waiting for you.\nTry it out and see what else it can do!\n\n\u003cbr/\u003e\n\n## Getting Started\n\n\u003e This project uses [pnpm](https://pnpm.io/) as the recommended package manager.\n\n```bash\n# If you don't have pnpm:\nnpm install -g pnpm\n```\n\n### Quick Start (Docker Compose Version) ğŸ³\n\n```bash\n# 1. Install dependencies\npnpm i\n\n# 2. Enter only the LLM PROVIDER API key(s) you want to use in the .env file at the project root.\n# Example: The app works with just OPENAI_API_KEY filled in.\n# (The .env file is automatically created when you run pnpm i.)\n\n# 3. Build and start all services (including PostgreSQL) with Docker Compose\npnpm docker-compose:up\n\n```\n\n### Quick Start (Local Version) ğŸš€\n\n```bash\n# 1. Install dependencies\npnpm i\n\n# 2. Create the environment variable file and fill in your .env values\npnpm initial:env # This runs automatically in postinstall, so you can usually skip it.\n\n# 3. (Optional) If you already have PostgreSQL running and .env is configured, skip this step\npnpm docker:pg\n\n# 4. Run database migrations\npnpm db:migrate\n\n# 5. Start the development server\npnpm dev\n\n# 6. (Optional) Build \u0026 start for local production-like testing\npnpm build:local \u0026\u0026 pnpm start\n# Use build:local for local start to ensure correct cookie settings\n```\n\nOpen [http://localhost:3000](http://localhost:3000) in your browser to get started.\n\n\u003cbr/\u003e\n\n### Environment Variables\n\nThe `pnpm i` command generates a `.env` file. Add your API keys there.\n\n```dotenv\n# === LLM Provider API Keys ===\n# You only need to enter the keys for the providers you plan to use\nGOOGLE_GENERATIVE_AI_API_KEY=****\nOPENAI_API_KEY=****\nXAI_API_KEY=****\nANTHROPIC_API_KEY=****\nOPENROUTER_API_KEY=****\nOLLAMA_BASE_URL=http://localhost:11434/api\n\n\n# Secret for Better Auth (generate with: npx @better-auth/cli@latest secret)\nBETTER_AUTH_S"])</script><script>self.__next_f.push([1,"ECRET=****\n\n# (Optional)\n# URL for Better Auth (the URL you access the app from)\nBETTER_AUTH_URL=\n\n# === Database ===\n# If you don't have PostgreSQL running locally, start it with: pnpm docker:pg\nPOSTGRES_URL=postgres://your_username:your_password@localhost:5432/your_database_name\n\n# Whether to use file-based MCP config (default: false)\nFILE_BASED_MCP_CONFIG=false\n\n# (Optional)\n# === OAuth Settings ===\n# Fill in these values only if you want to enable Google/GitHub login\nGOOGLE_CLIENT_ID=\nGOOGLE_CLIENT_SECRET=\nGITHUB_CLIENT_ID=\nGITHUB_CLIENT_SECRET=\n```\n\n\u003cbr/\u003e\n\n## ğŸ“˜ Guides\n\nStep-by-step setup guides for running and configuring MCP Client Chatbot.\n\n#### [ğŸ”Œ MCP Server Setup \u0026 Tool Testing](./docs/tips-guides/mcp-server-setup-and-tool-testing.md)\n\n- How to add and configure MCP servers in your environment\n\n#### [ğŸ³ Docker Hosting Guide](./docs/tips-guides/docker.md)\n\n- How to self-host the chatbot using Docker, including environment configuration.\n\n#### [â–² Vercel Hosting Guide](./docs/tips-guides/vercel.md)\n\n- Deploy the chatbot to Vercel with simple setup steps for production use.\n\n#### [ğŸ” OAuth Sign-In Setup](./docs/tips-guides/oauth.md)\n\n- Configure Google and GitHub OAuth for secure user login support.\n\n\u003cbr/\u003e\n\n## ğŸ’¡ Tips\n\nAdvanced use cases and extra capabilities that enhance your chatbot experience.\n\n#### [ğŸ§  Agentic Chatbot with Project Instructions](./docs/tips-guides/project_with_mcp.md)\n\n- Use MCP servers and structured project instructions to build a custom assistant that helps with specific tasks.\n\n#### [ğŸ’¬ Temporary Chat Windows](./docs/tips-guides/temporary_chat.md)\n\n- Open lightweight popup chats for quick side questions or testing â€” separate from your main thread.\n\n## ğŸ—ºï¸ Roadmap\n\nPlanned features coming soon to MCP Client Chatbot:\n\n- [ ] **MCP-integrated LLM Workflow**\n- [ ] **File Attach \u0026 Image Generation**\n- [ ] **Collaborative Document Editing** (like OpenAI Canvas: user \u0026 assistant co-editing)\n- [ ] **RAG (Retrieval-Augmented Generation)**\n- [ ] **Web-based Compute** (with [WebContainers](https://webcontainers.io) integration)\n\nğŸ’¡ If you have suggestions or need specific features, please create an [issue](https://github.com/cgoinglove/mcp-client-chatbot/issues)!\n\n## ğŸ™Œ Contributing\n\nWe welcome all contributions! Bug reports, feature ideas, code improvements â€” everything helps us build the best local AI assistant.\n\n**For detailed contribution guidelines**, please see our [Contributing Guide](./CONTRIBUTING.md).\n\n**Language Translations:** Help us make the chatbot accessible to more users by adding new language translations. See [language.md](./messages/language.md) for instructions on how to contribute translations.\n\nLet's build it together ğŸš€\n\n## ğŸ’¬ Join Our Discord\n\n[![Discord](https://img.shields.io/discord/1374047276074537103?label=Discord\u0026logo=discord\u0026color=5865F2)](https://discord.gg/gCRu69Upnp)\n\nConnect with the community, ask questions, and get support on our official Discord server!58:T4f8,## What is MCP Client Chatbot? \nMCP Client Chatbot is a versatile chat interface that enables users to leverage multiple AI providers such as OpenAI, Anthropic, Google, and Ollama through the Model Context Protocol (MCP).\n\n## How to use MCP Client Chatbot? \nTo use the MCP Client Chatbot, clone the repository, install dependencies using pnpm, initialize the project, and start the development server. You can then access the application at http://localhost:3000.\n\n## Key features of MCP Client Chatbot? \n- Multi-provider AI integration for diverse functionalities.\n- Easy setup and configuration through a user-friendly interface.\n- Customizable server logic for advanced users.\n\n## Use cases of MCP Client Chatbot? \n1. Automating tasks across different AI platforms.\n2. Experimenting with various AI tools without complex setups.\n3. Integrating AI capabilities into personal projects or applications.\n\n## FAQ from MCP Client Chatbot? \n- Is MCP Client Chatbot free to use?  \n\u003e Yes! The MCP Client Chatbot is open-source and free to use.\n\n- What programming language is used?  \n\u003e The project "])</script><script>self.__next_f.push([1,"is developed using TypeScript and Next.js.\n\n- Can I add my own AI providers?  \n\u003e Yes! You can easily add and configure additional AI providers through the MCP management interface.59:Tc9c,# mcp-chatbot\n\nA modular, async research assistant that combines **Anthropic Claude 3** with the **Model Context Protocol (MCP)**, delivering onâ€demand literature search and summarisation for academics and engineers.\n\n---\n\n\n## 1. Project Structure\n\n```bash\nmcp-chatbot/\nâ”œâ”€â”€ Dockerfile\nâ”œâ”€â”€ pyproject.toml\nâ”œâ”€â”€ uv.lock\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ server_config.json\nâ”œâ”€â”€ research_server.py\nâ”œâ”€â”€ papers/                  # Cached paper metadata by topic\nâ”œâ”€â”€ mcp_chatbot/\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ cli.py               # Typer-based CLI\nâ”‚   â””â”€â”€ core.py              # Main chatbot engine\nâ””â”€â”€ tests/\n    â””â”€â”€ test_core.py\n```\n\n\n## 2. QuickÂ Start\n\n### 2.1. Clone the Repository\n\n```bash\ngit clone https://github.com/mctrinh/mcp-chatbot.git\ncd mcp-chatbot\n```\n\n### 2.2. Install Dependencies\n\n#### Install `uv` (recommended)\n```bash\n# Git Bash or WSL on Windows, doesn't work in standard Command Prompt or PowerShell\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Scoop (Windows)\nscoop install uv\n\n# Chocolatey (Windows - Administrator Command Prompt - Recommended)\nchoco install uv\nuv --version\n```\n\n#### Install Python packages in `project.dependencies` in `pyproject.toml`\n```bash\npip install -e .\n```\n\n## 3. Build and Run with Docker\n```bash\n# Build image\ndocker build -t mcp-chatbot:0.1 .\n\n# Run server and CLI (ports 8001 and 8000)\ndocker run --rm -it -p 8001:8001 -p 8000:8000 mcp-chatbot:0.1\n```\n\n## 4. Run Without Docker (Local Dev)\n```bash\n# Install dependencies\nuv pip install -e .[dev]\n\n# Start the research server (MCP tool)\npython research_server.py\n\n# In a new terminal, launch the chatbot CLI\nmcp-chatbot run\n```\n\n\n## 5. Try the Chatbot\n\n### 5.1. REPL Mode\n```bash\npython -m mcp_chatbot.cli run\n```\nOr using the installed script:\n```bash\nmcp-chatbot run\n```\nOnce inside the REPL (Read-Eval-Print Loop), you can interact with the chatbot directly by typing commands or queries. Example commands:\n```bash\n/prompts            # list Claude prompts\n@folders            # list downloaded paper topics\nAI alignment        # ask anything â€“ Claude decide whether to invoke tools\n```\n\n### 5.2. One-shot Query\n```bash\nmcp-chatbot once \"What are the latest trends in diffusion models?\"\n```\n\n\n## 6. Configuration (Optional)\nEnvironment variables and `server_config.json` control model and ports:\n```bash\nexport ANTHROPIC_MODEL=\"claude-3-opus-20240229\"\nexport RESEARCH_PORT=8001\nexport PAPER_DIR=./papers\n```\n\n\n## 7. Testing\n\n```bash\n# Installs pytest, coverage, etc.\nuv pip install -e .[dev]\n\n# Run unit tests\npytest -q\n\n# With coverage (optional)\npytest --cov=mcp_chatbot\n```\n\n\n## 8. Road map\n- Research MCP server with `search_papers` and `extract_info` (done)\n\n- Tool usage via Claude 3 (done)\n\n- Prompt orchestration (done)\n\n- Vector search over stored papers (Faiss / Chroma)\n\n- Web UI using FastAPI + React\n\n- GitHub Actions for CI/CD\n\n\n## 9. License\nMIT License. Copyright Â© 2025.\n\n\n## 10. Current Issues\n\nIssues occur when running ```mcp-chatbot run```\n\n- \u003cspan style=\"color:red;\"\u003eâš  Could not connect to server 'fetch': Method not found\u003c/span\u003e\n- \u003cspan style=\"color:red;\"\u003eâš  Could not connect to server 'filesystem': Method not found\u003c/span\u003e5a:T563,## What is MCP Chatbot? \nMCP Chatbot is a modular, async research assistant that combines Anthropic Claude 3 with the Model Context Protocol (MCP), providing on-demand literature search and summarization for academics and engineers.\n\n## How to use MCP Chatbot? \nTo use MCP Chatbot, clone the repository from GitHub, install the necessary dependencies, and run the server. You can interact with the chatbot through a command-line interface (CLI) or in REPL mode.\n\n## Key features of MCP Chatbot? \n- On-demand literature search and summarization\n- Integration with Anthropic Claude 3 for advanced AI capabilities\n- Modular architecture for easy customization\n- CLI and REPL "])</script><script>self.__next_f.push([1,"modes for user interaction\n\n## Use cases of MCP Chatbot? \n1. Assisting researchers in finding relevant literature quickly.\n2. Summarizing academic papers for easier understanding.\n3. Providing insights and answers to specific research queries.\n\n## FAQ from MCP Chatbot? \n- Can MCP Chatbot handle all types of literature?  \n\u003e Yes! MCP Chatbot is designed to assist with a wide range of academic and engineering literature.\n\n- Is MCP Chatbot free to use?  \n\u003e Yes! MCP Chatbot is open-source and free for everyone to use.\n\n- How accurate are the summaries provided by MCP Chatbot?  \n\u003e The accuracy of the summaries depends on the quality of the input literature and the capabilities of the underlying AI model.5b:T119c,# MCP Agents Cloud\n\nMCP Agents Cloudæ˜¯ä¸€ä¸ªæä¾›ç®¡ç†MCPæœåŠ¡å™¨å’Œä»£ç†ï¼ˆAgentï¼‰çš„å¹³å°ã€‚\n\n## åŠŸèƒ½ç‰¹æ€§\n\n- ç”¨æˆ·ç®¡ç†ï¼ˆæ³¨å†Œã€ç™»å½•ã€å¯†ç é‡ç½®ï¼‰\n- MCPæœåŠ¡å™¨ç®¡ç†ï¼ˆæ·»åŠ ã€ç¼–è¾‘ã€åˆ é™¤ã€æŸ¥çœ‹ï¼‰\n- Agentç®¡ç†ï¼ˆåˆ›å»ºã€ç¼–è¾‘ã€åˆ é™¤ã€æŸ¥çœ‹ï¼‰\n- Agent SDKï¼ˆPythonåŒ…å’ŒHTTP APIï¼‰\n- AgentèŠå¤©äº¤äº’ï¼ˆæµå¼è¾“å‡ºï¼‰\n- SDKå¯†é’¥ç®¡ç†\n\n## æŠ€æœ¯æ ˆ\n\n### å‰ç«¯\n- Vue.js\n- Element UI\n- Axios\n- Vue Router\n- Vuex\n\n### åç«¯\n- Python\n- FastAPI\n- SQLAlchemy\n- JWT\n- openai-agentæ¡†æ¶\n\n### æ•°æ®åº“\n- MySQL 8.0\n\n## å¿«é€Ÿå¼€å§‹\n\n### å®‰è£…ä¾èµ–ç»„ä»¶\n\né¡¹ç›®ä¾èµ–MySQLæ•°æ®åº“ï¼Œå¯ä»¥é€šè¿‡Dockerå¿«é€Ÿå®‰è£…ï¼š\n\n```bash\n# è¿›å…¥dockerç›®å½•\ncd docker\n\n# ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨\nsudo mkdir -p /appdata/share/agents-mcp-cloud/mysql/data\nsudo chown -R $USER:$USER /appdata/share/agents-mcp-cloud/mysql/data\n\n# å¯åŠ¨MySQLæœåŠ¡\ndocker-compose up -d mysql\n```\n\næ•°æ®åº“å°†åœ¨63307ç«¯å£å¯åŠ¨ã€‚è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ[Dockerä¾èµ–ç»„ä»¶æ–‡æ¡£](docker/README.md)ã€‚\n\n### åç«¯è®¾ç½®\n\n1. è¿›å…¥åç«¯ç›®å½•ï¼š\n```bash\ncd backend\n```\n\n2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š\n```bash\npython -m venv venv\n```\n\n3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š\n```bash\n# Windows\nvenv\\Scripts\\activate\n# Linux/Mac\nsource venv/bin/activate\n```\n\n4. å®‰è£…ä¾èµ–ï¼š\n```bash\npip install -r requirements.txt\n```\n\n5. é…ç½®ç³»ç»Ÿï¼š\n```bash\n# æ ¹æ®ç¯å¢ƒé€‰æ‹©å¤åˆ¶å¯¹åº”çš„é…ç½®æ–‡ä»¶\ncp config.yml.example config-dev.yml\n# ç„¶åç¼–è¾‘é…ç½®æ–‡ä»¶\n```\n\n6. è¿è¡Œåº”ç”¨ï¼š\n```bash\n# è®¾ç½®ç¯å¢ƒï¼ˆé»˜è®¤ä¸ºdevï¼‰\nexport ENV=dev  # æˆ– test, prod\n\n# æˆ–ç›´æ¥æŒ‡å®šé…ç½®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„\nexport CONFIG_FILE=\"$(pwd)/config-dev.yml\"\n\n# è¿è¡ŒæœåŠ¡\ncd backend  # ç¡®ä¿åœ¨backendç›®å½•ä¸‹è¿è¡Œ\nuvicorn main:app --reload\n```\n\n### å‰ç«¯è®¾ç½®\n\n1. è¿›å…¥å‰ç«¯ç›®å½•ï¼š\n```bash\ncd frontend\n```\n\n2. å®‰è£…ä¾èµ–ï¼š\n```bash\nnpm install\n```\n\n3. è¿è¡Œå¼€å‘æœåŠ¡å™¨ï¼š\n```bash\nnpm run serve\n```\n\n4. æ„å»ºç”Ÿäº§ç‰ˆæœ¬ï¼š\n```bash\nnpm run build\n```\n\n## é…ç½®è¯´æ˜\n\né¡¹ç›®ä½¿ç”¨åŸºäºç¯å¢ƒçš„YAMLé…ç½®æ–‡ä»¶ï¼š\n\n- `config-dev.yml`ï¼šå¼€å‘ç¯å¢ƒé…ç½®\n- `config-test.yml`ï¼šæµ‹è¯•ç¯å¢ƒé…ç½®\n- `config-prod.yml`ï¼šç”Ÿäº§ç¯å¢ƒé…ç½®\n\né…ç½®æ–‡ä»¶åº”æ”¾åœ¨backendç›®å½•ä¸‹ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ç§æ–¹å¼æŒ‡å®šé…ç½®ï¼š\n\n```bash\n# 1. é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šç¯å¢ƒï¼Œç³»ç»Ÿå°†æŸ¥æ‰¾backend/config-{ENV}.yml\nexport ENV=dev  # æˆ– test, prod\n\n# 2. ç›´æ¥æŒ‡å®šé…ç½®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼ˆæ¨èï¼‰\nexport CONFIG_FILE=\"/å®Œæ•´è·¯å¾„/åˆ°é…ç½®æ–‡ä»¶/config-dev.yml\"\n```\n\nä¸»è¦é…ç½®é¡¹åŒ…æ‹¬ï¼š\n\n- `app`: åº”ç”¨åç§°ã€ç‰ˆæœ¬ç­‰åŸºæœ¬ä¿¡æ¯\n- `api`: APIè·¯å¾„å‰ç¼€å’Œæ–‡æ¡£URL\n- `server`: æœåŠ¡å™¨ä¸»æœºã€ç«¯å£è®¾ç½®\n- `security`: å®‰å…¨è®¾ç½®ï¼ˆå¯†é’¥ã€ä»¤ç‰Œè¿‡æœŸæ—¶é—´ï¼‰\n- `cors`: è·¨åŸŸè®¾ç½®\n- `database`: æ•°æ®åº“è¿æ¥URLå’Œè¿æ¥æ± è®¾ç½®\n- `openai`: OpenAI APIå¯†é’¥å’Œæ¨¡å‹è®¾ç½®\n- `email`: ç”µå­é‚®ä»¶å‘é€è®¾ç½®\n- `smtp`: SMTPæœåŠ¡å™¨é…ç½®\n\nè¯¦ç»†é…ç½®ç¤ºä¾‹è¯·å‚è€ƒ`config.yml.example`æ–‡ä»¶ã€‚\n\n## APIæ–‡æ¡£\n\nå¯åŠ¨åç«¯æœåŠ¡å™¨åï¼Œå¯ä»¥åœ¨ä»¥ä¸‹åœ°å€è®¿é—®APIæ–‡æ¡£ï¼š\n\n```\nhttp://localhost:8000/docs\n```\n\n## é¡¹ç›®ç»“æ„\n\n```\nagents-mcp-cloud/\nâ”œâ”€â”€ backend/             # åç«¯ä»£ç \nâ”‚   â”œâ”€â”€ app/             # åº”ç”¨ä»£ç \nâ”‚   â”‚   â”œâ”€â”€ api/         # APIè·¯ç”±\nâ”‚   â”‚   â”œâ”€â”€ core/        # æ ¸å¿ƒåŠŸèƒ½\nâ”‚   â”‚   â”œâ”€â”€ db/          # æ•°æ®åº“å·¥å…·\nâ”‚   â”‚   â”œâ”€â”€ models/      # æ•°æ®æ¨¡å‹\nâ”‚   "])</script><script>self.__next_f.push([1,"â”‚   â”œâ”€â”€ schemas/     # Pydanticæ¨¡å¼\nâ”‚   â”‚   â”œâ”€â”€ utils/       # å·¥å…·å‡½æ•°\nâ”‚   â”‚   â””â”€â”€ services/    # ä¸šåŠ¡æœåŠ¡\nâ”‚   â”œâ”€â”€ config-dev.yml   # å¼€å‘ç¯å¢ƒé…ç½® \nâ”‚   â”œâ”€â”€ config-test.yml  # æµ‹è¯•ç¯å¢ƒé…ç½®\nâ”‚   â”œâ”€â”€ config-prod.yml  # ç”Ÿäº§ç¯å¢ƒé…ç½®\nâ”‚   â”œâ”€â”€ main.py          # ä¸»åº”ç”¨å…¥å£\nâ”‚   â””â”€â”€ requirements.txt # ä¾èµ–åˆ—è¡¨\nâ”œâ”€â”€ docker/              # Dockerä¾èµ–ç»„ä»¶\nâ”‚   â”œâ”€â”€ docker-compose.yml # Dockerç¼–æ’æ–‡ä»¶\nâ”‚   â””â”€â”€ mysql/           # MySQLç›¸å…³é…ç½®\nâ”œâ”€â”€ frontend/            # å‰ç«¯ä»£ç \nâ”‚   â”œâ”€â”€ public/          # é™æ€èµ„æº\nâ”‚   â”œâ”€â”€ src/             # æºä»£ç \nâ”‚   â”‚   â”œâ”€â”€ assets/      # èµ„æºæ–‡ä»¶\nâ”‚   â”‚   â”œâ”€â”€ components/  # Vueç»„ä»¶\nâ”‚   â”‚   â”œâ”€â”€ router/      # è·¯ç”±é…ç½®\nâ”‚   â”‚   â”œâ”€â”€ store/       # Vuexå­˜å‚¨\nâ”‚   â”‚   â”œâ”€â”€ views/       # é¡µé¢è§†å›¾\nâ”‚   â”‚   â””â”€â”€ api/         # APIå®¢æˆ·ç«¯\nâ”‚   â””â”€â”€ package.json     # ä¾èµ–åˆ—è¡¨\nâ””â”€â”€ scripts/             # è„šæœ¬æ–‡ä»¶\n```\n\n## è®¸å¯è¯\n\n[MIT](LICENSE)5c:T579,## what is MCP Agents Cloud? \nMCP Agents Cloud is a platform designed for managing MCP servers and agents, providing a comprehensive solution for user and server management.\n\n## how to use MCP Agents Cloud? \nTo use MCP Agents Cloud, set up the MySQL database using Docker, configure the backend and frontend environments, and run the application to access the management features.\n\n## key features of MCP Agents Cloud? \n- User management (registration, login, password reset)\n- MCP server management (add, edit, delete, view)\n- Agent management (create, edit, delete, view)\n- Agent SDK (Python package and HTTP API)\n- Agent chat interaction (streaming output)\n- SDK key management\n\n## use cases of MCP Agents Cloud? \n1. Managing multiple MCP servers efficiently.\n2. Creating and managing agents for various tasks.\n3. Providing a user-friendly interface for server and agent interactions.\n\n## FAQ from MCP Agents Cloud? \n- What technologies are used in MCP Agents Cloud?\n\u003e The project uses Vue.js for the frontend and Python with FastAPI for the backend, along with MySQL for the database.\n\n- Is there a detailed API documentation available?\n\u003e Yes, API documentation can be accessed at http://localhost:8000/api/v1/docs after starting the backend server.\n\n- How can I set up the project locally?\n\u003e Follow the quick start guide in the documentation to install dependencies and configure the environment.5d:T417,\u003cp align=\"center\"\u003e\n  \u003cimg src=\"https://github.com/user-attachments/assets/3f8c6127-2c02-4103-a010-0ea5a44dcbe2\" alt=\"Description\" width=\"300\"\u003e\n\u003c/p\u003e\n\n\nA CLI tool for interacting with MCP endpoints for CLI based AI agents (like aider)\n\n## Usage\n\nThe purpose of this tool is to load aider with context of how to call tools on an MCP endpoint.\n\ninside aider\n\n```bash\n/run utilitybelt describe https://mcp-example.com\n```\n\nthis should a list of command line calls to aider to use as suggestions for tools it can call.\n\nwhen tools are suggested, aider should use the following format:\n\n```bash\n/run utilitybelt tools call https://mcp-example.com \u003ctool_name\u003e \"\u003ctool_params_escaped_json\u003e\"\n```\n\n## See it work\n\nUsing an MCP endpoint for a calculator in aider.\n\n\u003cimg width=\"530\" alt=\"Screenshot 2025-03-24 at 1 02 00 AM\" src=\"https://github.com/user-attachments/assets/3af0d45e-c1e9-4700-abec-d48e395d999f\" /\u003e\n\u003cimg width=\"558\" alt=\"Screenshot 2025-03-24 at 1 02 13 AM\" src=\"https://github.com/user-attachments/assets/32ecbe7e-8102-4b41-a165-b01685e2635d\" /\u003e5e:T568,## what is UtilityBelt? \nUtilityBelt is a command-line interface (CLI) tool designed for interacting with MCP (Multi-Channel Protocol) endpoints, specifically for CLI-based AI agents like Aider.\n\n## how to use UtilityBelt? \nTo use UtilityBelt, you can load Aider with context on how to call tools on an MCP endpoint by executing the command: \n```bash\n/run utilitybelt describe https://mcp-example.com\n```\nThis command will provide a list of command line calls that Aider can use as suggestions fo"])</script><script>self.__next_f.push([1,"r tools.\n\n## key features of UtilityBelt? \n- Seamless integration with MCP endpoints for AI agents.\n- Provides command line suggestions for tool usage.\n- Facilitates easy interaction with various tools through Aider.\n\n## use cases of UtilityBelt? \n1. Interacting with a calculator MCP endpoint through Aider.\n2. Suggesting commands for various tools based on the MCP context.\n3. Enhancing the functionality of CLI-based AI agents by providing context-aware tool suggestions.\n\n## FAQ from UtilityBelt? \n- What is an MCP endpoint?\n\u003e An MCP endpoint is a service that allows communication with various tools and services through a unified protocol.\n\n- Can UtilityBelt be used with any CLI-based AI agent?\n\u003e Yes! UtilityBelt is designed to work with any CLI-based AI agent that can interact with MCP endpoints.\n\n- Is UtilityBelt free to use?\n\u003e Yes! UtilityBelt is open-source and free to use.5f:T6d8,# mcp-gomamayo\n\n\u003c!-- ãƒãƒƒã‚¸ (å¿…è¦ã«å¿œã˜ã¦å®Ÿéš›ã®ãƒãƒƒã‚¸URLã«ç½®ãæ›ãˆã¦ãã ã•ã„) --\u003e\n[![Go Version](https://img.shields.io/badge/go-v1.24-blue.svg\n)](https://golang.org/)\n[![MCP](https://img.shields.io/badge/MCP-Server-6236FF?style=flat\u0026logo=claude\u0026logoColor=white)](https://github.com/modelcontextprotocol/mcp)\n[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)\n\nãƒ†ã‚­ã‚¹ãƒˆä¸­ã®ã€Œã‚´ãƒãƒãƒ¨ã€æ§‹æ–‡ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãŸã‚ã® [Model Context Protocol (MCP)](https://github.com/modelcontextprotocol/specification) ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚ \n\n## ç›®æ¬¡\n\n- [ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)\n- [Claude Desktop ã§ã®åˆ©ç”¨](#claude-desktop-ã§ã®åˆ©ç”¨)\n  - [MCPã‚µãƒ¼ãƒãƒ¼è¨­å®š](#mcpã‚µãƒ¼ãƒãƒ¼è¨­å®š)\n- [ä½¿ã„æ–¹](#ä½¿ã„æ–¹)\n\n## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n\n```bash\ngit clone https://github.com/mizakahk/mcp-gomamayo.git\ncd mcp-gomamayo\ntask build\n```\n\n## Claude Desktop ã§ã®åˆ©ç”¨\n\n### MCPã‚µãƒ¼ãƒãƒ¼è¨­å®š\n\n`claude_desktop_config.json` ã«ä»¥ä¸‹ã®è¨­å®šã‚’è¿½åŠ ã—ã¾ã™\n\n1.  **WSLä¸Šã§èµ·å‹•:**\n    ```json\n    {\n      \"mcpServers\": {\n          \"mcp-gomamayo\": {\n              \"command\": \"wsl\",\n              \"args\": [\n                  \"bash\",\n                  \"-ic\",\n                  \"~/mcp-gomamayo/bin/mcp-gomamayo\"\n              ],\n              \"env\": {}\n          }\n      }\n    }\n    ```\n\nè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ãŸå¾Œã€Claude Desktop ã‚’å†èµ·å‹•ã™ã‚‹ã¨ã€`gomamayo-checker` ãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚\n\n## ä½¿ã„æ–¹\n\nMCP ã‚µãƒ¼ãƒãƒ¼ãŒ Claude Desktop ã§æœ‰åŠ¹ã«ãªã‚‹ã¨ã€`check_gomamayo` ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®ã‚´ãƒãƒãƒ¨æ§‹æ–‡ã‚’ãƒã‚§ãƒƒã‚¯ã§ãã¾ã™ã€‚\n\n**ä¾‹ ã€Œç¦å±±é›…æ²»ã€ã®åˆ¤å®š:**\n\n![akakara](screenshot/fukuyamamasaharu.png)60:T45d,## what is mcp-gomamayo? \nMCP-gomamayo is a server designed for the project 'ã‚´ãƒãƒãƒ¨', providing a platform for developers to build and manage their applications.\n\n## how to use mcp-gomamayo? \nTo use mcp-gomamayo, clone the repository from GitHub and follow the setup instructions provided in the documentation.\n\n## key features of mcp-gomamayo? \n- Easy setup and configuration for developers\n- Supports various plugins and extensions\n- Active community support for troubleshooting and enhancements\n\n## use cases of mcp-gomamayo? \n1. Building custom applications using the MCP framework.\n2. Managing server resources efficiently for development projects.\n3. Collaborating with other developers in the community.\n\n## FAQ from mcp-gomamayo? \n- Is mcp-gomamayo free to use?  \n\u003e Yes! mcp-gomamayo is open-source and free to use under the MIT license.\n\n- Where can I find the documentation?  \n\u003e Documentation is available in the GitHub repository under the 'docs' folder.\n\n- How can I contribute to mcp-gomamayo?  \n\u003e Contributions are welcome! Please check the 'Contributing' section in the repository for guidelines.61:T413,# MCP Agent\n\nThis is a Launchbar action integrated with Langchain and MCP to automatically complete tasks based on your prompt.\n\n## Configuration\n\nBefore using the application, ensure that you add a `.env` file to configure your LLM API key. Additionally, include an `mcp_config.json` file to set up your MCP.\n\nThe "])</script><script>self.__next_f.push([1,"`mcp_config.json` should format like this:\n\n```json\n{\n  \"filesystem\": {\n    \"command\": \"npx\",\n    \"args\": [\n      \"-y\",\n      \"@modelcontextprotocol/server-filesystem\",\n      \"/your/folder/path1\",\n      \"/your/folder/path2\"\n    ]\n  },\n  \"fetch\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"mcp-server-fetch\"\n    ]\n  }\n}\n```\nThe `suggestions.js` file is designed to activate autocomplete when you type \"@\", providing suggestions for the MCP server names. Furthermore, this function dynamically loads only the MCP server associated with the tool name you've specified. You have the flexibility to modify the keyword section within `suggestions.js` to align with the MCP server you have installed or to alter its name if you want.62:T4b0,## what is MCP Agent? \nMCP Agent is a LaunchBar action that integrates with Langchain and MCP to automatically complete tasks based on user prompts.\n\n## how to use MCP Agent? \nTo use MCP Agent, configure your environment by adding a `.env` file with your LLM API key and an `mcp_config.json` file to set up your MCP. The `mcp_config.json` should define commands and arguments for filesystem and fetch operations.\n\n## key features of MCP Agent? \n- Automatic task completion based on prompts\n- Integration with Langchain and MCP\n- Customizable configuration through JSON files\n\n## use cases of MCP Agent? \n1. Automating repetitive tasks in development workflows.\n2. Enhancing productivity by providing autocomplete suggestions for MCP server names.\n3. Streamlining file system operations through command execution.\n\n## FAQ from MCP Agent? \n- What is required to set up MCP Agent?\n\u003e You need to create a `.env` file for your API key and an `mcp_config.json` file for configuration.\n\n- Can I customize the commands in MCP Agent?\n\u003e Yes! You can modify the `mcp_config.json` and `suggestions.js` files to suit your needs.\n\n- Is MCP Agent free to use?\n\u003e Yes! MCP Agent is open-source and available for free.63:T5ec,# MCP Tool Langgraph Integration\n\n## Description\nExample project of how to integrate MCP endpoint tools into a Langgraph tool node\n\nThe graph consists of only 2 nodes, `agent` and `tool`.\n\n## Prerequisites\nTo use this project, make sure you have Python 3.11.\n\n### [uv](https://pypi.org/project/uv/) is recommended\n\n#### Linux and Mac\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n#### Windows\n```bash\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n### MCP Server requirements  \n- This example uses the MCP Server sample `@modelcontextprotocol/server-brave-search` to add Brave Search tools. This requires that you have `node` and `npx` installed.\n\n### API Keys\n- The MCP Server sample used is for Brave Search, you can get a free API key from https://brave.com/search/api/\n- You will need and API key for the chosen AI provider which defaults to Anthropic but can be changed by editing the `__main__.py` file\n- Put all api keys in a .env file in the repository root.\n\n## From source Usage\n```shell\nuv run mcp_langgraph_tools\n```\n\n## Multiple MCP servers at one time\nCheck the multi_server branch for a more advanced example of how to use multiple MCP servers at once.\n\n## Whats New\n\n- Version 0.1.0:\n  - Initial release\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\nPaul Robello - probello@gmail.com64:T58d,## What is MCP Tool Langgraph Integration? \nMCP Tool Langgraph Integration is an example project that demonstrates how to integrate MCP endpoint tools into a Langgraph tool node, consisting of two nodes: `agent` and `tool`.\n\n## How to use MCP Tool Langgraph Integration? \nTo use this project, ensure you have Python 3.11 installed. You can run the project from the source using the command `uv run mcp_langgraph_tools` after setting up the necessary API keys in a .env file.\n\n## Key features of MCP Tool Langgraph Integration? \n- Integration of MCP tools with Langgraph.\n- Simple setup with Python 3.11.\n- Support for Brave Sear"])</script><script>self.__next_f.push([1,"ch tools through the MCP Server.\n\n## Use cases of MCP Tool Langgraph Integration? \n1. Integrating AI tools into applications using Langgraph.\n2. Building custom agent-tool interactions for various applications.\n3. Utilizing Brave Search tools in conjunction with AI models.\n\n## FAQ from MCP Tool Langgraph Integration? \n- What are the prerequisites for using this project?  \n\u003e You need Python 3.11, and it's recommended to use the `uv` package for running the project.\n\n- How do I obtain the necessary API keys?  \n\u003e You can get a free API key for Brave Search from https://brave.com/search/api/ and you will need an API key for the AI provider, which can be set in the .env file.\n\n- Is this project open for contributions?  \n\u003e Yes! Contributions are welcome, and you can submit a Pull Request.65:Tf75,# Llama MCP Streamlit\n\nThis project is an interactive AI assistant built with **Streamlit**, **NVIDIA NIM's API (LLaMa 3.3:70b)/Ollama**, and **Model Control Protocol (MCP)**. It provides a conversational interface where you can interact with an LLM to execute real-time external tools via MCP, retrieve data, and perform actions seamlessly.\n\nThe assistant supports:\n\n- **Custom model selection** (NVIDIA NIM / Ollama)\n- **API configuration** for different backends\n- **Tool integration via MCP** to enhance usability and real-time data processing\n- **A user-friendly chat-based experience** with Streamlit\n\n## ğŸ“¸ Screenshots\n\n![Homepage Screenshot](screenshot/Screenshot1.png)\n\n![Tools Screenshot](screenshot/Screenshot3.png)\n\n![Chat Screenshot](screenshot/Screenshot2.png)\n\n![Chat (What can you do?) Screenshot](screenshot/Screenshot4.png)\n---\n\n## ğŸ“ Project Structure\n\n```\nllama_mcp_streamlit/\nâ”‚â”€â”€ ui/\nâ”‚   â”œâ”€â”€ sidebar.py       # UI components for Streamlit sidebar\nâ”‚   â”œâ”€â”€ chat_ui.py       # Chat interface components\nâ”‚â”€â”€ utils/\nâ”‚   â”œâ”€â”€ agent.py         # Handles interaction with LLM and tools\nâ”‚   â”œâ”€â”€ mcp_client.py    # MCP client for connecting to external tools\nâ”‚   â”œâ”€â”€ mcp_server.py    # Configuration for MCP server selection\nâ”‚â”€â”€ config.py            # Configuration settings\nâ”‚â”€â”€ main.py              # Entry point for the Streamlit app\n.env                      # Environment variables\nDockerfile                # Docker configuration\npyproject.toml            # Poetry dependency management\n```\n\n---\n\n## ğŸ”§ Environment Variables\n\nBefore running the project, configure the `.env` file with your API keys:\n\n```\n# Endpoint for the NVIDIA Integrate API\nAPI_ENDPOINT=https://integrate.api.nvidia.com/v1\nAPI_KEY=your_api_key_here\n\n# Endpoint for the Ollama API\nAPI_ENDPOINT=http://localhost:11434/v1/\nAPI_KEY=ollama\n```\n\n---\n\n## ğŸš€ Running the Project\n\n### Using Poetry\n\n1. Install dependencies:\n   ```bash\n   poetry install\n   ```\n2. Run the Streamlit app:\n   ```bash\n   poetry run streamlit run llama_mcp_streamlit/main.py\n   ```\n\n### Using Docker\n\n1. Build the Docker image:\n   ```bash\n   docker build -t llama-mcp-assistant .\n   ```\n2. Run the container:\n   ```bash\n   docker compose up\n   ```\n\n---\n\n\n## ğŸ”„ Changing MCP Server Configuration\n\nTo modify which MCP server to use, update the `utils/mcp_server.py` file.\nYou can use either NPX or Docker as the MCP server:\n\n### NPX Server\n\n```python\nserver_params = StdioServerParameters(\n    command=\"npx\",\n    args=[\n        \"-y\",\n        \"@modelcontextprotocol/server-filesystem\",\n        \"/Users/username/Desktop\",\n        \"/path/to/other/allowed/dir\"\n    ],\n    env=None,\n)\n```\n\n### Docker Server\n\n```python\nserver_params = StdioServerParameters(\n    command=\"docker\",\n    args=[\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\", \"type=bind,src=/Users/username/Desktop,dst=/projects/Desktop\",\n        \"--mount\", \"type=bind,src=/path/to/other/allowed/dir,dst=/projects/other/allowed/dir,ro\",\n        \"--mount\", \"type=bind,src=/path/to/file.txt,dst=/projects/path/to/file.txt\",\n        \"mcp/filesystem\",\n        \"/projects\"\n    ],\n    env=None,\n)\n```\n\nModify the `server_params` configuration as needed to fit your setup.\n\n---\n\n## ğŸ“Œ Features\n\n- **"])</script><script>self.__next_f.push([1,"Real-time tool execution via MCP**\n- **LLM-powered chat interface**\n- **Streamlit UI with interactive chat elements**\n- **Support for multiple LLM backends (NVIDIA NIM \u0026 Ollama)**\n- **Docker support for easy deployment**\n\n---\n\n## ğŸ›  Dependencies\n\n- Python 3.11+\n- Streamlit\n- OpenAI API (for NVIDIA NIM integration)\n- MCP (Model Control Protocol)\n- Poetry (for dependency management)\n- Docker (optional, for containerized deployment)\n\n---\n\n## ğŸ“œ License\n\nThis project is licensed under the MIT License.\n\n---\n\n## ğŸ¤ Contributing\n\nFeel free to submit pull requests or report issues!\n\n---\n\n## ğŸ“¬ Contact\n\nFor any questions, reach out via GitHub Issues.\n\n---66:T54a,## What is LLaMa-MCP-Streamlit? \nLLaMa-MCP-Streamlit is an interactive AI assistant built using Streamlit, NVIDIA NIM (LLaMa 3.3:70B), and Model Control Protocol (MCP). It allows users to interact with a large language model (LLM) to execute real-time external tools, retrieve data, and perform various actions seamlessly.\n\n## How to use LLaMa-MCP-Streamlit? \nTo use the assistant, you can run the Streamlit app after configuring the necessary API keys in the `.env` file. You can either use Poetry or Docker to set up and run the application.\n\n## Key features of LLaMa-MCP-Streamlit? \n- Custom model selection from NVIDIA NIM or Ollama.\n- API configuration for different backends.\n- Tool integration via MCP for enhanced usability.\n- User-friendly chat-based interface.\n\n## Use cases of LLaMa-MCP-Streamlit? \n1. Executing real-time data processing tasks.\n2. Interacting with various LLMs for different applications.\n3. Enhancing productivity through seamless tool integration.\n\n## FAQ from LLaMa-MCP-Streamlit? \n- **Can I use my own models?**  \nYes! You can select custom models from NVIDIA NIM or Ollama.\n\n- **Is Docker required to run the project?**  \nNo, Docker is optional. You can run the project using Poetry as well.\n\n- **How do I configure the MCP server?**  \nYou can modify the `utils/mcp_server.py` file to change the MCP server configuration.67:T672,## What is LangChain.js MCP Adapters? \nLangChain.js MCP Adapters is a library designed to integrate Model Context Protocol (MCP) tools with LangChain.js applications, enabling seamless communication between various AI models and services.\n\n## How to use LangChain.js MCP Adapters? \nTo use the adapters, install the package via npm and set up your MCP server. You can connect to the server using either stdio or SSE transport methods, depending on your requirements.\n\n## Key features of LangChain.js MCP Adapters? \n- **Transport Options**: Supports stdio and SSE connections with customizable headers for authentication.\n- **Multi-Server Management**: Connect to multiple MCP servers simultaneously and manage tools efficiently.\n- **Agent Integration**: Works with LangChain.js and LangGraph.js, optimized for various AI models.\n- **Development Features**: Includes comprehensive logging, flexible configurations, and robust error handling.\n\n## Use cases of LangChain.js MCP Adapters? \n1. Integrating multiple AI models for complex problem-solving.\n2. Building applications that require real-time data from various sources.\n3. Creating agents that can interact with different services seamlessly.\n\n## FAQ from LangChain.js MCP Adapters? \n- **What is the Model Context Protocol (MCP)?**  \n\u003e MCP is a protocol that allows different AI models to communicate and share context effectively.\n\n- **Is there a specific Node.js version required?**  \n\u003e Yes, Node.js version 18 or higher is required for the library to function properly.\n\n- **Can I connect to multiple servers?**  \n\u003e Yes, the library supports connecting to multiple MCP servers at the same time.68:Tae2,# MCP Client Using LangChain / TypeScript [![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/hideya/mcp-langchain-client-ts/blob/main/LICENSE)\n\nThis simple [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\nclient demonstrates the use of MCP server tools by LangChain ReAct Agent.\n\nIt leverages a utility function `convertMcpToLangchainTools()` from\n[`@h1"])</script><script>self.__next_f.push([1,"deya/langchain-mcp-tools`](https://www.npmjs.com/package/@h1deya/langchain-mcp-tools).  \nThis function handles parallel initialization of specified multiple MCP servers\nand converts their available tools into an array of LangChain-compatible tools\n([`StructuredTool[]`](https://api.js.langchain.com/classes/_langchain_core.tools.StructuredTool.html)).\n\nLLMs from Anthropic, OpenAI and Groq are currently supported.\n\nA python version of this MCP client is available\n[here](https://github.com/hideya/mcp-client-langchain-py)\n\n## Prerequisites\n\n- Node.js 16+\n- npm 7+ (`npx`) to run Node.js-based MCP servers\n- [optional] [`uv` (`uvx`)](https://docs.astral.sh/uv/getting-started/installation/)\n  installed to run Python-based MCP servers\n- API keys from [Anthropic](https://console.anthropic.com/settings/keys),\n  [OpenAI](https://platform.openai.com/api-keys), and/or\n  [Groq](https://console.groq.com/keys)\n  as needed.\n\n## Setup\n1. Install dependencies:\n    ```bash\n    npm install\n    ```\n\n2. Setup API keys:\n    ```bash\n    cp .env.template .env\n    ```\n    - Update `.env` as needed.\n    - `.gitignore` is configured to ignore `.env`\n      to prevent accidental commits of the credentials.\n\n3. Configure LLM and MCP Servers settings `llm_mcp_config.json5` as needed.\n\n    - [The configuration file format](https://github.com/hideya/mcp-client-langchain-ts/blob/main/llm_mcp_config.json5)\n      for MCP servers follows the same structure as\n      [Claude for Desktop](https://modelcontextprotocol.io/quickstart/user),\n      with one difference: the key name `mcpServers` has been changed\n      to `mcp_servers` to follow the snake_case convention\n      commonly used in JSON configuration files.\n    - The file format is [JSON5](https://json5.org/),\n      where comments and trailing commas are allowed.\n    - The format is further extended to replace `${...}` notations\n      with the values of corresponding environment variables.\n    - Keep all the credentials and private info in the `.env` file\n      and refer to them with `${...}` notation as needed.\n\n\n## Usage\n\nRun the app:\n```bash\nnpm start\n```\n\nRun in verbose mode:\n```bash\nnpm run start:v\n```\n\nSee commandline options:\n```bash\nnpm run start:h\n```\n\nAt the prompt, you can simply press Enter to use example queries that perform MCP server tool invocations.\n\nExample queries can be configured in  `llm_mcp_config.json5`69:T533,## What is MCP Client Using LangChain / TypeScript? \nMCP Client Using LangChain / TypeScript is a client implementation that demonstrates the use of Model Context Protocol (MCP) server tools through the LangChain ReAct Agent.\n\n## How to use MCP Client? \nTo use the MCP Client, install the necessary dependencies, set up your API keys, configure the MCP servers, and run the application using Node.js.\n\n## Key features of MCP Client? \n- Supports multiple MCP servers and converts their tools into LangChain-compatible tools.\n- Utilizes utility functions for parallel initialization of MCP servers.\n- Compatible with LLMs from Anthropic, OpenAI, and Groq.\n\n## Use cases of MCP Client? \n1. Integrating various MCP server tools into a single application.\n2. Facilitating the use of language models in applications requiring context management.\n3. Enabling developers to build applications that leverage multiple AI models seamlessly.\n\n## FAQ from MCP Client? \n- What are the prerequisites for using the MCP Client?  \n\u003e You need Node.js 16+, npm 7+, and API keys from the respective LLM providers.\n\n- Is there a Python version of this client?  \n\u003e Yes, a Python version is available on GitHub.\n\n- How do I configure the MCP servers?  \n\u003e You can configure the MCP servers in the `llm_mcp_config.json5` file following the specified format.6a:T1ec4,# Flask Webapplicatie met LLM-integratie en MCP-tools\n\nDeze Flask-webapplicatie stelt gebruikers in staat om:\n\n- LLM-modellen (OpenAI en Anthropic) te benaderen via een eenvoudige webinterface\n- Prompts in te voeren en antwoorden te ontvangen\n- MCP-servers (Model Context Protocol) voor GitHub en Brave Search te starten en stoppen\n- De prompt automatisch te verrijken"])</script><script>self.__next_f.push([1," met context uit deze tools voordat deze naar het LLM wordt gestuurd\n\n## Functionaliteiten\n\n- **LLM-model selectie**: Kies tussen OpenAI GPT-3.5 en Anthropic Claude 2\n- **Prompt invoer**: Voer een vraag of prompt in om door het gekozen model te laten beantwoorden\n- **MCP-tools beheer**: Start en stop externe tools (Brave Search en GitHub) vanuit de webinterface\n- **Contextverrijking**: De applicatie verrijkt je prompt automatisch met relevante informatie uit actieve tools\n- **Volledige prompt weergave**: Bekijk de volledige prompt inclusief toegevoegde context\n\n## Installatie\n\n### Vereisten\n\n- Python 3.7 of hoger\n\n### Stappen\n\n1. **Clone de repository**\n\n   ```bash\n   git clone https://github.com/Fbeunder/MCP_FLASK.git\n   cd MCP_FLASK\n   ```\n\n2. **Maak een virtuele omgeving aan (aanbevolen)**\n\n   ```bash\n   # Windows\n   python -m venv venv\n   venv\\Scripts\\activate\n   \n   # macOS/Linux\n   python3 -m venv venv\n   source venv/bin/activate\n   ```\n\n3. **Installeer de vereiste pakketten**\n\n   ```bash\n   # Aanbevolen: installeer alle afhankelijkheden via requirements.txt\n   pip install -r requirements.txt\n   \n   # Alternatief: installeer alleen de specifieke pakketten die je nodig hebt\n   pip install flask requests\n   \n   # Voor OpenAI model-toegang\n   pip install openai\n   \n   # Voor Anthropic model-toegang\n   pip install anthropic\n   \n   # Voor .env bestandsondersteuning\n   pip install python-dotenv\n   ```\n\n4. **Configureer de API-sleutels**\n\n   Je kunt API-sleutels configureren via omgevingsvariabelen of een .env bestand.\n\n   **Optie 1: Maak een .env bestand**\n   \n   Kopieer het .env.example bestand en pas het aan:\n   \n   ```bash\n   # Windows\n   copy .env.example .env\n   \n   # macOS/Linux\n   cp .env.example .env\n   ```\n   \n   Bewerk vervolgens het .env bestand en vul je API-sleutels in.\n\n   **Optie 2: Stel omgevingsvariabelen in**\n   \n   Stel de volgende omgevingsvariabelen in:\n\n   - `OPENAI_API_KEY`: Je OpenAI API-sleutel (voor GPT-modellen)\n   - `ANTHROPIC_API_KEY`: Je Anthropic API-sleutel (voor Claude-modellen)\n   - `BRAVE_API_KEY`: Je Brave Search API-sleutel (voor Brave Search MCP-server)\n   - `GITHUB_TOKEN`: Je GitHub Personal Access Token (optioneel, voor hogere limieten)\n\n   Bijvoorbeeld in Linux/macOS:\n\n   ```bash\n   export OPENAI_API_KEY=\"jouw-openai-api-sleutel\"\n   export ANTHROPIC_API_KEY=\"jouw-anthropic-api-sleutel\"\n   export BRAVE_API_KEY=\"jouw-brave-api-sleutel\"\n   export GITHUB_TOKEN=\"jouw-github-token\"\n   ```\n\n   Of in Windows:\n\n   ```cmd\n   set OPENAI_API_KEY=jouw-openai-api-sleutel\n   set ANTHROPIC_API_KEY=jouw-anthropic-api-sleutel\n   set BRAVE_API_KEY=jouw-brave-api-sleutel\n   set GITHUB_TOKEN=jouw-github-token\n   ```\n\n## Gebruik\n\n### De applicatie starten\n\nStart de Flask-app:\n\n```bash\npython app.py\n```\n\nDe applicatie zal standaard draaien op `http://localhost:5000`.\n\n### Werken met de webinterface\n\n1. **Open de webinterface** in je browser: `http://localhost:5000`\n\n2. **Start MCP-tools** (optioneel):\n   - Klik op \"Start Brave Search\" om de Brave Search-tool te starten\n   - Klik op \"Start GitHub\" om de GitHub-tool te starten\n\n3. **Voer een prompt in**:\n   - Selecteer het gewenste LLM-model uit de keuzelijst\n   - Typ je vraag of prompt in het tekstvak\n   - Klik op \"Verstuur naar AI\"\n\n4. **Bekijk het antwoord**:\n   - Het antwoord van het AI-model wordt getoond\n   - Je kunt optioneel op \"Toon volledige prompt met context\" klikken om te zien hoe de extra context is toegevoegd\n\n### MCP-servers\n\nDe applicatie gebruikt twee MCP-servers die automatisch gestart kunnen worden vanuit de interface:\n\n- **Brave Search MCP-server**: Draait op poort 5001 en biedt webzoekfunctionaliteit\n- **GitHub MCP-server**: Draait op poort 5002 en biedt GitHub-zoekfunctionaliteit\n\nWanneer deze servers actief zijn, wordt de context van deze tools automatisch toegevoegd aan je prompts.\n\n## Problemen oplossen\n\n### Virtuele omgeving problemen\n\nAls je een foutmelding krijgt over ontbrekende modules (zoals Flask) terwijl je zeker weet dat deze zijn geÃ¯nstalleerd, kan dit te maken hebben met problemen met virtuele omgevingen. Hier zijn en"])</script><script>self.__next_f.push([1,"kele stappen om dit op te lossen:\n\n#### Windows virtuele omgeving problemen\n\n1. **Controleer of de virtuele omgeving is geactiveerd**:\n   \n   Je moet de virtuele omgeving activeren in elke nieuwe terminal-sessie:\n   ```bash\n   venv\\Scripts\\activate\n   ```\n   \n   Je zou `(venv)` aan het begin van je command prompt moeten zien.\n\n2. **Controleer welke Python-executable wordt gebruikt**:\n   \n   ```bash\n   where python\n   ```\n   \n   Het eerste pad moet wijzen naar de python.exe in je virtuele omgeving (bijv. `\\path\\to\\project\\venv\\Scripts\\python.exe`).\n\n3. **Problemen met subprocess in Windows**:\n   \n   De laatste versie van de applicatie gebruikt nu automatisch dezelfde Python-executable voor het starten van MCP-servers als de hoofdapplicatie, wat problemen met virtuele omgevingen voorkomt.\n\n#### Linux/macOS virtuele omgeving problemen\n\n1. **Controleer of de virtuele omgeving is geactiveerd**:\n   \n   ```bash\n   source venv/bin/activate\n   ```\n   \n   Je zou `(venv)` aan het begin van je command prompt moeten zien.\n\n2. **Controleer welke Python-executable wordt gebruikt**:\n   \n   ```bash\n   which python\n   ```\n   \n   Het pad moet wijzen naar de python in je virtuele omgeving (bijv. `/path/to/project/venv/bin/python`).\n\n### ModuleNotFoundError: No module named 'flask'\n\nAls je deze fout nog steeds ziet wanneer je de applicatie of MCP-servers probeert te starten, probeer dan het volgende:\n\n1. **Controleer de installatie**:\n   ```bash\n   pip list | grep flask\n   ```\n   \n   Je zou Flask in de lijst moeten zien.\n\n2. **Herinstalleer Flask**:\n   ```bash\n   pip uninstall flask\n   pip install flask\n   ```\n\n3. **Gebruik absolute paden voor het uitvoeren**:\n   ```bash\n   # Vind het volledige pad naar Python in je virtuele omgeving\n   # Windows\n   echo %VIRTUAL_ENV%\\Scripts\\python.exe\n   \n   # Linux/macOS\n   echo $VIRTUAL_ENV/bin/python\n   \n   # Gebruik dit pad om de applicatie te starten\n   /volledig/pad/naar/venv/bin/python app.py\n   ```\n\n4. **Controleer PYTHONPATH**:\n   \n   In sommige gevallen kan de PYTHONPATH omgevingsvariabele verstoord raken:\n   ```bash\n   # Windows\n   echo %PYTHONPATH%\n   \n   # Linux/macOS\n   echo $PYTHONPATH\n   ```\n   \n   Als het een waarde heeft die niet zinvol is voor je project, overweeg om het tijdelijk te wissen:\n   ```bash\n   # Windows\n   set PYTHONPATH=\n   \n   # Linux/macOS\n   unset PYTHONPATH\n   ```\n\n### Andere package-gerelateerde fouten\n\nAls je andere ModuleNotFoundError-meldingen ziet, controleer dan of:\n- Alle packages zijn geÃ¯nstalleerd via `pip install -r requirements.txt`\n- Je Python-omgeving correct is ingesteld\n- Je geen oudere of incompatibele versies van packages hebt geÃ¯nstalleerd\n\n## Model Context Protocol (MCP)\n\nMCP (Model Context Protocol) is een open protocol dat AI-modellen in staat stelt om via gestandaardiseerde serverinterfaces veilig met externe bronnen te interageren. In deze applicatie worden MCP-servers gebruikt om:\n\n1. Extra context te verzamelen op basis van de gebruikersprompt\n2. Deze context toe te voegen aan de prompt voordat deze naar het LLM wordt gestuurd\n3. Zo het antwoord te verrijken met actuele of specifieke informatie\n\n## Opmerkingen\n\n- De MCP-serverimplementaties zijn vereenvoudigd voor demonstratiedoeleinden\n- Voor productiegerbruik is een betere foutafhandeling en beveiliging aanbevolen\n- De applicatie heeft API-sleutels nodig voor elke dienst (OpenAI, Anthropic, Brave Search)\n\n## Licentie\n\nMIT6b:T597,## What is MCP_FLASK? \nMCP_FLASK is a Flask web application that integrates LLM models and MCP tools to process prompts through various AI models and contextual tools.\n\n## How to use MCP_FLASK? \nTo use MCP_FLASK, clone the repository, set up a virtual environment, install the required packages, configure your API keys, and start the Flask app. Access the web interface to input prompts and receive responses from the selected LLM model.\n\n## Key features of MCP_FLASK? \n- Access to LLM models (OpenAI and Anthropic) via a simple web interface.\n- Input prompts and receive answers from the chosen model.\n- Start and stop MCP servers (Model Context Protocol) for GitHub and Bra"])</script><script>self.__next_f.push([1,"ve Search.\n- Automatic enrichment of prompts with context from these tools before sending to the LLM.\n- Full prompt display including added context.\n\n## Use cases of MCP_FLASK? \n1. Generating responses to user queries using AI models.\n2. Enriching prompts with real-time data from external sources.\n3. Managing external tools like Brave Search and GitHub directly from the web interface.\n\n## FAQ from MCP_FLASK? \n- What LLM models are supported?\n\u003e MCP_FLASK supports OpenAI GPT-3.5 and Anthropic Claude 2.\n\n- Is there a cost to use MCP_FLASK?\n\u003e MCP_FLASK is free to use, but requires API keys for the integrated services.\n\n- How do I troubleshoot installation issues?\n\u003e Ensure your virtual environment is activated and all required packages are installed.6c:T2bbe,# BrowserTools MCP\n\n\u003e Make your AI tools 10x more aware and capable of interacting with your browser\n\nThis application is a powerful browser monitoring and interaction tool that enables AI-powered applications via Anthropic's Model Context Protocol (MCP) to capture and analyze browser data through a Chrome extension.\n\nRead our [docs](https://browsertools.agentdesk.ai/) for the full installation, quickstart and contribution guides.\n\n## Roadmap\n\nCheck out our project roadmap here: [Github Roadmap / Project Board](https://github.com/orgs/AgentDeskAI/projects/1/views/1)\n\n## Updates\n\nv1.2.0 is out! Here's a quick breakdown of the update:\n- You can now enable \"Allow Auto-Paste into Cursor\" within the DevTools panel. Screenshots will be automatically pasted into Cursor (just make sure to focus/click into the Agent input field in Cursor, otherwise it won't work!)\n- Integrated a suite of SEO, performance, accessibility, and best practice analysis tools via Lighthouse\n- Implemented a NextJS specific prompt used to improve SEO for a NextJS application\n- Added Debugger Mode as a tool which executes all debugging tools in a particular sequence, along with a prompt to improve reasoning\n- Added Audit Mode as a tool to execute all auditing tools in a particular sequence\n- Resolved Windows connectivity issues\n- Improved networking between BrowserTools server, extension and MCP server with host/port auto-discovery, auto-reconnect, and graceful shutdown mechanisms\n- Added ability to more easily exit out of the Browser Tools server with Ctrl+C\n\n## Quickstart Guide\n\nThere are three components to run this MCP tool:\n\n1. Install our chrome extension from here: [v1.2.0 BrowserToolsMCP Chrome Extension](https://github.com/AgentDeskAI/browser-tools-mcp/releases/download/v1.2.0/BrowserTools-1.2.0-extension.zip)\n2. Install the MCP server from this command within your IDE: `npx @agentdeskai/browser-tools-mcp@latest`\n3. Open a new terminal and run this command: `npx @agentdeskai/browser-tools-server@latest`\n\n* Different IDEs have different configs but this command is generally a good starting point; please reference your IDEs docs for the proper config setup\n\nIMPORTANT TIP - there are two servers you need to install. There's...\n- browser-tools-server (local nodejs server that's a middleware for gathering logs)\nand\n- browser-tools-mcp (MCP server that you install into your IDE that communicates w/ the extension + browser-tools-server)\n\n`npx @agentdeskai/browser-tools-mcp@latest` is what you put into your IDE\n`npx @agentdeskai/browser-tools-server@latest` is what you run in a new terminal window\n\nAfter those three steps, open up your chrome dev tools and then the BrowserToolsMCP panel.\n\nIf you're still having issues try these steps:\n- Quit / close down your browser. Not just the window but all of Chrome itself. \n- Restart the local node server (browser-tools-server)\n- Make sure you only have ONE instance of chrome dev tools panel open\n\nAfter that, it should work but if it doesn't let me know and I can share some more steps to gather logs/info about the issue!\n\nIf you have any questions or issues, feel free to open an issue ticket! And if you have any ideas to make this better, feel free to reach out or open an issue ticket with an enhancement tag or reach out to me at [@tedx_ai on x](https://x.com/tedx_a"])</script><script>self.__next_f.push([1,"i)\n\n## Full Update Notes:\n\nCoding agents like Cursor can run these audits against the current page seamlessly. By leveraging Puppeteer and the Lighthouse npm library, BrowserTools MCP can now:\n\n- Evaluate pages for WCAG compliance\n- Identify performance bottlenecks\n- Flag on-page SEO issues\n- Check adherence to web development best practices\n- Review NextJS specific issues with SEO\n\n...all without leaving your IDE ğŸ‰\n\n---\n\n## ğŸ”‘ Key Additions\n\n| Audit Type         | Description                                                                                                                              |\n| ------------------ | ---------------------------------------------------------------------------------------------------------------------------------------- |\n| **Accessibility**  | WCAG-compliant checks for color contrast, missing alt text, keyboard navigation traps, ARIA attributes, and more.                        |\n| **Performance**    | Lighthouse-driven analysis of render-blocking resources, excessive DOM size, unoptimized images, and other factors affecting page speed. |\n| **SEO**            | Evaluates on-page SEO factors (like metadata, headings, and link structure) and suggests improvements for better search visibility.      |\n| **Best Practices** | Checks for general best practices in web development.                                                                                    |\n| **NextJS Audit**   | Injects a prompt used to perform a NextJS audit.                                                                                         |\n| **Audit Mode**     | Runs all auditing tools in a sequence.                                                                                                   |\n| **Debugger Mode**  | Runs all debugging tools in a sequence.                                                                                                  |\n\n---\n\n## ğŸ› ï¸ Using Audit Tools\n\n### âœ… **Before You Start**\n\nEnsure you have:\n\n- An **active tab** in your browser\n- The **BrowserTools extension enabled**\n\n### â–¶ï¸ **Running Audits**\n\n**Headless Browser Automation**:  \n Puppeteer automates a headless Chrome instance to load the page and collect audit data, ensuring accurate results even for SPAs or content loaded via JavaScript.\n\nThe headless browser instance remains active for **60 seconds** after the last audit call to efficiently handle consecutive audit requests.\n\n**Structured Results**:  \n Each audit returns results in a structured JSON format, including overall scores and detailed issue lists. This makes it easy for MCP-compatible clients to interpret the findings and present actionable insights.\n\nThe MCP server provides tools to run audits on the current page. Here are example queries you can use to trigger them:\n\n#### Accessibility Audit (`runAccessibilityAudit`)\n\nEnsures the page meets accessibility standards like WCAG.\n\n\u003e **Example Queries:**\n\u003e\n\u003e - \"Are there any accessibility issues on this page?\"\n\u003e - \"Run an accessibility audit.\"\n\u003e - \"Check if this page meets WCAG standards.\"\n\n#### Performance Audit (`runPerformanceAudit`)\n\nIdentifies performance bottlenecks and loading issues.\n\n\u003e **Example Queries:**\n\u003e\n\u003e - \"Why is this page loading so slowly?\"\n\u003e - \"Check the performance of this page.\"\n\u003e - \"Run a performance audit.\"\n\n#### SEO Audit (`runSEOAudit`)\n\nEvaluates how well the page is optimized for search engines.\n\n\u003e **Example Queries:**\n\u003e\n\u003e - \"How can I improve SEO for this page?\"\n\u003e - \"Run an SEO audit.\"\n\u003e - \"Check SEO on this page.\"\n\n#### Best Practices Audit (`runBestPracticesAudit`)\n\nChecks for general best practices in web development.\n\n\u003e **Example Queries:**\n\u003e\n\u003e - \"Run a best practices audit.\"\n\u003e - \"Check best practices on this page.\"\n\u003e - \"Are there any best practices issues on this page?\"\n\n#### Audit Mode (`runAuditMode`)\n\nRuns all audits in a particular sequence. Will run a NextJS audit if the framework is detected.\n\n\u003e **Example Queries:**\n\u003e\n\u003e - \"Run audit mode.\"\n\u003e - \"Enter audit mode.\"\n\n#### NextJS Audits (`runNextJSAudit`)\n\nChecks for best practices and SEO improvements for "])</script><script>self.__next_f.push([1,"NextJS applications\n\n\u003e **Example Queries:**\n\u003e\n\u003e - \"Run a NextJS audit.\"\n\u003e - \"Run a NextJS audit, I'm using app router.\"\n\u003e - \"Run a NextJS audit, I'm using page router.\"\n\n#### Debugger Mode (`runDebuggerMode`)\n\nRuns all debugging tools in a particular sequence\n\n\u003e **Example Queries:**\n\u003e\n\u003e - \"Enter debugger mode.\"\n\n## Architecture\n\nThere are three core components all used to capture and analyze browser data:\n\n1. **Chrome Extension**: A browser extension that captures screenshots, console logs, network activity and DOM elements.\n2. **Node Server**: An intermediary server that facilitates communication between the Chrome extension and any instance of an MCP server.\n3. **MCP Server**: A Model Context Protocol server that provides standardized tools for AI clients to interact with the browser.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  MCP Client â”‚ â”€â”€â–º â”‚  MCP Server  â”‚ â”€â”€â–º â”‚  Node Server  â”‚ â”€â”€â–º â”‚   Chrome    â”‚\nâ”‚  (e.g.      â”‚ â—„â”€â”€ â”‚  (Protocol   â”‚ â—„â”€â”€ â”‚ (Middleware)  â”‚ â—„â”€â”€ â”‚  Extension  â”‚\nâ”‚   Cursor)   â”‚     â”‚   Handler)   â”‚     â”‚               â”‚     â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nModel Context Protocol (MCP) is a capability supported by Anthropic AI models that\nallow you to create custom tools for any compatible client. MCP clients like Claude\nDesktop, Cursor, Cline or Zed can run an MCP server which \"teaches\" these clients\nabout a new tool that they can use.\n\nThese tools can call out to external APIs but in our case, **all logs are stored locally** on your machine and NEVER sent out to any third-party service or API. BrowserTools MCP runs a local instance of a NodeJS API server which communicates with the BrowserTools Chrome Extension.\n\nAll consumers of the BrowserTools MCP Server interface with the same NodeJS API and Chrome extension.\n\n#### Chrome Extension\n\n- Monitors XHR requests/responses and console logs\n- Tracks selected DOM elements\n- Sends all logs and current element to the BrowserTools Connector\n- Connects to Websocket server to capture/send screenshots\n- Allows user to configure token/truncation limits + screenshot folder path\n\n#### Node Server\n\n- Acts as middleware between the Chrome extension and MCP server\n- Receives logs and currently selected element from Chrome extension\n- Processes requests from MCP server to capture logs, screenshot or current element\n- Sends Websocket command to the Chrome extension for capturing a screenshot\n- Intelligently truncates strings and # of duplicate objects in logs to avoid token limits\n- Removes cookies and sensitive headers to avoid sending to LLMs in MCP clients\n\n#### MCP Server\n\n- Implements the Model Context Protocol\n- Provides standardized tools for AI clients\n- Compatible with various MCP clients (Cursor, Cline, Zed, Claude Desktop, etc.)\n\n## Installation\n\nInstallation steps can be found in our documentation:\n\n- [BrowserTools MCP Docs](https://browsertools.agentdesk.ai/)\n\n## Usage\n\nOnce installed and configured, the system allows any compatible MCP client to:\n\n- Monitor browser console output\n- Capture network traffic\n- Take screenshots\n- Analyze selected elements\n- Wipe logs stored in our MCP server\n- Run accessibility, performance, SEO, and best practices audits\n\n## Compatibility\n\n- Works with any MCP-compatible client\n- Primarily designed for Cursor IDE integration\n- Supports other AI editors and MCP clients6d:T546,## What is BrowserTools MCP? \nBrowserTools MCP is a powerful browser monitoring and interaction tool that enables AI-powered applications to capture and analyze browser data through a Chrome extension using Anthropic's Model Context Protocol (MCP).\n\n## How to use BrowserTools MCP? \nTo use BrowserTools MCP, install th"])</script><script>self.__next_f.push([1,"e Chrome extension, set up the MCP server in your IDE, and run the browser-tools-server in a terminal. After setup, open the Chrome DevTools and access the BrowserToolsMCP panel.\n\n## Key features of BrowserTools MCP? \n- Capture and analyze browser data seamlessly.\n- Run accessibility, performance, SEO, and best practices audits.\n- Integrated debugging and auditing tools for enhanced web development.\n- Compatibility with various MCP clients like Cursor, Cline, and Zed.\n\n## Use cases of BrowserTools MCP? \n1. Monitoring browser console output and network traffic.\n2. Running audits for accessibility and performance on web pages.\n3. Capturing screenshots and analyzing selected DOM elements.\n\n## FAQ from BrowserTools MCP? \n- Is BrowserTools MCP free to use?  \n\u003e Yes! BrowserTools MCP is free to use for everyone.\n\n- What browsers are supported?  \n\u003e BrowserTools MCP is designed for use with Chrome.\n\n- Can I use it with other IDEs?  \n\u003e Yes, it is primarily designed for Cursor IDE but can work with other MCP-compatible clients.6e:T54c,# Figma Design Automation\n\nThis repository contains tools for automating Figma design creation and manipulation, including:\n\n1. **Figma Plugin**: A plugin for creating startup website components\n2. **Direct Integration**: Python scripts for direct Figma file manipulation\n3. **MCP Integration**: Tools that leverage MCP's Figma integration\n\n## Features\n\n- Automated navigation bar creation\n- Component templating\n- Style management\n- Direct file manipulation\n\n## Setup\n\n### Plugin Setup\n```bash\ncd figma-plugin\nnpm install\nnpm run build\n```\n\n### Python Setup\n```bash\ncd figma-agent\npython -m venv venv\nsource venv/bin/activate  # or `venv\\Scripts\\activate` on Windows\npip install -r requirements.txt\n```\n\n### Configure Figma API\n1. Get your Figma access token from Figma settings\n2. Set up the token using MCP Figma integration\n\n## Usage\n\n### Using the Plugin\n1. Import the plugin in Figma\n2. Run it from the plugins menu\n3. Customize the generated components\n\n### Using Direct Integration\n```bash\npython src/direct_figma.py\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nMIT License - see LICENSE file for details6f:T483,## what is Figma Design Automation? \nFigma Design Automation is a project that provides tools and plugins for automating the creation and manipulation of designs in Figma, a popular design tool.\n\n## how to use Figma Design Automation? \nTo use the project, you can either install the Figma plugin or use Python scripts for direct integration with Figma files. Follow the setup instructions provided in the repository to get started.\n\n## key features of Figma Design Automation? \n- Automated navigation bar creation\n- Component templating for quick design setups\n- Style management to maintain design consistency\n- Direct file manipulation through Python scripts\n\n## use cases of Figma Design Automation? \n1. Rapidly creating website components for startups\n2. Automating repetitive design tasks in Figma\n3. Integrating design workflows with Python scripts for enhanced functionality\n\n## FAQ from Figma Design Automation? \n- Is the Figma Design Automation project free to use?  \n\u003e Yes! The project is open-source and free to use.\n\n- What programming language is used in this project?  \n\u003e The project primarily uses Python for the direct integration scripts.70:T27e1,# Llama-Server MCP Proxy\n\nThis Node.js application acts as a proxy server for `llama-server`. Its primary purpose is to intercept chat completion requests, enhance them with tool capabilities via the Model Context Protocol (MCP), and allow the Language Model (LLM) to use these tools iteratively.\n\nIt proxies standard `llama-server` GUI requests (like fetching the main page) directly to your local `llama-server` instance and specifically processes `/v1/chat/completions` requests to enable tool interactions.\n\n## Current statu"])</script><script>self.__next_f.push([1,"s\n\n* brave search works\n* search1 API works\n* filesystem access is problematic, depending on the model used\n* puppeteer\n\n\n## Key Features\n\n*   **MCP Tool Integration:** Connects to MCP-compatible tool servers defined in `mcp-config.json`.\n*   **Dynamic System Prompt:** Automatically generates a system prompt listing available tools and their descriptions, injecting it into the LLM's context.\n*   **Iterative Tool Use:** Allows the LLM to make multiple tool calls in a single user turn. The proxy handles the request-response flow:\n    1.  LLM indicates a tool call.\n    2.  Proxy detects and parses the tool call.\n    3.  Proxy executes the tool via the appropriate MCP client.\n    4.  Proxy sends the tool's result back to the LLM.\n    5.  LLM uses the result to continue its response or call another tool.\n*   **Streaming Support:** Maintains streaming of LLM responses (Server-Sent Events) to the client, including intermediate messages like \"[Executing tool...]\" and tool results.\n*   **Error Handling:** Forwards errors from `llama-server` and provides error messages for failed tool executions back to the LLM and client. The LLM will analyze the error and attempt to find a workable approach.\n*   **Configurable:** Uses environment variables for port, `llama-server` URL, and MCP configuration path.\n*   **Debug Logging:** Optional verbose debug logging via an environment variable.\n\n## Prerequisites\n\n*   **Node.js:** Version 18 or higher (as indicated by `@modelcontextprotocol/sdk` dependencies).\n*   **`llama-server`:** A running instance of `llama-server` (or a compatible OpenAI-like API endpoint).\n*   **MCP Tool Servers:** One or more MCP-compatible tool servers that you want the LLM to access.\n\n## Setup\n\n1.  **Clone the Repository (or create the project directory):**\n    ```bash\n    # If you have a git repository:\n    # git clone \u003cyour-repo-url\u003e\n    # cd llama-server_mcp_proxy\n\n    # If starting from scratch, create a directory and navigate into it:\n    mkdir llama-server_mcp_proxy\n    cd llama-server_mcp_proxy\n    ```\n\n2.  **Create `package.json`:**\n    If you don't have one, create a `package.json` file with the following content:\n    ```json\n    {\n      \"name\": \"llama-server-mcp-proxy\",\n      \"version\": \"1.0.0\",\n      \"description\": \"A proxy for llama-server to enable MCP tool usage.\",\n      \"main\": \"llama-server-mcp-proxy.js\", \n      \"scripts\": {\n        \"start\": \"node llama-server-mcp-proxy.js\"\n      },\n      \"dependencies\": {\n        \"@modelcontextprotocol/sdk\": \"^1.8.0\"\n      }\n    }\n    ```\n\n3.  **Install Dependencies:**\n    Run the following command in your project directory to install the necessary packages:\n    ```bash\n    npm install\n    ```\n    This will use your `package.json` (and `package-lock.json` if present and consistent) to install the `@modelcontextprotocol/sdk`.\n\n4.  **Create `mcp-config.json`:**\n    This file tells the proxy how to connect to your MCP tool servers. It should be in the same directory as your proxy script (e.g., `llama-server-mcp-proxy.js`) by default, or you can specify its path via the `MCP_CONFIG_PATH` environment variable.\n\n    As a ready quick-start example rename  `mcp-config.json.example` to `mcp-config.json`\n\n    **`mcp-config.json.example`:**\n    ```json\n    {\n      \"mcpServers\": {\n        \"search1api\": {\n          \"command\": \"npx\",\n          \"args\": [\n            \"search1api-mcp\",\n            \"--port\",\n            \"0\", \n            \"--api-key\",\n            \"YOUR_SEARCH1API_KEY_PLACEHOLDER\" \n          ],\n          \"env\": {\n            \"DEBUG\": \"true\" \n          }\n        },\n        \"another_tool_server\": {\n          \"command\": \"path/to/your/tool/server/executable\",\n          \"args\": [\n            \"--some-config-for-tool\", \"value\",\n            \"--api-key\", \"ANOTHER_API_KEY_PLACEHOLDER\"\n          ],\n          \"env\": {}\n        }\n      }\n    }\n    ```\n    *   **`mcpServers`**: An object where each key is a unique name for your tool server (e.g., \"search1api\", \"my_custom_tools\").\n    *   **`command`**: The command to execute to start the MCP tool server. This could be `npx` for npx-runn"])</script><script>self.__next_f.push([1,"able packages, a direct path to an executable, or a script.\n    *   **`args`**: An array of arguments to pass to the command.\n        *   `--port 0` is often used to let the MCP server pick an available port for stdio communication.\n        *   **Replace `YOUR_SEARCH1API_KEY_PLACEHOLDER` and other placeholders with your actual API keys or necessary configuration.**\n    *   **`env`**: An optional object of environment variables to set for the MCP server process.\n\n    **Create your actual `mcp-config.json` by copying the example and filling in your real API keys and paths.**\n\n5.  **Add `mcp-config.json` to `.gitignore`:**\n    To prevent accidentally committing your sensitive API keys, create or update your `.gitignore` file in the project root:\n    ```\n    node_modules/\n    mcp-config.json\n    *.log\n    # Add other files/directories you want to ignore\n    ```\n\n6.  **Save the Proxy Code:**\n    Save the JavaScript proxy code provided in the previous steps into a file, for example, `llama-server-mcp-proxy.js` (as referenced in `package.json`).\n\n## Running the Proxy\n\n1.  **Ensure `llama-server` is running.**\n    The proxy needs to connect to it. By default, it assumes `llama-server` is at `http://localhost:8080`.\n\n2.  **Start the Proxy Server:**\n    Open your terminal in the project directory and run:\n    ```bash\n    npm start\n    ```\n    Or directly using Node:\n    ```bash\n    node llama-server-mcp-proxy.js\n    ```\n\n    You should see console output indicating the proxy has started, which MCP servers it connected to, and the tools available.\n\n3.  **Configure Environment Variables (Optional):**\n    You can customize the proxy's behavior using environment variables:\n    *   `PORT`: The port the proxy server will listen on (default: `9090`).\n    *   `LLAMA_SERVER_URL`: The URL of your running `llama-server` instance (default: `http://localhost:8080`).\n    *   `MCP_CONFIG_PATH`: The full path to your `mcp-config.json` file (default: `./mcp-config.json` relative to the script).\n    *   `MCP_PROXY_DEBUG`: Set to `true` for verbose debug logging (default: `false`).\n    *   `LLAMA_SERVER_TIMEOUT`: Timeout in milliseconds for requests to `llama-server` (default: `60000`).\n\n    Example (Linux/macOS):\n    ```bash\n    PORT=9000 LLAMA_SERVER_URL=http://127.0.0.1:8081 MCP_PROXY_DEBUG=true node llama-server-mcp-proxy.js\n    ```\n    Example (Windows PowerShell):\n    ```powershell\n    $env:PORT=\"9000\"; $env:LLAMA_SERVER_URL=\"http://127.0.0.1:8081\"; $env:MCP_PROXY_DEBUG=\"true\"; node llama-server-mcp-proxy.js\n    ```\n\n## Usage\n\n1.  Once the proxy server is running, **point your LLM GUI client (e.g., your browser accessing a web UI that normally talks to `llama-server`) to the proxy's address and port** (e.g., `http://localhost:9090` if the proxy is running on port 9090).\n2.  Interact with the LLM as usual.\n3.  When you ask the LLM to perform a task that could benefit from one of the configured tools, it should:\n    *   Indicate its intention to use a tool.\n    *   Output a tool call in the format `TOOL_NAME(ARG_NAME=\"ARG_VALUE\", ...)` or potentially an XML format.\n4.  The proxy will:\n    *   Detect this tool call.\n    *   Show an \"[Executing tool: TOOL_NAME...]\" message in the stream.\n    *   Execute the tool.\n    *   Show a \"[Tool Result for TOOL_NAME]: ...RAW_RESULT...\" message in the stream.\n    *   Feed the result back to the LLM.\n5.  The LLM will then use the tool's result to formulate its final response or decide to call another tool.\n\n## Tool Call Formats Recognized\n\nThe proxy attempts to recognize tool calls in the LLM's output in two primary formats after the LLM finishes its current response segment (indicated by `[DONE]`):\n\n1.  **Simple Function Style:**\n    ```    tool_name(param1=\"value1\", param2=\"value2\")\n    ```\n    Example: `news(query=\"latest AI research\", max_results=3)`\n\n2.  **XML Style:**\n    ```xml\n    \u003ctool_call\u003e\n        \u003ctool\u003etool_name\u003c/tool\u003e\n        \u003cparams\u003e\n            \u003cparam1\u003evalue1\u003c/param1\u003e\n            \u003cparam2\u003evalue2\u003c/param2\u003e\n        \u003c/params\u003e\n    \u003c/tool_call\u003e\n    ```\n\nThe proxy will parse the arguments accordingly fo"])</script><script>self.__next_f.push([1,"r each format.\n\n## Troubleshooting\n\n*   **\"Tool ... not found in any connected MCP server\"**:\n    *   Ensure the tool name output by the LLM exactly matches a tool name listed when the proxy starts (which comes from your MCP servers).\n    *   Check your `mcp-config.json` for typos in tool server commands or configurations.\n    *   Verify that your MCP tool servers are starting correctly and successfully registering their tools. Check the console output of the proxy when it starts for connection messages.\n*   **Proxy errors / `llama-server` errors (500, 502, etc.)**:\n    *   Ensure `llama-server` is running and accessible at the `LLAMA_SERVER_URL`.\n    *   Check `llama-server`'s own logs for any issues.\n    *   Enable `MCP_PROXY_DEBUG=true` for more detailed logs from the proxy.\n*   **Tool execution errors (e.g., \"402 Payment Required\")**: These errors come from the MCP tool server itself. The proxy will report them to the LLM, which should then ideally try a different approach or inform you.\n*   **\"Socket hang up\" / `ECONNRESET`**: This can occur if `llama-server` closes the connection unexpectedly. This might happen if the proxy sends a malformed request (e.g., incorrect JSON structure, problematic headers) or if `llama-server` itself encounters an internal error. Debug logs from both the proxy and `llama-server` are crucial.\n\n## Dependencies\n\n*   `@modelcontextprotocol/sdk`: Version `^1.8.0` (and its transitive dependencies as listed in `package-lock.json`).\n\n---71:T6ca,## what is Llama-Server MCP Proxy? \nLlama-Server MCP Proxy is a Node.js application that acts as a proxy server for `llama-server`, enabling the use of Model Context Protocol (MCP) tools for enhanced chat completion requests.\n\n## how to use Llama-Server MCP Proxy? \nTo use the proxy, clone the repository, set up the necessary configuration files, and run the proxy server. Point your LLM GUI client to the proxy's address to interact with the LLM using the configured tools.\n\n## key features of Llama-Server MCP Proxy? \n- **MCP Tool Integration:** Connects to MCP-compatible tool servers.\n- **Dynamic System Prompt:** Automatically generates a system prompt listing available tools.\n- **Iterative Tool Use:** Allows multiple tool calls in a single user turn.\n- **Streaming Support:** Maintains streaming of LLM responses.\n- **Error Handling:** Forwards errors from `llama-server` and provides feedback.\n- **Configurable:** Uses environment variables for customization.\n- **Debug Logging:** Optional verbose logging for troubleshooting.\n\n## use cases of Llama-Server MCP Proxy? \n1. Enhancing chat interactions with external tools.\n2. Integrating various MCP-compatible services for dynamic responses.\n3. Streamlining the development of applications using `llama-server`.\n\n## FAQ from Llama-Server MCP Proxy? \n- Can I use any MCP-compatible tool with this proxy?\n\u003e Yes! You can configure any MCP-compatible tool server in the `mcp-config.json` file.\n\n- What are the prerequisites for running this proxy?\n\u003e You need Node.js version 18 or higher and a running instance of `llama-server`.\n\n- How do I handle errors during tool execution?\n\u003e The proxy will forward errors from `llama-server`, and you can enable debug logging for more insights.7:[[\"$\",\"div\",null,{\"className\":\"mb-4 w-full max-w-2xl overflow-hidden\",\"children\":[\"$undefined\",[\"$\",\"h1\",null,{\"className\":\"text-2xl font-bold mb-2\",\"children\":\"MCP Clients\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"A list of MCP Clients.\"}],\"$undefined\",[\"$\",\"$L26\",null,{\"tabs\":[{\"title\":\"All\",\"url\":\"/clients\",\"is_active\":true},{\"title\":\"Featured\",\"url\":\"/clients?tag=featured\",\"is_active\":false},{\"title\":\"Latest\",\"url\":\"/clients?tag=latest\",\"is_active\":false}]}]]}],[\"$\",\"$L27\",null,{\"projects\":[{\"id\":11234,\"uuid\":\"925c500f-5984-4f05-b0c6-55cb50edbb4b\",\"name\":\"CarrotAI\",\"title\":\"CarrotAI\",\"description\":\"CarrotAI is a cutting-edge AI agent application that delivers real-time streaming chat via Server-Sent Events (SSE) with built-in Model Control Protocol (MCP) integration. It supports concurrent connections to multipl"])</script><script>self.__next_f.push([1,"e SSE MCP servers and provides user interfaces in English, Chinese, and Japanese.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/55939146?v=4\",\"created_at\":\"$D2025-04-27T17:20:16.235Z\",\"updated_at\":\"$D2025-04-27T17:29:11.312Z\",\"status\":\"created\",\"author_name\":\"Xingsandesu\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/55939146?v=4\",\"tags\":\"[]\",\"category\":\"communication\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/xingsandesu/carrotai\",\"target\":\"_self\",\"content\":\"$28\",\"summary\":\"$29\",\"img_url\":\"https://github.com/Xingsandesu/CarrotAI/raw/main/public/icon.png\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"39\\\",\\\"license\\\":\\\"View license\\\",\\\"language\\\":\\\"Dart\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-10 23:10:22\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":3275,\"uuid\":\"83072fea-5ed8-47f9-b8a1-dad2d84f43bb\",\"name\":\"seekchat\",\"title\":\"SeekChat\",\"description\":\"âœ¨ A Sleek and Powerful AI Desktop Assistant that supports MCP integrationâœ¨\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/200639714?v=4\",\"created_at\":\"$D2025-03-18T14:03:38.702Z\",\"updated_at\":\"$D2025-03-19T02:23:56.319Z\",\"status\":\"created\",\"author_name\":\"seekrays\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/200639714?v=4\",\"tags\":\"chat,ai,mcp,chat-application,mcp-client\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/seekrays/seekchat\",\"target\":\"_self\",\"content\":\"$2a\",\"summary\":\"$2b\",\"img_url\":\"https://github.com/seekrays/seekchat/raw/main/public/assets/logo/logo.png\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"31\\\",\\\"license\\\":\\\"Apache-2.0 license\\\",\\\"language\\\":\\\"JavaScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-04-18 23:51:40\\\"}\",\"user_uuid\":\"c94858b7-f782-4c1b-9ce9-d04bd19d716d\",\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":1690,\"uuid\":\"8e7dd7d7-a5ce-4e5f-9e5c-5d50fbc35844\",\"name\":\"easyrag\",\"title\":\"LLM RAG\",\"description\":\"Easy RAG scripts for a local, embedded, MCP-enabled knowledge store.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/392846?v=4\",\"created_at\":\"$D2025-03-05T04:47:53.650Z\",\"updated_at\":\"$D2025-03-12T10:20:52.478Z\",\"status\":\"created\",\"author_name\":\"binarybana\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/392846?v=4\",\"tags\":\"[]\",\"category\":\"research-and-data\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/binarybana/easyrag\",\"target\":\"_self\",\"content\":\"# LLM RAG\\n\\nA RAG (Retrieval Augmented Generation) implementation using LlamaIndex for document processing, Gemini for embeddings, and LanceDB for vector storage.\\n\\n## Setup\\n\\nThis project uses `uv` for dependency management and `direnv` for environment management. To get started:\\n\\n1. Install dependencies:\\n```bash\\n# Create and activate a new virtual environment\\nuv venv\\nsource .venv/bin/activate\\n\\n# Install dependencies\\nuv pip install -e .\\n```\\n\\n2. Set up environment:\\n```bash\\n# Create .env file with your Google API key\\necho \\\"GOOGLE_API_KEY=your_key_here\\\" \u003e .env\\n\\n# Allow direnv to load the environment\\ndirenv allow\\n```\\n\\n## Usage\\n\\n### Data Ingestion\\n\\n```bash\\npython -m llm_rag.ingest --source /path/to/source --type [code|url|pdf]\\n```\\n\\n### Search Server\\n\\n```bash\\npython -m llm_rag.search --db /path/to/lancedb\",\"summary\":\"$2c\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"2\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-02-24 03:21:00\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_cal"])</script><script>self.__next_f.push([1,"l\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":3634,\"uuid\":\"7b7657e3-76e9-42ce-bfc3-fdadd53b2123\",\"name\":\"mcp-download\",\"title\":\"Download MCP å·¥å…·\",\"description\":\"ğŸ“¥ MCP Download Tool - AI-powered file download manager | åŸºäº MCP çš„æ™ºèƒ½ä¸‹è½½ç®¡ç†å·¥å…·\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/149454909?v=4\",\"created_at\":\"$D2025-03-20T17:06:45.553Z\",\"updated_at\":\"$D2025-03-20T17:12:23.932Z\",\"status\":\"created\",\"author_name\":\"shuakami\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/149454909?v=4\",\"tags\":\"nodejs,typescript,mcp,multi-thread,download-manager,file-downloader,download-tool,ai-powered,model-context-protocol,concurrent-download\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/shuakami/mcp-download\",\"target\":\"_self\",\"content\":\"$2d\",\"summary\":\"$2e\",\"img_url\":\"https://camo.githubusercontent.com/146c49c81cd3ae1dd924a1ee530d2f0cf4d598239f847274c2dc91a66fe98d7d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4953432d3361383666663f7374796c653d666c61742d737175617265\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"6\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-04-03 08:56:04\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":4857,\"uuid\":\"8bb637e7-befd-4acf-84ef-ac5049793f79\",\"name\":\"pydantic-mcp\",\"title\":\"pydantic-mcp\",\"description\":\"Model Context Protocol tool calling support for Pydantic AI\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/11581?v=4\",\"created_at\":\"$D2025-03-27T01:33:50.178Z\",\"updated_at\":\"$D2025-03-27T01:45:11.248Z\",\"status\":\"created\",\"author_name\":\"rectalogic\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/11581?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/rectalogic/pydantic-mcp\",\"target\":\"_self\",\"content\":\"$2f\",\"summary\":\"$30\",\"img_url\":\"https://camo.githubusercontent.com/8e3a7706d788c18db4eb8b8b9335f1a3cd280cc6792513c7a4309e3cbf9bded6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f707964616e7469632d6d6370\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"9\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-26 09:43:26\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":1588,\"uuid\":\"ad3d62d5-2d93-4fb0-bc8a-19c8f7e9ad2d\",\"name\":\"LibreChat\",\"title\":\"LibreChat\",\"description\":\"Enhanced ChatGPT Clone: Features Agents, DeepSeek, Anthropic, AWS, OpenAI, Assistants API, Azure, Groq, o1, GPT-4o, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active project.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/110412045?v=4\",\"created_at\":\"$D2025-02-23T09:39:31.721Z\",\"updated_at\":\"$D2025-02-23T09:48:51.305Z\",\"status\":\"created\",\"author_name\":\"danny-avila\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/110412045?v=4\",\"tags\":\"aws,google,ai,clone,azure,plugins,gemini,vision,openai,artifacts,webui,claude,o1,chatgpt,chatgpt-clone,anthropic,librechat,dall-e-3,assistant-api,deepseek\",\"category\":\"communication\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/danny-avila/librechat\",\"target\":\"_self\",\"content\":\"$31\",\"summary\":\"$32\",\"img_url\":\"https://github.com/danny-avila/LibreChat/raw/main/client/public/assets/logo.svg\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"26295\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"TypeScript\\\""])</script><script>self.__next_f.push([1,",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-04 23:11:34\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":1514,\"uuid\":\"88413413-012d-496a-868c-2ca975bd361c\",\"name\":\"tester-mcp-client\",\"title\":\"Tester Client for Model Context Protocol (MCP)\",\"description\":\"Model Context Protocol (MCP) Client for Apify's Actors\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/24586296?v=4\",\"created_at\":\"$D2025-02-20T16:08:57.483Z\",\"updated_at\":\"$D2025-02-23T07:22:07.796Z\",\"status\":\"created\",\"author_name\":\"apify\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/24586296?v=4\",\"tags\":\"mcp,mcp-server,mcp-client\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/apify/tester-mcp-client\",\"target\":\"_self\",\"content\":\"$33\",\"summary\":\"$34\",\"img_url\":\"https://camo.githubusercontent.com/352247438a1896874feeafcaa399fa9dfbfcd1615c2e1917b42ebd6379bbd024/68747470733a2f2f61706966792e636f6d2f6163746f722d62616467653f6163746f723d6a6972692e7370696c6b612f7465737465722d6d63702d636c69656e74\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"57\\\",\\\"license\\\":\\\"Apache-2.0 license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-06 11:50:25\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":13902,\"uuid\":\"1597f200-b9f6-483e-98fc-a644d839eef4\",\"name\":\"AI-Agent-Zxc\",\"title\":\"AIæ™ºèƒ½ä½“é¡¹ç›®\",\"description\":\"åŸºäºSpringAIæ¡†æ¶å®ç°æ¨¡å‹è°ƒç”¨ã€RAGã€ToolCallingå’ŒMCPï¼Œå®ç°ä¸€ä¸ªå¯ä»¥è§£å†³å¤æ‚é—®é¢˜ï¼Œè‡ªä¸»è°ƒç”¨å·¥å…·çš„æ™ºèƒ½ä½“\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/175464331?v=4\",\"created_at\":\"$D2025-06-01T02:16:03.334Z\",\"updated_at\":\"$D2025-06-01T02:33:45.711Z\",\"status\":\"created\",\"author_name\":\"Study944\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/175464331?v=4\",\"tags\":\"[]\",\"category\":\"research-and-data\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/study944/ai-agent-zxc\",\"target\":\"_self\",\"content\":\"$35\",\"summary\":\"$36\",\"img_url\":\"https://private-user-images.githubusercontent.com/175464331/448319848-faac2f40-0b76-43ef-9201-2083b277ebc3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDkzMTY5MzgsIm5iZiI6MTc0OTMxNjYzOCwicGF0aCI6Ii8xNzU0NjQzMzEvNDQ4MzE5ODQ4LWZhYWMyZjQwLTBiNzYtNDNlZi05MjAxLTIwODNiMjc3ZWJjMy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYwN1QxNzE3MThaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iYmYxOTNiZTg1NGUwOWMzZTgzZjY2Y2NlYzQ5YWNjZmZhNTMxYzQ1ZDVlZmQ5NTNhYTIxYjdhMTkwODkwNzkxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.jfgHDJ78MHuq_ksE7QCFdhabugET9NaGkc4JyCygD68\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"5\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Java\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-05 14:25:26\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":163,\"uuid\":\"547f6f55-6c53-4b09-bb65-75e02151ecff\",\"name\":\"mcp-cli\",\"title\":\"mcp-cli\",\"description\":\"A CLI inspector for the Model Context Protocol\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/321947?v=4\",\"created_at\":\"$D2024-12-13T09:12:08.219Z\",\"updated_at\":\"$D2024-12-13T12:28:15.313Z\",\"status\":\"created\",\"author_name\":\"wong2\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/321947?v=4\",\"tags\":\"[]\",\"cate"])</script><script>self.__next_f.push([1,"gory\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/wong2/mcp-cli\",\"target\":\"_self\",\"content\":\"$37\",\"summary\":\"$38\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"332\\\",\\\"license\\\":\\\"GPL-3.0 license\\\",\\\"language\\\":\\\"JavaScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-06 19:50:35\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":1591,\"uuid\":\"a5436f61-0660-4865-af45-c5723970e24b\",\"name\":\"genaiscript\",\"title\":\"GenAIScript\",\"description\":\"Automatable GenAI Scripting\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/6154722?v=4\",\"created_at\":\"$D2025-02-23T09:41:42.006Z\",\"updated_at\":\"$D2025-02-23T09:48:50.393Z\",\"status\":\"created\",\"author_name\":\"microsoft\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/6154722?v=4\",\"tags\":\"javascript,agent,typescript,ai,scripting,vscode-extension,gpt,agents,gpt4,llm,prompt-engineering,chatgpt,genai,genaistack,llm-framework,phi4,deepseek-r1\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/microsoft/genaiscript\",\"target\":\"_self\",\"content\":\"$39\",\"summary\":\"$3a\",\"img_url\":\"https://github.com/microsoft/genaiscript/raw/main/docs/public/images/favicon.png\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"2633\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-27 11:13:57\\\"}\",\"user_uuid\":\"b76eccd5-70a1-4bbb-a50b-069bed4af838\",\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":\"npx -y genaiscript mcp\",\"server_params\":\"{}\",\"server_config\":\"{\\n    \\\"mcpServers\\\": {\\n        \\\"genaiscript\\\": {\\n            \\\"command\\\": \\\"npx\\\",\\n            \\\"args\\\": [\\\"-y\\\", \\\"genaiscript\\\", \\\"mcp\\\"]\\n        }\\n    }\\n}\\n\",\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":4856,\"uuid\":\"77987fa8-b707-41ee-9d03-ceba2fa3af91\",\"name\":\"mcp-client-app\",\"title\":\"MCP Client Application\",\"description\":\"A mcp client chat application built for learning purposes\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/32272832?v=4\",\"created_at\":\"$D2025-03-27T01:27:06.746Z\",\"updated_at\":\"$D2025-03-27T01:31:10.083Z\",\"status\":\"created\",\"author_name\":\"RegiByte\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/32272832?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/regibyte/mcp-client-app\",\"target\":\"_self\",\"content\":\"$3b\",\"summary\":\"$3c\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"6\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-17 15:30:38\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":10355,\"uuid\":\"147f54b4-0086-4ab1-a9a3-301101ecd326\",\"name\":\"Clap-Agents\",\"title\":\"CLAP - Cognitive Layer Agent Package\",\"description\":\"Powerful Asynchronous Multi agent framework built from scratch in python supporting RAG and MCP compatibilities.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/171569690?v=4\",\"created_at\":\"$D2025-04-22T17:52:16.134Z\",\"updated_at\":\"$D2025-04-22T17:56:36.950Z\",\"status\":\"created\",\"author_name\":\"MaitreyaM\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/171569690?v=4\",\"tags\":\"[]\",\"category\":\"research-and-data\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/maitreyam/clap-agents\",\"target\":\"_self\",\"content\":\"$3d\",\"summary\":\"$3e\",\"img_url\":\"https://github.com/MaitreyaM/Clap-Agents/raw/main/GITCLAP.png\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"4\\\",\\\"license\\\":\\\"Apache-2.0 license\\\",\\\"language\\\":\\\"Python\\\",\\\"is_off"])</script><script>self.__next_f.push([1,"icial\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-07 17:18:32\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":2084,\"uuid\":\"7191e1bc-54ac-4e32-bca4-51dac11f731e\",\"name\":\"MCP_CLI_CLIENT\",\"title\":\"MCP CLI Client\",\"description\":\"Een lokale MCP host en client die met meerdere LLM's en meerdere MCP servers kan werken.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/9841793?v=4\",\"created_at\":\"$D2025-03-09T02:48:46.323Z\",\"updated_at\":\"$D2025-03-12T10:18:19.965Z\",\"status\":\"created\",\"author_name\":\"Fbeunder\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/9841793?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/fbeunder/mcp_cli_client\",\"target\":\"_self\",\"content\":\"$3f\",\"summary\":\"$40\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"0\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-05 09:12:25\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":16681,\"uuid\":\"7b439253-1444-425f-8c6b-be3bb683377f\",\"name\":\"sekora-gitlab-mcp\",\"title\":\"Sekora GitLab MCP\",\"description\":\" Complete GitLab MCP integration with 72 specialized tools for comprehensive DevOps management\",\"avatar_url\":\"https://sekora.ai/favicon.ico\",\"created_at\":\"$D2025-08-10T20:15:53.322Z\",\"updated_at\":\"$D2025-08-10T21:00:15.112Z\",\"status\":\"created\",\"author_name\":\"Sekora\",\"author_avatar_url\":null,\"tags\":\"  gitlab, devops, ci-cd, issue-management, merge-requests, pipelines, security-scanning, analytics, deployment, project-management\",\"category\":null,\"is_featured\":false,\"sort\":1,\"url\":\"https://gitlab.com/sekora-ai/sekora-gitlab-mcp\",\"target\":\"_self\",\"content\":\"Comprehensive GitLab Model Context Protocol (MCP) server providing 72 specialized tools for complete DevOps lifecycle management. Built with the MCP Framework for\\n  type-safe, reliable GitLab API integration.\\n\\n  Key Features:\\n  - ğŸ”§ Issue Management - Complete issue lifecycle with milestones and labels\\n  - ğŸš€ CI/CD Pipeline Management - Monitor, trigger, and analyze pipelines and jobs\\n  - ğŸ”€ Merge Request Workflow - Full MR lifecycle from creation to merge\\n  - ğŸ“Š Advanced Analytics - Project insights, contributor stats, and usage metrics\\n  - ğŸ”’ Security \u0026 Quality - SAST, dependency scanning, license compliance\\n  - ğŸŒ Environment Management - Deployment tracking, feature flags, and GitLab Pages\\n  - ğŸ‘¥ Team Collaboration - Discussions, wiki, snippets, and mentions\\n  - ğŸ¢ Project Administration - Member management, settings, integrations\\n\\n  Supports both GitLab.com and self-hosted instances with multi-tenant configuration.\",\"summary\":\"$41\",\"img_url\":null,\"type\":\"client\",\"metadata\":null,\"user_uuid\":\"34a0afcc-d842-433b-9bd6-6aa3c69ddd08\",\"tools\":\"$42\",\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":\"GITLAB_TOKEN={GITLAB_TOKEN} npx @sekora/gitlab-mcp@latest\",\"server_params\":\"{\\\"GITLAB_TOKEN\\\":\\\"your-gitlab-private-token\\\"}\",\"server_config\":\"{\\n    \\\"mcpServers\\\": {\\n        \\\"gitlab-mcp\\\": {\\n            \\\"command\\\": \\\"npx\\\",\\n            \\\"args\\\": [\\\"@sekora/gitlab-mcp@latest\\\"],\\n            \\\"env\\\": {\\n                \\\"GITLAB_TOKEN\\\":  \\\"your-gitlab-private-token\\\"\\n            }\\n        }\\n    }\\n}\",\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":7810,\"uuid\":\"5b1e644b-160f-47b5-84fb-6a017c181c65\",\"name\":\"mcp-use\",\"title\":\"Unified MCP Client Library\",\"description\":\"mcp-use is the easiest way to interact with mcp servers with custom agents\",\"avatar_url\":\"https://avatars.githubusercontent.co"])</script><script>self.__next_f.push([1,"m/u/207005519?v=4\",\"created_at\":\"$D2025-04-10T10:11:12.419Z\",\"updated_at\":\"$D2025-04-10T10:16:59.546Z\",\"status\":\"created\",\"author_name\":\"mcp-use\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/207005519?v=4\",\"tags\":\"python,agent,ai,mcp,agents,mcp-client\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/mcp-use/mcp-use\",\"target\":\"_self\",\"content\":\"$43\",\"summary\":\"$44\",\"img_url\":\"https://github.com/mcp-use/mcp-use/raw/main/static/logo-white.svg\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"3538\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-04 22:25:04\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":3464,\"uuid\":\"3636b7ee-524a-4d48-8ec8-63c8bf6059ed\",\"name\":\"weather-tool-with-mcp\",\"title\":\"Requirements:\",\"description\":\"MCP Weather Tool\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/45539506?v=4\",\"created_at\":\"$D2025-03-19T17:10:33.099Z\",\"updated_at\":\"$D2025-03-19T17:11:21.159Z\",\"status\":\"created\",\"author_name\":\"rairai77\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/45539506?v=4\",\"tags\":\"[]\",\"category\":\"research-and-data\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/rairai77/weather-tool-with-mcp\",\"target\":\"_self\",\"content\":\"# Requirements:\\n- uv for dependencies\\n- weatherapi.com key\\n\\n# Setup:\\n- copy .example.env to .env and add the weather api key\\n- create a custom ollama model called llama3.1-tool:8b using the modelfile and llama3.1:8b as a base\\n\\n# Usage:\\n```sh\\nollama serve\\nuv run main.py\\n```\",\"summary\":\"$45\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"1\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-18 12:38:36\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":11296,\"uuid\":\"0570ff16-21ea-429a-9727-d122e9c7f729\",\"name\":\"xhs-mcp\",\"title\":\"å°çº¢ä¹¦MCPæœåŠ¡\",\"description\":\"å°çº¢ä¹¦MCPæœåŠ¡ x-s x-t jsé€†å‘\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/85341781?v=4\",\"created_at\":\"$D2025-04-28T06:19:04.264Z\",\"updated_at\":\"$D2025-04-28T06:47:46.722Z\",\"status\":\"created\",\"author_name\":\"jobsonlook\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/85341781?v=4\",\"tags\":\"mcp,xhs\",\"category\":null,\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/jobsonlook/xhs-mcp\",\"target\":\"_self\",\"content\":\"$46\",\"summary\":\"# å°çº¢ä¹¦MCPæœåŠ¡\\n## ç‰¹ç‚¹\\n- [x] é‡‡ç”¨jsé€†å‘å‡ºx-s,x-t,ç›´æ¥è¯·æ±‚httpæ¥å£,æ— é¡»ç¬¨é‡çš„playwright\\n- [x] æœç´¢ç¬”è®°\\n- [x] è·å–ç¬”è®°å†…å®¹\\n- [x] è·å–ç¬”è®°çš„è¯„è®º\\n- [x] å‘è¡¨è¯„è®º\\n\\n![ç‰¹æ€§](https://raw.githubusercontent.com/jobsonlook/xhs-mcp/master/docs/feature.png)\\n\\n## å¿«é€Ÿå¼€å§‹\\n\\n### 1. ç¯å¢ƒ\\n * node\\n * python 3.12\\n\\n### 2. å®‰è£…ä¾èµ–\\n```sh\\n\\ngit clone git@github.com:jobsonlook/xhs-mcp.git\\ncd xhs-mcp\\nuv sync \\n\\n```\\n\\n### 3. è·å–å°çº¢ä¹¦çš„cookie\\n[æ‰“å¼€webå°çº¢ä¹¦](https://www.xiaohongshu.com/explore)\\nç™»å½•åï¼Œè·å–cookie\\n![cookie](https://raw.githubusercontent.com/jobsonlook/xhs-mcp/master/docs/cookie.png)\\n\\n### 4. é…ç½®mcp server\\n\\n```json\\n{\\n    \\\"mcpServers\\\": {\\n        \\\"xhs-mcp\\\": {\\n            \\\"command\\\": \\\"uv\\\",\\n            \\\"args\\\": [\\n                \\\"--directory\\\",\\n                \\\"/Users/xxx/xhs-mcp\\\",\\n                \\\"run\\\",\\n                \\\"main.py\\\"\\n            ],\\n            \\\"env\\\": {\\n                \\\"XHS_COOKIE\\\": \\\"xxxx\\\"\\n            },\\n        }\\n    }\\n}\\n```\\n\\n## å…è´£å£°æ˜\\næœ¬é¡¹ç›®ä»…ç”¨äºå­¦ä¹ äº¤æµï¼Œç¦æ­¢ç”¨äºå…¶ä»–ç”¨é€”ï¼Œä»»ä½•æ¶‰åŠå•†ä¸šç›ˆåˆ©ç›®çš„å‡ä¸å¾—ä½¿ç”¨ï¼Œå¦åˆ™é£é™©è‡ªè´Ÿã€‚\\n\",\"img_u"])</script><script>self.__next_f.push([1,"rl\":\"https://camo.githubusercontent.com/fe5c402eb402210fc8a113bc89e57ed2d7d58f93765ad2ca68cd0f953e667124/68747470733a2f2f736d6974686572792e61692f62616467652f406a6f62736f6e6c6f6f6b2f7868732d6d6370\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"155\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-30 14:30:32\\\"}\",\"user_uuid\":\"7db5fa7d-1ef0-4734-bcd1-b916376c54fb\",\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":\"{\\n    \\\"mcpServers\\\": {\\n        \\\"xhs-mcp\\\": {\\n            \\\"command\\\": \\\"uv\\\",\\n            \\\"args\\\": [\\n                \\\"--directory\\\",\\n                \\\"/Users/xxx/xhs-mcp\\\",\\n                \\\"run\\\",\\n                \\\"main.py\\\"\\n            ],\\n            \\\"env\\\": {\\n                \\\"XHS_COOKIE\\\": \\\"xxxx\\\"\\n            },\\n        }\\n    }\\n}\",\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":5032,\"uuid\":\"a0021f7f-9209-4938-a2cc-bf68f48eb46e\",\"name\":\"slack-mcp-client\",\"title\":\"Slack MCP Client\",\"description\":\"An MCP client for slack in Typescript\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/2435414?v=4\",\"created_at\":\"$D2025-03-30T20:49:21.606Z\",\"updated_at\":\"$D2025-03-30T21:02:05.057Z\",\"status\":\"created\",\"author_name\":\"csonigo\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/2435414?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/csonigo/slack-mcp-client\",\"target\":\"_self\",\"content\":\"$47\",\"summary\":\"$48\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"17\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-20 16:26:52\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":13897,\"uuid\":\"caad1c1f-5307-4e9b-8bd1-13657301a401\",\"name\":\"speech-mcp\",\"title\":\"Speech Mcp\",\"description\":\"Speech MCP Project\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/131324946?v=4\",\"created_at\":\"$D2025-06-01T02:06:49.692Z\",\"updated_at\":\"$D2025-06-02T09:11:50.745Z\",\"status\":\"created\",\"author_name\":\"netixc\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/131324946?v=4\",\"tags\":\"[]\",\"category\":\"speech-processing\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/netixc/speech-mcp\",\"target\":\"_self\",\"content\":\"$49\",\"summary\":\"$4a\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"1\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-04 11:23:56\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":7671,\"uuid\":\"2ab964b5-34f7-4d30-bda8-9326234b61bc\",\"name\":\"speelka-agent\",\"title\":\"Speelka Agent\",\"description\":\"Universal LLM Agent based on MCP\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/66022?v=4\",\"created_at\":\"$D2025-04-09T20:58:10.269Z\",\"updated_at\":\"$D2025-04-09T20:58:17.017Z\",\"status\":\"created\",\"author_name\":\"korchasa\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/66022?v=4\",\"tags\":\"agent,mcp,llm,agentic-ai,mcp-server\",\"category\":\"research-and-data\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/korchasa/speelka-agent\",\"target\":\"_self\",\"content\":\"$4b\",\"summary\":\"$4c\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"2\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"Go\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-21 17:51:08\\\"}\",\"user_uuid\":\"c6bcd7e6-69ad-4743-b43f-c952ee67d83f\",\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":nul"])</script><script>self.__next_f.push([1,"l,\"server_config\":\"\",\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":3789,\"uuid\":\"23d1c4d7-711e-45f1-af84-a575314ae1b0\",\"name\":\"FLUJO\",\"title\":\"DISCLAIMER\",\"description\":\"MCP-Hub and -Inspector, Multi-Model Workflow and Chat Interface\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/196235471?v=4\",\"created_at\":\"$D2025-03-21T17:42:31.607Z\",\"updated_at\":\"$D2025-03-21T17:46:55.791Z\",\"status\":\"created\",\"author_name\":\"mario-andreschak\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/196235471?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/mario-andreschak/flujo\",\"target\":\"_self\",\"content\":\"$4d\",\"summary\":\"$4e\",\"img_url\":\"https://private-user-images.githubusercontent.com/196235471/434461898-8d71d291-74a3-486d-a8f5-c8976aedba0f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDkwNjE0MTksIm5iZiI6MTc0OTA2MTExOSwicGF0aCI6Ii8xOTYyMzU0NzEvNDM0NDYxODk4LThkNzFkMjkxLTc0YTMtNDg2ZC1hOGY1LWM4OTc2YWVkYmEwZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjA0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYwNFQxODE4MzlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yZjRiOWI5OTM0ODkxMjgxNjIwYmJkM2E4ZjA4ZTYzY2I2ZjhmZDRiYmQwNzJiYTZkNzllMjQyMWJiZTQ2NTAxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.mNqMgFu7brYOof3xwOlmNV0hPk8Jj4mTifUZZ_9I4Uo\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"460\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-04-29 12:39:45\\\"}\",\"user_uuid\":\"eeb63909-b358-407c-83e2-6118dbefccf1\",\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":\"\",\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":12289,\"uuid\":\"43a99ccc-ff01-415f-9ba6-f96a308e6356\",\"name\":\"teamspark-workbench\",\"title\":\"TeamSpark AI Workbench\",\"description\":\"TeamSpark AI Workbench\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/151309166?v=4\",\"created_at\":\"$D2025-05-03T17:26:41.019Z\",\"updated_at\":\"$D2025-05-03T17:33:13.591Z\",\"status\":\"created\",\"author_name\":\"TeamSparkAI\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/151309166?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/teamsparkai/teamspark-workbench\",\"target\":\"_self\",\"content\":\"$4f\",\"summary\":\"$50\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"0\\\",\\\"license\\\":\\\"View license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-18 22:47:22\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":4874,\"uuid\":\"7e659ab9-6b7a-418d-8267-16b99eadba75\",\"name\":\"Jira_mcp_streamlit\",\"title\":\"Jira Assistant with MCP Integration\",\"description\":\"A Streamlit-powered Jira assistant with MCP integration. Create, search, and manage Jira tickets through a clean tabbed interface using natural language commands or direct forms. Built with Python and MCP framework.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/44362349?v=4\",\"created_at\":\"$D2025-03-27T03:49:31.782Z\",\"updated_at\":\"$D2025-03-27T03:52:08.604Z\",\"status\":\"created\",\"author_name\":\"pawankumar94\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/44362349?v=4\",\"tags\":\"jira,googlecloudplatform,gemini-api,streamlit,vertexai,generativeai,modelcontextprotocol\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/pawankumar94/jira_mcp_streamlit\",\"target\":\"_self\",\"content\":\"$51\",\"summary\":\"$52\",\"img_url\":\"https://github.com/pawankumar94/Jira_mcp_streamlit/raw/main/jira_"])</script><script>self.__next_f.push([1,"server_demo.gif\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"2\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-02 11:10:24\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":10356,\"uuid\":\"a8eb3461-ec0d-4e86-94a2-f9fcafe21c57\",\"name\":\"scira-mcp-chat\",\"title\":\"Scira Mcp Chat\",\"description\":\"A minimalistic MCP client with a good feature set.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/76097144?v=4\",\"created_at\":\"$D2025-04-22T17:58:27.781Z\",\"updated_at\":\"$D2025-04-22T18:00:54.897Z\",\"status\":\"created\",\"author_name\":\"zaidmukaddam\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/76097144?v=4\",\"tags\":\"mcp,openai,xai,anthropic,model-context-protocol,mcp-client,grok3\",\"category\":\"communication\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/zaidmukaddam/scira-mcp-chat\",\"target\":\"_self\",\"content\":\"$53\",\"summary\":\"$54\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"536\\\",\\\"license\\\":\\\"Apache-2.0 license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-04 08:01:19\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":7217,\"uuid\":\"92b0ed1b-6edd-44ea-b17e-5362339b816d\",\"name\":\"langchaingo-mcp-adapter\",\"title\":\"LangChainGo MCP Adapter\",\"description\":\"A Go adapter that bridges LangChain Go tools with Model Context Protocol (MCP) servers.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/6240399?v=4\",\"created_at\":\"$D2025-04-08T00:58:32.227Z\",\"updated_at\":\"$D2025-04-08T01:57:27.864Z\",\"status\":\"created\",\"author_name\":\"i2y\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/6240399?v=4\",\"tags\":\"go,agent,golang,mcp,langchaingo,mcp-tools\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/i2y/langchaingo-mcp-adapter\",\"target\":\"_self\",\"content\":\"$55\",\"summary\":\"$56\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"15\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"Go\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-04-08 19:01:52\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":8753,\"uuid\":\"e3ba9bf9-7cfb-4654-bcd4-e418b8e2f083\",\"name\":\"mcp-client-chatbot\",\"title\":\"MCP Client Chatbot\",\"description\":\"ğŸš€ Open source MCP Client: A Multi-provider AI Chatbot Solution\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/86150470?v=4\",\"created_at\":\"$D2025-04-14T17:26:29.091Z\",\"updated_at\":\"$D2025-04-14T17:48:38.765Z\",\"status\":\"created\",\"author_name\":\"cgoinglove\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/86150470?v=4\",\"tags\":\"agent,ai,mcp,chatbot,web-ui,openai,next,voice-ai,ai-chatbot,vercel,ollama,openai-realtime,mcp-server,mcp-client\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/cgoinglove/mcp-client-chatbot\",\"target\":\"_self\",\"content\":\"$57\",\"summary\":\"$58\",\"img_url\":\"https://camo.githubusercontent.com/b82579bc6d2350fec1b1fb45c1da7683645f728898b5fdf941dae6b889bf0b90/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d43502d537570706f727465642d303063383533\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"225\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-06-04 13:23:49\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":"])</script><script>self.__next_f.push([1,"false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":13908,\"uuid\":\"71eeae82-0530-4698-afc4-515d2c4f82f9\",\"name\":\"mcp-chatbot\",\"title\":\"mcp-chatbot\",\"description\":\"MCP Chatbot powered by Anthropic Claude. Delivering onâ€demand literature search and summarisation for academics and engineers\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/51781970?v=4\",\"created_at\":\"$D2025-06-01T02:28:40.877Z\",\"updated_at\":\"$D2025-06-01T02:33:42.145Z\",\"status\":\"created\",\"author_name\":\"mctrinh\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/51781970?v=4\",\"tags\":\"mcp,chatbot,ai-chatbot,anthropic-claude,model-context-protocol,model-context-protocol-client,model-context-protocol-server,mcp-chatbot\",\"category\":\"research-and-data\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/mctrinh/mcp-chatbot\",\"target\":\"_self\",\"content\":\"$59\",\"summary\":\"$5a\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"9\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-24 22:57:03\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":6672,\"uuid\":\"ad7c1634-2242-43c2-bab5-891cac37cbc4\",\"name\":\"agents-mcp-cloud\",\"title\":\"MCP Agents Cloud\",\"description\":\"MCP Agents Cloudæ˜¯ä¸€ä¸ªæä¾›ç®¡ç†MCPæœåŠ¡å™¨å’Œä»£ç†ï¼ˆAgentï¼‰çš„å¹³å°ã€‚\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/20783890?v=4\",\"created_at\":\"$D2025-04-05T17:21:51.168Z\",\"updated_at\":\"$D2025-04-05T17:35:21.445Z\",\"status\":\"created\",\"author_name\":\"HiCoderMonkey\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/20783890?v=4\",\"tags\":\"[]\",\"category\":\"cloud-platforms\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/hicodermonkey/agents-mcp-cloud\",\"target\":\"_self\",\"content\":\"$5b\",\"summary\":\"$5c\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"3\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Vue\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-04-23 16:12:47\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":4302,\"uuid\":\"91172914-b379-458d-9492-cdd8527fbd78\",\"name\":\"UtilityBelt\",\"title\":\"UtilityBelt\",\"description\":\"Talk to MCP servers from aider\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/294042?v=4\",\"created_at\":\"$D2025-03-24T08:36:11.641Z\",\"updated_at\":\"$D2025-03-24T08:40:33.189Z\",\"status\":\"created\",\"author_name\":\"richardanaya\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/294042?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/richardanaya/utilitybelt\",\"target\":\"_self\",\"content\":\"$5d\",\"summary\":\"$5e\",\"img_url\":\"https://private-user-images.githubusercontent.com/294042/425979995-3f8c6127-2c02-4103-a010-0ea5a44dcbe2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDkwNjE3MzMsIm5iZiI6MTc0OTA2MTQzMywicGF0aCI6Ii8yOTQwNDIvNDI1OTc5OTk1LTNmOGM2MTI3LTJjMDItNDEwMy1hMDEwLTBlYTVhNDRkY2JlMi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjA0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYwNFQxODIzNTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kM2Q2MDkyM2MwMDNlMWEwYTVhYzZmNDgyODdkN2M1ZTk5ZWE4N2ExOTYyZGU2ZjNhYTczYmIxODFmZWU5ZDA5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.gzrTb0ycG9od_f1gScSpgwoz8j0bwGDdF7zGNlPDS4U\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"9\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Rust\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-04-17 23:15:16\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_of"])</script><script>self.__next_f.push([1,"ficial\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":7370,\"uuid\":\"f20db41e-cf62-4909-b979-3e408f696b1a\",\"name\":\"mcp-gomamayo\",\"title\":\"mcp-gomamayo\",\"description\":\"MCP server for â€ã‚´ãƒãƒãƒ¨â€\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/51170522?v=4\",\"created_at\":\"$D2025-04-08T15:24:07.131Z\",\"updated_at\":\"$D2025-04-08T15:33:57.010Z\",\"status\":\"created\",\"author_name\":\"mizakaHK\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/51170522?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/mizakahk/mcp-gomamayo\",\"target\":\"_self\",\"content\":\"$5f\",\"summary\":\"$60\",\"img_url\":\"https://camo.githubusercontent.com/df03313729d77d343a03ff02a3ce4310beb539c0fc8ac239cd456c55fbbaf589/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f676f2d76312e32342d626c75652e737667\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"3\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"Go\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-04-09 00:52:00\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":4859,\"uuid\":\"729a777b-9287-432b-b092-5d0aa0310299\",\"name\":\"launchbar-mcp_agent\",\"title\":\"MCP Agent\",\"description\":\"This is a LaunchBar version of Raycast's AI extension function, which is integrated with Langchain and MCP to automatically complete tasks based on your prompt.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/24350182?v=4\",\"created_at\":\"$D2025-03-27T01:37:49.510Z\",\"updated_at\":\"$D2025-03-27T01:46:18.941Z\",\"status\":\"created\",\"author_name\":\"justinhuang0208\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/24350182?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/justinhuang0208/launchbar-mcp_agent\",\"target\":\"_self\",\"content\":\"$61\",\"summary\":\"$62\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"1\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-09 17:25:30\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":1599,\"uuid\":\"bde432f6-913c-4ea1-b1dd-a043b469f7a8\",\"name\":\"mcp_langgraph_tools\",\"title\":\"MCP Tool Langgraph Integration\",\"description\":\"MCP Tools Langraph Integration\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/955011?v=4\",\"created_at\":\"$D2025-02-23T09:43:40.403Z\",\"updated_at\":\"$D2025-02-23T09:48:49.574Z\",\"status\":\"created\",\"author_name\":\"paulrobello\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/955011?v=4\",\"tags\":\"ai,mcp,python3\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/paulrobello/mcp_langgraph_tools\",\"target\":\"_self\",\"content\":\"$63\",\"summary\":\"$64\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"43\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-20 22:44:56\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":1460,\"uuid\":\"8e8e5210-0dd2-457e-8f8c-a193a181630f\",\"name\":\"LLaMa-MCP-Streamlit\",\"title\":\"Llama MCP Streamlit\",\"description\":\"AI assistant built with Streamlit, NVIDIA NIM (LLaMa 3.3:70B) / Ollama, and Model Control Protocol (MCP).\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/67359594?v=4\",\"created_at\":\"$D2025-02-20T15:55:25.926Z\",\"updated_at\":\"$D2025-02"])</script><script>self.__next_f.push([1,"-23T07:21:41.084Z\",\"status\":\"created\",\"author_name\":\"Nikunj2003\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/67359594?v=4\",\"tags\":\"python,mcp,llama,streamlit,llm,ollama,model-context-protocol,mcp-server,nvidia-nim-api,mcp-client,mcp-llama\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/nikunj2003/llama-mcp-streamlit\",\"target\":\"_self\",\"content\":\"$65\",\"summary\":\"$66\",\"img_url\":\"https://github.com/Nikunj2003/LLaMa-MCP-Streamlit/raw/main/screenshot/Screenshot1.png\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"39\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-02-09 21:36:50\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":2737,\"uuid\":\"bcc38201-47fa-488b-9f8d-fa7de4a3f5a7\",\"name\":\"langchainjs-mcp-adapters\",\"title\":\"LangChain.js MCP Adapters\",\"description\":\"** THIS REPO HAS MOVED TO\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/126733545?v=4\",\"created_at\":\"$D2025-03-14T00:49:19.559Z\",\"updated_at\":\"$D2025-03-14T00:52:17.455Z\",\"status\":\"created\",\"author_name\":\"langchain-ai\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/126733545?v=4\",\"tags\":\"javascript,typescript,mcp,ai-tools,langchain,llm-tools,openai-functions,langchainjs,llm-agents,agent-tools,llm-integration,model-context-protocol\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/langchain-ai/langchainjs-mcp-adapters\",\"target\":\"_self\",\"content\":\"# LangChain.js MCP Adapters\\n\\n\u003e [!IMPORTANT]\\n\u003e **This package has been migrated into [the LangChainJS monorepo](https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-mcp-adapters).**\\n\\n[![npm version](https://img.shields.io/npm/v/@langchain/mcp-adapters.svg)](https://www.npmjs.com/package/@langchain/mcp-adapters)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\nThis library provides a lightweight wrapper to allow [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) services to be used with [LangChain.js](https://github.com/langchain-ai/langchainjs).\\n\\nThis project has moved. For a current description of this project, please see the [up-to-date README](https://github.com/langchain-ai/langchainjs/tree/main/libs/langchain-mcp-adapters#readme) at the project's new location.\",\"summary\":\"$67\",\"img_url\":\"https://camo.githubusercontent.com/f692f43989f66fa5cc21c30d90e9d7007cc6e549a0a3fe6126e02bb1affcf72c/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f406c616e67636861696e2f6d63702d61646170746572732e737667\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"232\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-16 15:18:45\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":1603,\"uuid\":\"a5f6d8a9-afe7-4de1-9724-89af1338aa41\",\"name\":\"mcp-client-langchain-ts\",\"title\":\"MCP Client Using LangChain / TypeScript\",\"description\":\"Simple CLI MCP Client Implementation Using LangChain ReAct Agent / TypeScript\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/321713?v=4\",\"created_at\":\"$D2025-02-23T09:43:40.351Z\",\"updated_at\":\"$D2025-02-23T09:48:50.089Z\",\"status\":\"created\",\"author_name\":\"hideya\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/321713?v=4\",\"tags\":\"nodejs,typescript,mcp,langchain,langchain-typescript,tool-call,tool-calling,modelcontextprotocol,mcp-client\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/hideya/mcp-client-langchain-ts\",\"target\":\"_self\",\"content\":\"$68\",\"summary\":\"$69\",\"img_url\":\"https://cam"])</script><script>self.__next_f.push([1,"o.githubusercontent.com/cce5a2a14b0faab422e0bfcdc074afb46089831a0bf5930a7d8af3f31b98f847/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667\",\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"10\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"TypeScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-31 15:31:35\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":2089,\"uuid\":\"75a74e84-feeb-420a-b5c0-e31673048591\",\"name\":\"MCP_FLASK\",\"title\":\"Flask Webapplicatie met LLM-integratie en MCP-tools\",\"description\":\"Flask webapplicatie met LLM-integratie en MCP-tools voor het verwerken van prompts via verschillende AI-modellen en contextuele tools.\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/9841793?v=4\",\"created_at\":\"$D2025-03-09T02:55:24.578Z\",\"updated_at\":\"$D2025-03-12T10:18:20.303Z\",\"status\":\"created\",\"author_name\":\"Fbeunder\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/9841793?v=4\",\"tags\":\"[]\",\"category\":\"research-and-data\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/fbeunder/mcp_flask\",\"target\":\"_self\",\"content\":\"$6a\",\"summary\":\"$6b\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"0\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-05 22:02:09\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":13917,\"uuid\":\"d49294b7-7196-433e-b132-c887058405f6\",\"name\":\"mcp-react-dev-tools\",\"title\":\"BrowserTools MCP\",\"description\":\"MCP for React Dev Tools - Use directly inside cursor\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/41532804?v=4\",\"created_at\":\"$D2025-06-01T02:37:10.506Z\",\"updated_at\":\"$D2025-06-01T02:47:00.802Z\",\"status\":\"created\",\"author_name\":\"wimpywarlord\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/41532804?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/wimpywarlord/mcp-react-dev-tools\",\"target\":\"_self\",\"content\":\"$6c\",\"summary\":\"$6d\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"3\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"JavaScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-14 10:41:25\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":3792,\"uuid\":\"bca428e6-d7ce-44c1-9fff-15f5b1c08c3d\",\"name\":\"figma-design-mcp\",\"title\":\"Figma Design Automation\",\"description\":\"Automated Figma design creation tools and plugins\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/196500012?v=4\",\"created_at\":\"$D2025-03-21T17:50:54.106Z\",\"updated_at\":\"$D2025-03-21T17:54:23.998Z\",\"status\":\"created\",\"author_name\":\"aranyak-4002\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/196500012?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/aranyak-4002/figma-design-mcp\",\"target\":\"_self\",\"content\":\"$6e\",\"summary\":\"$6f\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"5\\\",\\\"license\\\":\\\"MIT license\\\",\\\"language\\\":\\\"Python\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-03-21 10:24:38\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false},{\"id\":13919,\"uuid\":\"0e315494-9d76-47fe-96aa-49c85e9352ae\",\"name\":\"llama-se"])</script><script>self.__next_f.push([1,"rver_mcp_proxy\",\"title\":\"Llama-Server MCP Proxy\",\"description\":\"Simple node proxy for llama-server that enables MCP use\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/211084106?v=4\",\"created_at\":\"$D2025-06-01T02:37:10.619Z\",\"updated_at\":\"$D2025-06-01T02:46:49.179Z\",\"status\":\"created\",\"author_name\":\"extopico\",\"author_avatar_url\":\"https://avatars.githubusercontent.com/u/211084106?v=4\",\"tags\":\"[]\",\"category\":\"developer-tools\",\"is_featured\":false,\"sort\":1,\"url\":\"https://github.com/extopico/llama-server_mcp_proxy\",\"target\":\"_self\",\"content\":\"$70\",\"summary\":\"$71\",\"img_url\":null,\"type\":\"client\",\"metadata\":\"{\\\"star\\\":\\\"13\\\",\\\"license\\\":\\\"\\\",\\\"language\\\":\\\"JavaScript\\\",\\\"is_official\\\":false,\\\"latest_commit_time\\\":\\\"2025-05-10 16:35:05\\\"}\",\"user_uuid\":null,\"tools\":null,\"sse_url\":null,\"sse_provider\":null,\"sse_params\":null,\"is_official\":false,\"server_command\":null,\"server_params\":null,\"server_config\":null,\"allow_call\":false,\"is_innovation\":false,\"is_dxt\":false,\"dxt_manifest\":null,\"dxt_file_url\":null,\"is_audit\":false}]}],[\"$\",\"$L72\",null,{\"totalPages\":8,\"itemsPerPage\":60,\"currentPage\":6}]]\n"])</script></body></html>